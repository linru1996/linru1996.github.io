<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title></title>
    <url>/2020/02/16/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E5%88%9B%E5%BB%BA%E5%9E%8B/</url>
    <content><![CDATA[<p><a href="https://blog.csdn.net/ydonghao2/article/details/80181778" target="_blank" rel="noopener">https://blog.csdn.net/ydonghao2/article/details/80181778</a></p>
<h2 id="简单工厂"><a href="#简单工厂" class="headerlink" title="简单工厂"></a>简单工厂</h2><h4 id="工厂（Creator）角色"><a href="#工厂（Creator）角色" class="headerlink" title="-     工厂（Creator）角色"></a>-     工厂（Creator）角色</h4><p>简单工厂模式的核心，它负责实现创建所有实例的内部逻辑。工厂类的创建产品类的方法可以被外界直接调用，创建所需的产品对象。</p>
<h4 id="抽象产品（Product）角色"><a href="#抽象产品（Product）角色" class="headerlink" title="-     抽象产品（Product）角色"></a>-     抽象产品（Product）角色</h4><p>简单工厂模式所创建的所有对象的父类，它负责描述所有实例所共有的公共接口。</p>
<h4 id="具体产品（Concrete-Product）角色"><a href="#具体产品（Concrete-Product）角色" class="headerlink" title="-     具体产品（Concrete Product）角色"></a>-     具体产品（Concrete Product）角色</h4><p>是简单工厂模式的创建目标，所有创建的对象都是充当这个角色的某个具体类的实例。  </p>
<h2 id="工厂方法"><a href="#工厂方法" class="headerlink" title="工厂方法"></a>工厂方法</h2><h4 id="抽象工厂-Creator-角色："><a href="#抽象工厂-Creator-角色：" class="headerlink" title="- 抽象工厂(Creator)角色："></a>- 抽象工厂(Creator)角色：</h4><p>是工厂方法模式的核心，与应用程序无关。任何在模式中创建的对象的工厂类必须实现这个接口。</p>
<h4 id="具体工厂-Concrete-Creator-角色："><a href="#具体工厂-Concrete-Creator-角色：" class="headerlink" title="- 具体工厂(Concrete Creator)角色："></a>- 具体工厂(Concrete Creator)角色：</h4><p>这是实现抽象工厂接口的具体工厂类，包含与应用程序密切相关的逻辑，并且受到应用程序调用以创建产品对象。在上图中有两个这样的角色：BulbCreator与TubeCreator。</p>
<h4 id="抽象产品-Product-角色："><a href="#抽象产品-Product-角色：" class="headerlink" title="- 抽象产品(Product)角色："></a>- 抽象产品(Product)角色：</h4><p>工厂方法模式所创建的对象的超类型，也就是产品对象的共同父类或共同拥有的接口。 </p>
<h4 id="具体产品-Concrete-Product-角色："><a href="#具体产品-Concrete-Product-角色：" class="headerlink" title="- 具体产品(Concrete Product)角色："></a>- 具体产品(Concrete Product)角色：</h4><p>这个角色实现了抽象产品角色所定义的接口。某具体产品有专门的具体工厂创建，它们之间往往一一对应。  </p>
<h3 id="创建步骤："><a href="#创建步骤：" class="headerlink" title="创建步骤："></a>创建步骤：</h3><p>步骤1： 创建抽象工厂类，定义具体工厂的公共接口；<br>步骤2： 创建抽象产品类 ，定义具体产品的公共接口；<br>步骤3： 创建具体产品类（继承抽象产品类） &amp; 定义生产的具体产品；<br>步骤4：创建具体工厂类（继承抽象工厂类），定义创建对应具体产品实例的方法；<br>步骤5：外界通过调用具体工厂类的方法，从而创建不同具体产品类的实例   </p>
<h2 id="抽象工厂"><a href="#抽象工厂" class="headerlink" title="抽象工厂"></a>抽象工厂</h2><p>抽象工厂模式创建的是对象家族，也就是很多对象而不是一个对象，并且这些对象是相关的，也就是说必须一起创建出来。而工厂方法模式只是用于创建一个对象，这和抽象工厂模式有很大不同。   </p>
<h2 id="生成器"><a href="#生成器" class="headerlink" title="生成器"></a>生成器</h2><p>封装一个对象的构造过程，并允许按步骤构造。（汉堡套餐、房子）<br>四个要素：</p>
<ul>
<li>Builder：生成器接口，定义创建一个Product对象所需要的各个部件的操作。</li>
<li>ConcreteBuilder：具体的生成器实现，实现各个部件的创建，并负责组装Product对象的各个部件，同时还提供一个让用户获取组装完成后的产品对象的方法。</li>
<li>Director：指导者，也被称导向者，主要用来使用Builder接口，以一个统一的过程来构建所需要的Product对象。</li>
<li>Product：产品，表示被生成器构建的复杂对象，包含多个部件。  </li>
</ul>
<h2 id="原型模式（clone）"><a href="#原型模式（clone）" class="headerlink" title="原型模式（clone）"></a>原型模式（clone）</h2><p><a href="https://www.jianshu.com/p/ed6a4552517c" target="_blank" rel="noopener">https://www.jianshu.com/p/ed6a4552517c</a><br>用原型实例指定创建对象的种类，并通过拷贝这些原型创建新的对象。<br>资源优化场景；类初始化需要很多资源；性能和安全有要求的场景    </p>
<h1 id="行为型"><a href="#行为型" class="headerlink" title="行为型"></a>行为型</h1><h2 id="1-责任链模式"><a href="#1-责任链模式" class="headerlink" title="1.责任链模式"></a>1.责任链模式</h2><p><a href="https://www.jianshu.com/p/9f7d9775bdda" target="_blank" rel="noopener">https://www.jianshu.com/p/9f7d9775bdda</a><br>责任链，顾名思义，就是用来处理相关事务责任的一条执行链，执行链上有多个节点，每个节点都有机会（条件匹配）处理请求事务，如果某个节点处理完了就可以根据实际业务需求传递给下一个节点继续处理或者返回处理完毕。   </p>
<ul>
<li>责任链主要重在责任分离处理，让各个节点各司其职。</li>
<li>责任链上的各个节点都有机会处理事务，但是也可能不会受理请求。</li>
<li>责任链比较长，调试时可能会比较麻烦。</li>
<li>责任链一般用于处理流程节点之类的实际业务场景中。</li>
<li>Spring拦截器链、servlet过滤器链等都采用了责任链设计模式。  </li>
</ul>
<h2 id="2-命令模式（顾客-服务员-厨师）"><a href="#2-命令模式（顾客-服务员-厨师）" class="headerlink" title="2.命令模式（顾客-服务员-厨师）"></a>2.命令模式（顾客-服务员-厨师）</h2><p><a href="http://www.ayqy.net/blog/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%91%BD%E4%BB%A4%E6%A8%A1%E5%BC%8F%EF%BC%88command-pattern%EF%BC%89/" target="_blank" rel="noopener">http://www.ayqy.net/blog/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%91%BD%E4%BB%A4%E6%A8%A1%E5%BC%8F%EF%BC%88command-pattern%EF%BC%89/</a><br>将一个请求封装为一个对象，从而使你可用不同的请求对客户进行参数化；对请求排队或记录请求日志，以及支持可撤销的操作。</p>
<p>是一种数据驱动的设计模式，它属于行为型模式，请求以命令的形式包裹在对象中，并传给调用对象。调用对象寻找可以处理该命令的合适的对象，并把该命令传给相应的对象，该对象执行命令。</p>
<p>在软件系统中，行为请求者与行为实现者通常是一种紧耦合的关系，但某些场合，比如需要对行为进行记录、撤销或重做、事务等处理时，这种无法抵御变化的紧耦合的设计就不太合适。  </p>
<p>通过调用者调用接受者执行命令，顺序：调用者→接受者→命令。<br>请求者（客户）与执行者（低层组件）被彻底解耦，作为中间人的调用者也不了解请求者与执行者的具体细节，它们被很好的保护了起来。这正是我们想要的。</p>
]]></content>
  </entry>
  <entry>
    <title></title>
    <url>/2020/02/13/%E5%AD%97%E7%AC%A6%E4%B8%B2/</url>
    <content><![CDATA[<h1 id="字符串"><a href="#字符串" class="headerlink" title="字符串"></a>字符串</h1><p>s = String.valueOf(ch); </p>
<p>int[][] arr = new int[2][3];  </p>
<pre><code>class Solution {
    List&lt;List&lt;Integer&gt;&gt; levels = new ArrayList&lt;List&lt;Integer&gt;&gt;();

    public void helper(TreeNode node, int level) {
        // start the current level
        if (levels.size() == level)
            levels.add(new ArrayList&lt;Integer&gt;());

         // fulfil the current level
         levels.get(level).add(node.val);

         // process child nodes for the next level
         if (node.left != null)
            helper(node.left, level + 1);
         if (node.right != null)
            helper(node.right, level + 1);
    }

    public List&lt;List&lt;Integer&gt;&gt; levelOrder(TreeNode root) {
        if (root == null) return levels;
        helper(root, 0);
        return levels;
    }
}</code></pre><p>作者：LeetCode<br>链接：<a href="https://leetcode-cn.com/problems/binary-tree-level-order-traversal/solution/er-cha-shu-de-ceng-ci-bian-li-by-leetcode/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/binary-tree-level-order-traversal/solution/er-cha-shu-de-ceng-ci-bian-li-by-leetcode/</a><br>来源：力扣（LeetCode）<br>著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p>
]]></content>
  </entry>
  <entry>
    <title></title>
    <url>/2020/02/13/%E9%9B%86%E5%90%88/</url>
    <content><![CDATA[<h1 id="集合"><a href="#集合" class="headerlink" title="集合"></a>集合</h1><p>HashSet <character> hs = new HashSet&lt;&gt;(Arrays.asList(‘a’,’e’,’i’,’o’,’u’,<br>        ‘A’,’E’,’I’,’O’,’U’));<br>hs.contains(ch[i])</character></p>
]]></content>
  </entry>
  <entry>
    <title></title>
    <url>/2020/02/13/%E9%98%9F%E5%88%97/</url>
    <content><![CDATA[<h1 id="队列"><a href="#队列" class="headerlink" title="队列"></a>队列</h1><pre><code>Queue &lt; Integer &gt; queue = new LinkedList &lt; &gt; ();

queue.add(nums[i][j]);  

res[i][j] = queue.remove();</code></pre>]]></content>
  </entry>
  <entry>
    <title></title>
    <url>/2020/02/07/%E9%93%BE%E8%A1%A8/</url>
    <content><![CDATA[<pre><code> ListNode temp = head;
if(head==null || head.next == null) return head;   </code></pre><h2 id="链表1：相交链表（双指针）"><a href="#链表1：相交链表（双指针）" class="headerlink" title="链表1：相交链表（双指针）"></a>链表1：相交链表（双指针）</h2><pre><code>public class Solution {
    public ListNode getIntersectionNode(ListNode headA, ListNode headB) {
        /**
        定义两个指针, 第一轮让两个到达末尾的节点指向另一个链表的头部, 最后如果相遇则为交点(在第一轮移动中恰好抹除了长度差)
        两个指针等于移动了相同的距离, 有交点就返回, 无交点就是各走了两条指针的长度
        **/
        if(headA == null || headB == null) return null;
        ListNode pA = headA, pB = headB;
        // 在这里第一轮体现在pA和pB第一次到达尾部会移向另一链表的表头, 而第二轮体现在如果pA或pB相交就返回交点, 不相交最后就是null==null
        while(pA != pB) {
            pA = pA == null ? headB : pA.next;
            pB = pB == null ? headA : pB.next;
        }
        return pA;
    }
}</code></pre><h2 id="链表2：反转链表"><a href="#链表2：反转链表" class="headerlink" title="链表2：反转链表"></a>链表2：反转链表</h2><p>直接反转/递归<br>递归：<br>public ListNode reverseList(ListNode head) {<br>    if (head == null || head.next == null) return head;<br>    ListNode p = reverseList(head.next);<br>    head.next.next = head;<br>    head.next = null;<br>    return p;<br>}</p>
<p>作者：LeetCode<br>链接：<a href="https://leetcode-cn.com/problems/reverse-linked-list/solution/fan-zhuan-lian-biao-by-leetcode/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/reverse-linked-list/solution/fan-zhuan-lian-biao-by-leetcode/</a><br>来源：力扣（LeetCode）<br>著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p>
]]></content>
  </entry>
  <entry>
    <title></title>
    <url>/2020/02/07/%E6%A0%91/</url>
    <content><![CDATA[<h1 id="树（处理方法：递归）"><a href="#树（处理方法：递归）" class="headerlink" title="树（处理方法：递归）"></a>树（处理方法：递归）</h1><pre><code>public class TreeNode{
    public int val;
    public TreeNode left,right;

    public TreeNode(int val){
        this.val = val;
        this.left = null;
        this.right = null;
    }
}  </code></pre><p>树的遍历：前序、中序、后序</p>
<p>二叉搜索树：中序遍历是升序遍历<br>常见操作： 查询、插入新节点、删除    logn</p>
]]></content>
  </entry>
  <entry>
    <title></title>
    <url>/2020/02/06/%E6%95%B0%E7%BB%84/</url>
    <content><![CDATA[<h2 id="数组1：-在排序数组中查找元素的第一个和最后一个位置"><a href="#数组1：-在排序数组中查找元素的第一个和最后一个位置" class="headerlink" title="数组1： 在排序数组中查找元素的第一个和最后一个位置"></a>数组1： 在排序数组中查找元素的第一个和最后一个位置</h2><h3 id="二分查找临界值"><a href="#二分查找临界值" class="headerlink" title="二分查找临界值"></a>二分查找临界值</h3><p><a href="https://leetcode-cn.com/problems/find-first-and-last-position-of-element-in-sorted-array/" title="https://leetcode-cn.com/problems/find-first-and-last-position-of-element-in-sorted-array/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/find-first-and-last-position-of-element-in-sorted-array/</a></p>
<p>题解：<br><a href="https://leetcode-cn.com/problems/find-first-and-last-position-of-element-in-sorted-array/solution/er-fen-cha-zhao-suan-fa-xi-jie-xiang-jie-by-labula/" title="https://leetcode-cn.com/problems/find-first-and-last-position-of-element-in-sorted-array/solution/er-fen-cha-zhao-suan-fa-xi-jie-xiang-jie-by-labula/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/find-first-and-last-position-of-element-in-sorted-array/solution/er-fen-cha-zhao-suan-fa-xi-jie-xiang-jie-by-labula/</a>  </p>
<pre><code>int binarySearch(int[] nums, int target) {
    int left = 0, right = ...;

    while(...) {
        int mid = (right + left) / 2;
        if (nums[mid] == target) {
            ...
        } else if (nums[mid] &lt; target) {
            left = ...
        } else if (nums[mid] &gt; target) {
            right = ...
        }
    }
    return ...;
}</code></pre><h3 id="查找一个数："><a href="#查找一个数：" class="headerlink" title="查找一个数："></a>查找一个数：</h3><pre><code>int binarySearch(int[] nums, int target) {
    int left = 0; 
    int right = nums.length - 1; // 注意

    while(left &lt;= right) {  //注意
        int mid = (right + left) / 2;
        if(nums[mid] == target)
            return mid; 
        else if (nums[mid] &lt; target)
            left = mid + 1; // 注意
        else if (nums[mid] &gt; target)
            right = mid - 1; // 注意
        }
    return -1;
}</code></pre><h3 id="寻找左侧边界的二分搜索"><a href="#寻找左侧边界的二分搜索" class="headerlink" title="寻找左侧边界的二分搜索"></a>寻找左侧边界的二分搜索</h3><p>直接看代码，其中的标记是需要注意的细节：</p>
<pre><code>int left_bound(int[] nums, int target) {
    if (nums.length == 0) return -1;
    int left = 0;
    int right = nums.length; // 注意

    while (left &lt; right) { // 注意
        int mid = (left + right) / 2;
        if (nums[mid] == target) {
            right = mid;
        } else if (nums[mid] &lt; target) {
            left = mid + 1;
        } else if (nums[mid] &gt; target) {
            right = mid; // 注意
        }
    }
    return left;
}</code></pre><h3 id="寻找右侧边界的二分查找"><a href="#寻找右侧边界的二分查找" class="headerlink" title="寻找右侧边界的二分查找"></a>寻找右侧边界的二分查找</h3><p>寻找右侧边界和寻找左侧边界的代码差不多，只有两处不同，已标注：</p>
<pre><code>int right_bound(int[] nums, int target) {
    if (nums.length == 0) return -1;
    int left = 0, right = nums.length;

    while (left &lt; right) {
        int mid = (left + right) / 2;
        if (nums[mid] == target) {
            left = mid + 1; // 注意
        } else if (nums[mid] &lt; target) {
            left = mid + 1;
        } else if (nums[mid] &gt; target) {
            right = mid;
        }
    }
    return left - 1; // 注意
}</code></pre><h2 id="数组1：下一个排列："><a href="#数组1：下一个排列：" class="headerlink" title="数组1：下一个排列："></a>数组1：下一个排列：</h2><p><a href="https://leetcode-cn.com/problems/next-permutation/" title="https://leetcode-cn.com/problems/next-permutation/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/next-permutation/</a>      </p>
<h3 id="题解1：（先交换后排序）"><a href="#题解1：（先交换后排序）" class="headerlink" title="题解1：（先交换后排序）"></a>题解1：（先交换后排序）</h3><pre><code>public class Solution {
    public void nextPermutation(int[] nums) {
        int i = nums.length - 2;
        while (i &gt;= 0 &amp;&amp; nums[i + 1] &lt;= nums[i]) {
            i--;
        }
        if (i &gt;= 0) {
            int j = nums.length - 1;
            while (j &gt;= 0 &amp;&amp; nums[j] &lt;= nums[i]) {
                j--;
            }
            swap(nums, i, j);
        }
        reverse(nums, i + 1);
    }

    private void reverse(int[] nums, int start) {
        int i = start, j = nums.length - 1;
        while (i &lt; j) {
            swap(nums, i, j);
            i++;
            j--;
        }
    }

    private void swap(int[] nums, int i, int j) {
        int temp = nums[i];
        nums[i] = nums[j];
        nums[j] = temp;
    }
}</code></pre><h3 id="解法2：（先排序后交换）"><a href="#解法2：（先排序后交换）" class="headerlink" title="解法2：（先排序后交换）"></a>解法2：（先排序后交换）</h3><h4 id="排序函数sort参数-nums-i-nums-length-最后一个参数是下标加1"><a href="#排序函数sort参数-nums-i-nums-length-最后一个参数是下标加1" class="headerlink" title="排序函数sort参数(nums,i,nums.length)  最后一个参数是下标加1"></a>排序函数sort参数(nums,i,nums.length)  最后一个参数是下标加1</h4><pre><code>class Solution {
    public void nextPermutation(int[] nums) {
         int len = nums.length;
        for (int i = len - 1; i &gt;= 0; i--) {
            if (i == 0) {
                Arrays.sort(nums);
                return;
            } else {
                if (nums[i] &gt; nums[i - 1]) {
                    Arrays.sort(nums, i, len);
                    for (int j = i; j &lt;len; j++) {
                        if (nums[j] &gt; nums[i - 1]) {
                            int temp = nums[j];
                            nums[j] = nums[i - 1];
                            nums[i - 1] = temp;
                            return;
                        }
                    }
                }
            }
        }
    }
}</code></pre><h2 id="数组2：最大子序和"><a href="#数组2：最大子序和" class="headerlink" title="数组2：最大子序和"></a>数组2：最大子序和</h2><p>给定一个整数数组 nums ，找到一个具有最大和的连续子数组（子数组最少包含一个元素），返回其最大和。<br>输入: [-2,1,-3,4,-1,2,1,-5,4],<br>输出: 6<br>解释: 连续子数组 [4,-1,2,1] 的和最大，为 6。  </p>
<h3 id="解法："><a href="#解法：" class="headerlink" title="解法："></a>解法：</h3><pre><code>class Solution {
    public int maxSubArray(int[] nums) {
        int ans = nums[0];
        int sum = 0;
        for(int num: nums) {
            if(sum &gt; 0) {
                sum += num;
            } else {
                sum = num;
            }
            ans = Math.max(ans, sum);
        }
        return ans;
    }
}</code></pre>]]></content>
  </entry>
  <entry>
    <title></title>
    <url>/2020/01/09/leetcode%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<h1 id="双指针"><a href="#双指针" class="headerlink" title="双指针"></a>双指针</h1><h2 id="1、三数之和"><a href="#1、三数之和" class="headerlink" title="1、三数之和"></a>1、三数之和</h2><p><a href="https://leetcode-cn.com/problems/3sum/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/3sum/</a><br>给定一个包含 n 个整数的数组 nums，判断 nums 中是否存在三个元素 a，b，c ，使得 a + b + c = 0 ？找出所有满足条件且不重复的三元组。<br>注意：答案中不可以包含重复的三元组。  </p>
<h3 id="解决方案：排序加双指针"><a href="#解决方案：排序加双指针" class="headerlink" title="解决方案：排序加双指针"></a>解决方案：排序加双指针</h3><p> List<string> strings = new ArrayList<string>(asList(“foo”, “bar”, “baz”)) </string></string></p>
<h3 id="解题思路："><a href="#解题思路：" class="headerlink" title="解题思路："></a>解题思路：</h3><p>暴力法搜索为 O(N^3)时间复杂度，可通过双指针动态消去无效解来优化效率。  </p>
<p>双指针法铺垫： 先将给定 nums 排序，复杂度为 O(NlogN)。 </p>
<h4 id="双指针法思路："><a href="#双指针法思路：" class="headerlink" title="双指针法思路："></a>双指针法思路：</h4><p>固定 3 个指针中最左（最小）数字的指针 k，双指针 i，j 分设在数组索引 (k, len(nums))(k,len(nums)) 两端，通过双指针交替向中间移动，记录对于每个固定指针 k 的所有满足 nums[k] + nums[i] + nums[j] == 0 的 i,j 组合：  </p>
<ul>
<li>当 nums[k] &gt; 0 时直接break跳出：因为 nums[j] &gt;= nums[i] &gt;= nums[k] &gt; 0，即 33 个数字都大于 00 ，在此固定指针 k 之后不可能再找到结果了。  </li>
<li>当 k &gt; 0且nums[k] == nums[k 1]时即跳过此元素nums[k]：因为已经将 nums[k 1] 的所有组合加入到结果中，本次双指针搜索只会得到重复组合。  </li>
<li>i，j 分设在数组索引 (k, len(nums))(k,len(nums)) 两端，当i &lt; j时循环计算s = nums[k] + nums[i] + nums[j]，并按照以下规则执行双指针移动：<br>  当s &lt; 0时，i += 1并跳过所有重复的nums[i]；<br>  当s &gt; 0时，j -= 1并跳过所有重复的nums[j]；<br>  当s == 0时，记录组合[k, i, j]至res，执行i += 1和j -= 1并跳过所有重复的nums[i]和nums[j]，防止记录到重复组合。  </li>
</ul>
<h4 id="复杂度分析："><a href="#复杂度分析：" class="headerlink" title="复杂度分析："></a>复杂度分析：</h4><p>时间复杂度 O(N^2)：其中固定指针k循环复杂度 O(N)，双指针 i，j 复杂度 O(N)。<br>空间复杂度 O(1)：指针使用常数大小的额外空间。</p>
<h4 id="解法："><a href="#解法：" class="headerlink" title="解法："></a>解法：</h4><pre><code>class Solution {
    public List&lt;List&lt;Integer&gt;&gt; threeSum(int[] nums) {
        Arrays.sort(nums);
        List&lt;List&lt;Integer&gt;&gt; res = new ArrayList&lt;&gt;();
        for(int k = 0; k &lt; nums.length - 2; k++){
            if(nums[k] &gt; 0) break;
            if(k &gt; 0 &amp;&amp; nums[k] == nums[k - 1]) continue;
            int i = k + 1, j = nums.length - 1;
            while(i &lt; j){
                int sum = nums[k] + nums[i] + nums[j];
                if(sum &lt; 0){
                    while(i &lt; j &amp;&amp; nums[i] == nums[++i]);
                } else if (sum &gt; 0) {
                    while(i &lt; j &amp;&amp; nums[j] == nums[--j]);
                } else {
                    res.add(new ArrayList&lt;Integer&gt;(Arrays.asList(nums[k], nums[i], nums[j])));
                    while(i &lt; j &amp;&amp; nums[i] == nums[++i]);
                    while(i &lt; j &amp;&amp; nums[j] == nums[--j]);
                }
            }
        }
        return res;
    }
}</code></pre><h2 id="2、最接近的三数之和"><a href="#2、最接近的三数之和" class="headerlink" title="2、最接近的三数之和"></a>2、最接近的三数之和</h2><p><a href="https://leetcode-cn.com/problems/3sum-closest/" title="https://leetcode-cn.com/problems/3sum-closest/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/3sum-closest/</a></p>
<h3 id="思路："><a href="#思路：" class="headerlink" title="思路："></a>思路：</h3><p>标签：排序和双指针<br>本题目因为要计算三个数，如果靠暴力枚举的话时间复杂度会到 O(n^3)，需要降低时间复杂度<br>首先进行数组排序，时间复杂度 O(nlogn)<br>在数组 nums 中，进行遍历，每遍历一个值利用其下标i，形成一个固定值 nums[i]<br>再使用前指针指向 start = i + 1 处，后指针指向 end = nums.length - 1 处，也就是结尾处<br>根据 sum = nums[i] + nums[start] + nums[end] 的结果，判断 sum 与目标 target 的距离，如果更近则更新结果 ans<br>同时判断 sum 与 target 的大小关系，因为数组有序，如果 sum &gt; target 则 end–，如果 sum &lt; target 则 start++，如果 sum == target 则说明距离为 0 直接返回结果<br>整个遍历过程，固定值为 n 次，双指针为 n 次，时间复杂度为 O(n^2)<br>总时间复杂度：O(nlogn) + O(n^2) = O(n^2)  </p>
<h3 id="题解："><a href="#题解：" class="headerlink" title="题解："></a>题解：</h3><pre><code>class Solution {
    public int threeSumClosest(int[] nums, int target) {
        Arrays.sort(nums);
        int ans = nums[0] + nums[1] + nums[2]; //不能改Integer.MAX_VALUE,会溢出
        for(int i=0;i&lt;nums.length;i++) {
            int start = i+1, end = nums.length - 1;
            while(start &lt; end) {
                int sum = nums[start] + nums[end] + nums[i];
                if(Math.abs(target - sum) &lt; Math.abs(target - ans))
                    ans = sum;
                if(sum &gt; target)
                    end--;
                else if(sum &lt; target)
                    start++;
                else
                    return ans;
            }
        }
        return ans;
    }
}</code></pre><h2 id="3、盛水最多的容器"><a href="#3、盛水最多的容器" class="headerlink" title="3、盛水最多的容器"></a>3、盛水最多的容器</h2><h3 id="解决：双指针（前后同时向内移动）"><a href="#解决：双指针（前后同时向内移动）" class="headerlink" title="解决：双指针（前后同时向内移动）"></a>解决：双指针（前后同时向内移动）</h3><h4 id="解法：-1"><a href="#解法：-1" class="headerlink" title="解法："></a>解法：</h4><pre><code>class Solution {
    public int maxArea(int[] height) {
        int res=0;
        int leftpoint=0;
        int rightpoint=height.length-1;
        while(rightpoint&gt;leftpoint){
            res=Math.max(res,(rightpoint-leftpoint)*Math.min(height[rightpoint],height[leftpoint]));
            if(height[rightpoint]&lt;height[leftpoint]){
                rightpoint--;
            }
            else{
                leftpoint++;
            }
        }
        return res;
    }

}</code></pre><h2 id="爬楼梯："><a href="#爬楼梯：" class="headerlink" title="爬楼梯："></a>爬楼梯：</h2><p><a href="https://leetcode-cn.com/problems/climbing-stairs/?utm_source=LCUS&utm_medium=ip_redirect_q_uns&utm_campaign=transfer2china" target="_blank" rel="noopener">https://leetcode-cn.com/problems/climbing-stairs/?utm_source=LCUS&amp;utm_medium=ip_redirect_q_uns&amp;utm_campaign=transfer2china</a><br>假设你正在爬楼梯。需要 n 阶你才能到达楼顶。<br>每次你可以爬 1 或 2 个台阶。你有多少种不同的方法可以爬到楼顶呢？  </p>
<h3 id="题解：-利用数学规律：f-n-f-n-1-f-n-2-，使用数组组个计算，一次循环完成，时间复杂度为O-n-。-斐波那契问题-动态规划"><a href="#题解：-利用数学规律：f-n-f-n-1-f-n-2-，使用数组组个计算，一次循环完成，时间复杂度为O-n-。-斐波那契问题-动态规划" class="headerlink" title="题解： 利用数学规律：f[n]=f[n-1]+f[n-2]，使用数组组个计算，一次循环完成，时间复杂度为O(n)。  斐波那契问题  动态规划"></a>题解： 利用数学规律：f[n]=f[n-1]+f[n-2]，使用数组组个计算，一次循环完成，时间复杂度为O(n)。  斐波那契问题  动态规划</h3><h4 id="解法：-2"><a href="#解法：-2" class="headerlink" title="解法："></a>解法：</h4><pre><code>class Solution {
    public int climbStairs(int n) {
        int f1=1,f2=2;
        int fn =0;
        if(n==1)return 1;
        if(n==2)return 2;
        for(int i=3; i&lt;=n;i++){
            fn=f1+f2;
            f1=f2;
            f2=fn;
        }
        return fn;
    }
}</code></pre><h2 id="反转链表"><a href="#反转链表" class="headerlink" title="反转链表"></a>反转链表</h2><h3 id="题解：迭代"><a href="#题解：迭代" class="headerlink" title="题解：迭代"></a>题解：迭代</h3><h4 id="解法1："><a href="#解法1：" class="headerlink" title="解法1："></a>解法1：</h4><pre><code>public ListNode reverseList(ListNode head) {
    ListNode prev = null;
    ListNode curr = head;
    while (curr != null) {
        ListNode nextTemp = curr.next;
        curr.next = prev;
        prev = curr;
        curr = nextTemp;
    }
    return prev;
}</code></pre><h3 id="解法2：递归（假设后面的已经全部反转）"><a href="#解法2：递归（假设后面的已经全部反转）" class="headerlink" title="解法2：递归（假设后面的已经全部反转）"></a>解法2：递归（假设后面的已经全部反转）</h3><pre><code>public ListNode reverseList(ListNode head) {
    if (head == null || head.next == null) return head;
    ListNode p = reverseList(head.next);
    head.next.next = head;
    head.next = null;
    return p;
}</code></pre>]]></content>
  </entry>
  <entry>
    <title></title>
    <url>/2020/01/01/ES%20reindex/</url>
    <content><![CDATA[<h2 id="重建索引"><a href="#重建索引" class="headerlink" title="重建索引"></a><a href="https://juejin.im/post/5afa6634518825673e35c5a5" target="_blank" rel="noopener">重建索引</a></h2><pre><code>PUT /url-content/_alias/update_index   //为索引创建别名  



GET /update_index/_search
{
  &quot;query&quot;: {
    &quot;match_all&quot;: {}
  }
}




PUT /content_index_new    //好像不太对

{
 &quot;settings&quot;: {
     &quot;number_of_shards&quot;: 10,
     &quot;number_of_replicas&quot;: 0
 },
 &quot;mappings&quot;: {
     &quot;properties&quot;: {
         &quot;mainurl&quot;: {
            &quot;type&quot;: &quot;keyword&quot;
         },
         &quot;content&quot;: {&quot;type&quot;: &quot;text&quot;,
          &quot;analyzer&quot;: &quot;ik_max_word&quot;,
          &quot;search_analyzer&quot;: &quot;ik_smart&quot;
         },
         &quot;keyword&quot;: {&quot;type&quot;: &quot;text&quot;}

     }
 }
}</code></pre><h2 id="reindex语句"><a href="#reindex语句" class="headerlink" title="reindex语句"></a>reindex语句</h2><pre><code>POST _reindex?wait_for_completion=false   //解决数据过大超时
{
  &quot;source&quot;: {
    &quot;index&quot;: &quot;main-contents&quot;
  },
  &quot;dest&quot;: {
    &quot;index&quot;: &quot;main-contents-new&quot;
  }

}</code></pre>]]></content>
  </entry>
  <entry>
    <title>Mysql学习-1（架构、日志、事务、索引）</title>
    <url>/2019/12/24/Mysql%E5%AD%A6%E4%B9%A0-1%EF%BC%88%E6%9E%B6%E6%9E%84%E3%80%81%E6%97%A5%E5%BF%97%E3%80%81%E4%BA%8B%E5%8A%A1%E3%80%81%E7%B4%A2%E5%BC%95%EF%BC%89/</url>
    <content><![CDATA[<h1 id="一、SQL语句执行-基本架构"><a href="#一、SQL语句执行-基本架构" class="headerlink" title="一、SQL语句执行 基本架构"></a>一、SQL语句执行 基本架构</h1><h3 id="MVCC—-多版本并发控制"><a href="#MVCC—-多版本并发控制" class="headerlink" title="MVCC—-多版本并发控制"></a>MVCC—-多版本并发控制</h3><h3 id="当前读和一致性读"><a href="#当前读和一致性读" class="headerlink" title="当前读和一致性读"></a>当前读和一致性读</h3><p>慢查询日志 slow log—可以查到扫描行数</p>
<p><span style="color:red;">Server层+存储引擎层</span><br><span style="color:red;">Server层：连接器、查询缓存、分析器、优化器、执行器等  以及内置函数，所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。</span><br>存储引擎层：数据的存储和提取，架构模式是插件式的。支持InnoDB、MyISAM、Memory等多个存储引擎。  engine=memory<br>不同的存储引擎共用一个Server层   </p>
<p>连接器：负责和客户端建立连接、获取权限、维持和管理连接<br>长连接可能导致内存占用过大  </p>
<p>查询缓存：mysql拿到查询请求后会先查看查询缓存，如果语句不在查询缓存中会继续后面的执行阶段，执行结果会存入查询缓存中。<br>建议不要使用查询缓存，mysql8.0开始没有查询缓存功能。 在一个表上有更新的时候，跟这个表有关的查询缓存会失效。   </p>
<p>分析器：词法分析+语法分析  </p>
<p>优化器：在表里有多个索引的时候，决定使用哪个索引；或者在一个语句有多表关联的时候，决定各表的连接顺序。  </p>
<p>执行器：开始执行的时候，要先判断一下对这个表有没有执行查询的权限，如果有，继续执行。使用引擎提供的接口。   </p>
<h1 id="二、日志"><a href="#二、日志" class="headerlink" title="二、日志"></a>二、日志</h1><h2 id="WAL-技术"><a href="#WAL-技术" class="headerlink" title="WAL 技术"></a>WAL 技术</h2><p>WAL 的全称是 Write-Ahead Logging，它的关键点就是先写日志，再写磁盘。  </p>
<p>日志模块：redo log（重做日志）和binlog（归档日志）先写日志，再写磁盘。<br>语句更新会生成undo log（回滚日志）   </p>
<h2 id="redo-log（crash-safe能力）InnoDB特有"><a href="#redo-log（crash-safe能力）InnoDB特有" class="headerlink" title="redo log（crash-safe能力）InnoDB特有"></a>redo log（crash-safe能力）InnoDB特有</h2><p>当有一条记录需要更新的时候，InnoDB引擎会先把记录写到redo log中，并更新缓存，会在适当时候更新磁盘。<br>InnoDB的redo log大小固定，从头写到末尾。write pos当前记录位置，checkpoint当前擦出位置。往后推移并循环，擦除记录前要把记录更新到数据文件。  </p>
<h2 id="binlog"><a href="#binlog" class="headerlink" title="binlog"></a>binlog</h2><p>Server层日志，没有crash-safe能力。binlog 没有能力恢复“数据页”    </p>
<h2 id="区别："><a href="#区别：" class="headerlink" title="区别："></a>区别：</h2><p>redo log是InnoDB特有，binlog在Mysql的server层实现，所有引擎都可以使用；<br>redo log是物理日志，记录的是“在摸个数据页上做了什么修改”，binlog是逻辑日志，记录的是语句的原始逻辑，比如“给ID=2这一行的c字段加一”；<br>redo log循环写，空间固定会用完；binlog是可以追加写入，写到一定大小会切换到下一个，不会覆盖。  </p>
<h2 id="执行update流程："><a href="#执行update流程：" class="headerlink" title="执行update流程："></a>执行update流程：</h2><ol>
<li>执行器先找引擎取 ID=2 这一行。ID 是主键，引擎直接用树搜索找到这一行。如果ID=2 这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。  </li>
<li>执行器拿到引擎给的行数据，把这个值加上 1，比如原来是 N，现在就是 N+1，得到新的一行数据，再调用引擎接口写入这行新数据。</li>
<li>引擎将这行新数据更新到内存中，同时将这个更新操作记录到 redo log 里面，此时redo log 处于 prepare 状态。然后告知执行器执行完成了，随时可以提交事务。  </li>
<li>执行器生成这个操作的 binlog，并把 binlog 写入磁盘。  </li>
<li>执行器调用引擎的提交事务接口，引擎把刚刚写入的 redo log 改成提交（commit）状态，更新完成。  </li>
</ol>
<p>redo log拆成prepare和commit，<span style="color:red;">两阶段提交</span>，保证日志恢复出来的库的状态和原库一致。   </p>
<h2 id="两阶段提交时Mysql异常重启后事务情况："><a href="#两阶段提交时Mysql异常重启后事务情况：" class="headerlink" title="两阶段提交时Mysql异常重启后事务情况："></a>两阶段提交时Mysql异常重启后事务情况：</h2><h3 id="崩溃恢复时的判断规则："><a href="#崩溃恢复时的判断规则：" class="headerlink" title="崩溃恢复时的判断规则："></a>崩溃恢复时的判断规则：</h3><pre><code>1. 如果 redo log 里面的事务是完整的，也就是已经有了 commit 标识，则直接提交；
2. 如果 redo log 里面的事务只有完整的 prepare，则判断对应的事务 binlog 是否存在并完整：（一个事务的 binlog 是有完整格式的）
    a. 如果是，则提交事务；
    b. 否则，回滚事务。  </code></pre><p>对于 InnoDB 引擎来说，如果 redo log 提交完成了，事务就不能回滚（如果这还允许回滚，就可能覆盖掉别的事务的更新）。而如果 redo log 直接提交，然后 binlog 写入的时候失败，InnoDB 又回滚不了，数据和 binlog 日志又不一致了。  </p>
<p>让数据库恢复到半个月内任意一秒的状态：找到全量备份，从备份的时间点开始取出binlog  </p>
<p>redo log 用于保证 <span style="color:red;">crash-safe</span> 能力。innodb_flush_log_at_trx_commit 这个参数设置成1 的时候，表示每次事务的 redo log 都直接持久化到磁盘。这个参数建议设置成 1，这样可以保证 MySQL 异常重启之后数据不丢失。<br>sync_binlog 这个参数设置成 1 的时候，表示每次事务的 binlog 都持久化到磁盘。这个参数也建议设置成 1，这样可以保证 MySQL 异常重启之后 binlog 不丢失。    </p>
<h3 id="binlog-有着-redo-log-无法替代的功能。"><a href="#binlog-有着-redo-log-无法替代的功能。" class="headerlink" title="binlog 有着 redo log 无法替代的功能。"></a>binlog 有着 redo log 无法替代的功能。</h3><pre><code>一个是归档。redo log 是循环写，写到末尾是要回到开头继续写的。这样历史日志没法保留，redo log 也就起不到归档的作用。
一个就是 MySQL 系统依赖于 binlog。binlog 作为 MySQL 一开始就有的功能，被用在了很多地方。其中，MySQL 系统高可用的基础，就是 binlog 复制。
还有很多公司有异构系统（比如一些数据分析系统），这些系统就靠消费 MySQL 的binlog 来更新自己的数据。关掉 binlog 的话，这些下游系统就没法输入了。   </code></pre><h3 id="正常运行中的实例，数据写入后的最终落盘，是从-redo-log-更新过来的还是从-buffer-pool-更新过来的？"><a href="#正常运行中的实例，数据写入后的最终落盘，是从-redo-log-更新过来的还是从-buffer-pool-更新过来的？" class="headerlink" title="正常运行中的实例，数据写入后的最终落盘，是从 redo log 更新过来的还是从 buffer pool 更新过来的？"></a>正常运行中的实例，数据写入后的最终落盘，是从 redo log 更新过来的还是从 buffer pool 更新过来的？</h3><p>实际上，redo log 并没有记录数据页的完整数据，所以它并没有能力自己去更新磁盘数据<br>页，也就不存在“数据最终落盘，是由 redo log 更新过去”的情况。</p>
<ol>
<li>如果是正常运行的实例的话，数据页被修改以后，跟磁盘的数据页不一致，称为脏页。最终数据落盘，就是把内存中的数据页写盘。这个过程，甚至与 redo log 毫无关系。  </li>
<li>在崩溃恢复场景中，InnoDB 如果判断到一个数据页可能在崩溃恢复的时候丢失了更新，就会将它读到内存，然后让 redo log 更新内存内容。更新完成后，内存页变成脏页，就回到了第一种情况的状态。  </li>
</ol>
<h1 id="三、事务隔离"><a href="#三、事务隔离" class="headerlink" title="三、事务隔离"></a>三、事务隔离</h1><h2 id="可重复读是InnoDB默认的隔离级别"><a href="#可重复读是InnoDB默认的隔离级别" class="headerlink" title="可重复读是InnoDB默认的隔离级别"></a><span style="color:red;">可重复读是InnoDB默认的隔离级别</span></h2><h3 id="ACID（Atomicity、Consistency、Isolation、Durability，即原子性、一致性、隔离性、持久性）"><a href="#ACID（Atomicity、Consistency、Isolation、Durability，即原子性、一致性、隔离性、持久性）" class="headerlink" title="ACID（Atomicity、Consistency、Isolation、Durability，即原子性、一致性、隔离性、持久性）"></a>ACID（Atomicity、Consistency、Isolation、Durability，即原子性、一致性、隔离性、持久性）</h3><h3 id="脏读（dirty-read）、不可重复读（non-repeatable-read）、幻读（phantom-read）"><a href="#脏读（dirty-read）、不可重复读（non-repeatable-read）、幻读（phantom-read）" class="headerlink" title="脏读（dirty read）、不可重复读（non-repeatable read）、幻读（phantom read）"></a>脏读（dirty read）、不可重复读（non-repeatable read）、幻读（phantom read）</h3><h2 id="SQL标准的事务隔离级别："><a href="#SQL标准的事务隔离级别：" class="headerlink" title="SQL标准的事务隔离级别："></a>SQL标准的事务隔离级别：</h2><p>读未提交是指，一个事务还没提交时，它做的变更就能被别的事务看到。<br>读提交是指，一个事务提交之后，它做的变更才会被其他事务看到。<br>可重复读是指，一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。<br>串行化，顾名思义是对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当<br>出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。  </p>
<p>视图概念<br>将启动参数 transaction-isolation 的值设置成 READ-COMMITTED   </p>
<h2 id="Mysql的事务启动方式："><a href="#Mysql的事务启动方式：" class="headerlink" title="Mysql的事务启动方式："></a>Mysql的事务启动方式：</h2><ol>
<li>显式启动事务语句， begin 或 start transaction。配套的提交语句是 commit，回滚语句是 rollback。   </li>
<li>set autocommit=0，这个命令会将这个线程的自动提交关掉。意味着如果你只执行一个 select 语句，这个事务就启动了，而且并不会自动提交。这个事务持续存在直到你主动执行 commit 或 rollback 语句，或者断开连接。<br>有些客户端连接框架会默认连接成功后先执行一个 set autocommit=0 的命令。这就导致接下来的查询都在事务中，如果是长连接，就导致了意外的长事务。<br>建议总是使用 set autocommit=1, 通过显式语句的方式来启动事务。  ？？？？？？？存疑<br>在 autocommit 为 1 的情况下，用 begin 显式启动的事务，如果执行 commit 则提交事务。如果执行 commit work and chain，则是提交事务并自动启动下一个事务，这样也省去了再次执行 begin 语句的开销。同时带来的好处是从程序开发的角度明确地知道每个语句是否处于事务中。   </li>
</ol>
<h1 id="四、索引"><a href="#四、索引" class="headerlink" title="四、索引"></a>四、索引</h1><p>提高数据的查询效率  </p>
<h2 id="常见模型：哈希表、有序数组和搜索树。"><a href="#常见模型：哈希表、有序数组和搜索树。" class="headerlink" title="常见模型：哈希表、有序数组和搜索树。"></a>常见模型：哈希表、有序数组和搜索树。</h2><p>哈希表适用于只有等值查询的场景；<br>有序数组在等值查询和范围查询场景性能都可以，但只适应于静态存储引擎；<br>平衡二叉树：搜索时间复杂度O(log(n)),更新的时间复杂度 O(log(n))   </p>
<h3 id="InnoDB使用B-树模型，减少单次查询的磁盘访问次数。"><a href="#InnoDB使用B-树模型，减少单次查询的磁盘访问次数。" class="headerlink" title="InnoDB使用B+树模型，减少单次查询的磁盘访问次数。"></a>InnoDB使用B+树模型，减少单次查询的磁盘访问次数。</h3><p>主键索引和非主键索引<br><span style="color:red;"><br>主键索引的叶子节点存的是整行数据。在 InnoDB 里，主键索引也被称为聚簇索引（clustered index）。<br>非主键索引的叶子节点内容是主键的值。在 InnoDB 里，非主键索引也被称为二级索引（secondary index）。<br></span>    </p>
<h3 id="索引维护："><a href="#索引维护：" class="headerlink" title="索引维护："></a>索引维护：</h3><p>新插入数据记录。索引需要移动甚至会页分裂，页合并<br>自增主键：<br>覆盖索引：查询不需要回表，减少树的搜索次数，性能优化手段。<br>前缀索引：</p>
<h3 id="联合索引：安排索引内的字段顺序"><a href="#联合索引：安排索引内的字段顺序" class="headerlink" title="联合索引：安排索引内的字段顺序"></a>联合索引：安排索引内的字段顺序</h3><p>第一原则是，如果通过调整顺序，可以少维护一个索引，那么这个顺序往往就是需要优先考虑采用的。<br>索引下推优化    </p>
<h1 id="五、全局锁、表锁、行锁"><a href="#五、全局锁、表锁、行锁" class="headerlink" title="五、全局锁、表锁、行锁"></a>五、全局锁、表锁、行锁</h1><h2 id="1、全局锁"><a href="#1、全局锁" class="headerlink" title="1、全局锁"></a>1、全局锁</h2><p>全局锁的典型使用场景是，做全库逻辑备份。<br>全局锁主要用在逻辑备份过程中。对于全部是 InnoDB 引擎的库，建议选择使用–<br>single-transaction 参数，对应用会更友好。   </p>
<h2 id="2、表级锁"><a href="#2、表级锁" class="headerlink" title="2、表级锁"></a>2、表级锁</h2><p>表级锁：表锁、元数据锁（MDL）  </p>
<h3 id="1）表锁"><a href="#1）表锁" class="headerlink" title="1）表锁"></a>1）表锁</h3><p>表锁的语法：lock tables…read/write<br>表锁一般是在数据库引擎不支持行锁的时候才会被用到的。如果你发现你的应用程序里有lock tables 这样的语句，你需要追查一下，比较可能的情况是：<br>要么是你的系统现在还在用 MyISAM 这类不支持事务的引擎，那要安排升级换引擎；<br>要么是你的引擎升级了，但是代码还没升级。这样的情况，最后业务开发就是把<br>lock tables 和 unlock tables 改成 begin 和 commit，问题就解决了。   </p>
<h3 id="2）元数据锁"><a href="#2）元数据锁" class="headerlink" title="2）元数据锁"></a>2）元数据锁</h3><p>MDL 不需要显式只用，在访问一个表的时候会被自动加上，保证读写的正确性。<br>因此，在 MySQL 5.5 版本中引入了 MDL，当对一个表做增删改查操作的时候，加 MDL读锁；当要对表做结构变更操作的时候，加 MDL 写锁。<br>MDL会直到事务提交才释放，在做表结构变更的时候，你一定要小心不要导致锁住线上查询和更新。   </p>
<h2 id="3、行锁"><a href="#3、行锁" class="headerlink" title="3、行锁"></a>3、行锁</h2><h3 id="引擎层由各个引擎自己实现，不是所有引擎都支持。InnoDB支持。"><a href="#引擎层由各个引擎自己实现，不是所有引擎都支持。InnoDB支持。" class="headerlink" title="引擎层由各个引擎自己实现，不是所有引擎都支持。InnoDB支持。"></a>引擎层由各个引擎自己实现，不是所有引擎都支持。InnoDB支持。</h3><p><span style="color:red;">在 InnoDB 事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议。 </span>     </p>
<p>如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。<br>但是，调整语句顺序并不能完全避免死锁。引入了死锁和死锁检测的概念，以及提供了三个方案，来减少死锁对数据库的影响。减少死锁的主要方向，就是控制访问相同资源的并发事务量。    </p>
<h3 id="死锁：事务A等待事务B释放行锁，事务B等待事务A释放行锁。"><a href="#死锁：事务A等待事务B释放行锁，事务B等待事务A释放行锁。" class="headerlink" title="死锁：事务A等待事务B释放行锁，事务B等待事务A释放行锁。"></a>死锁：事务A等待事务B释放行锁，事务B等待事务A释放行锁。</h3><h3 id="解决策略："><a href="#解决策略：" class="headerlink" title="解决策略："></a>解决策略：</h3><ul>
<li>直接进入等待，直至超时。这个超时时间可以通过参数innodb_lock_wait_timeout 来设置。 InnoDB默认50s，过于长；    </li>
<li>发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 innodb_deadlock_detect 设置为 on，表示开启这个逻辑。InnoDB默认值为0。  <h3 id="但死锁检测存在问题：并发量大导致CPU资源耗费。"><a href="#但死锁检测存在问题：并发量大导致CPU资源耗费。" class="headerlink" title="但死锁检测存在问题：并发量大导致CPU资源耗费。"></a>但死锁检测存在问题：并发量大导致CPU资源耗费。</h3><h3 id="解决由这种热点行更新导致的性能问题："><a href="#解决由这种热点行更新导致的性能问题：" class="headerlink" title="解决由这种热点行更新导致的性能问题："></a>解决由这种热点行更新导致的性能问题：</h3>一种头痛医头的方法，就是如果你能确保这个业务一定不会出现死锁，可以临时把死锁检测关掉；另一个思路是控制并发度，并发控制做在数据库服务端，可以考虑在中间件实现，或在Mysql里面，基本思路是，对于相同行的更新，在进入引擎之前排队。<br>或者，可以考虑通过将一行改成逻辑上的多行来减少锁冲突。  </li>
</ul>
<h1 id="六、事务隔离"><a href="#六、事务隔离" class="headerlink" title="六、事务隔离"></a>六、事务隔离</h1><p>一个数据版本，对于一个事务视图来说，除了自己的更新总是可见以外，有三种情况：   </p>
<ol>
<li>版本未提交，不可见；  </li>
<li>版本已提交，但是是在视图创建后提交的，不可见；  </li>
<li>版本已提交，而且是在视图创建前提交的，可见。  </li>
</ol>
<p>更新数据都是先读后写的，而这个读，只能读当前的值，称为“当前读”（current read）。  </p>
<p>InnoDB 的行数据有多个版本，每个数据版本有自己的 row trx_id，每个事务或者语句有自己的一致性视图。普通查询语句是一致性读，一致性读会根据 row trx_id 和一致性视图确定数据版本的可见性。<br>对于可重复读，查询只承认在事务启动前就已经提交完成的数据；<br>对于读提交，查询只承认在语句启动前就已经提交完成的数据；<br>而当前读，总是读取已经提交完成的最新版本。   </p>
<h1 id="七、普通索引和唯一索引"><a href="#七、普通索引和唯一索引" class="headerlink" title="七、普通索引和唯一索引"></a>七、普通索引和唯一索引</h1><p>这两类索引在查询能力上是没差别的，主要考虑的是对更新性能的影响。<br>由于唯一索引用不上 change buffer 的优化机制，因此如果业务可以接受，从性能角度出发建议优先考虑非唯一索引。 </p>
<h3 id="1-change-buffer："><a href="#1-change-buffer：" class="headerlink" title="1.change buffer："></a>1.change buffer：</h3><p>当需要更新一个数据页时，如果数据页在内存中就直接更新，而如果这个数据页还没有在内存中的话，在不影响数据一致性的前提下，InooDB 会将这些更新操作缓存在 changebuffer 中，这样就不需要从磁盘中读入这个数据页了。在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行 change buffer 中与这个页有关的操作。通过这种方式就能保证这个数据逻辑的正确性。change buffer会持久化到磁盘。  </p>
<p><span style="color:red;">唯一索引需要首先保证唯一性，因此必须将数据读到内存查看，所以唯一索引的更新就不能使用 change buffer，实际上也只有普通索引可以使用。</span>      </p>
<h3 id="2-merge："><a href="#2-merge：" class="headerlink" title="2.merge："></a>2.merge：</h3><p>将 change buffer 中的操作应用到原数据页。。除了访问这个数据页会触发 merge 外，系统有后台线程会定期 merge。在数据库正常关闭<br>（shutdown）的过程中，也会执行 merge 操作。  </p>
<h3 id="3-change-buffer-的使用场景"><a href="#3-change-buffer-的使用场景" class="headerlink" title="3.change buffer 的使用场景"></a>3.change buffer 的使用场景</h3><p>change buffer 只限于用在普通索引的场景下，而不适用于唯一索引。那么，现在有一个问题就是：普通索引的所有场景，使用 change buffer 都可以起到加速作用吗？  </p>
<p>因为 merge 的时候是真正进行数据更新的时刻，而 change buffer 的主要目的就是将记录的变更动作缓存下来，所以在一个数据页做 merge 之前，change buffer 记录的变更越多（也就是这个页面上要更新的次数越多），收益就越大。  </p>
<p>因此，对于写多读少的业务来说，页面在写完以后马上被访问到的概率比较小，此时<br>change buffer 的使用效果最好。这种业务模型常见的就是账单类、日志类的系统。  </p>
<p>反过来，假设一个业务的更新模式是写入之后马上会做查询，那么即使满足了条件，将更新先记录在 change buffer，但之后由于马上要访问这个数据页，会立即触发 merge 过程。这样随机访问 IO 的次数不会减少，反而增加了 change buffer 的维护代价。所以，对于这种业务模式来说，change buffer 反而起到了副作用。    </p>
<p>如果所有的更新后面，都马上伴随着对这个记录的查询，那么应该关闭 change buffer。而在其他情况下，change buffer 都能提升更新性能。  </p>
<p>在实际使用中，你会发现，普通索引和 change buffer 的配合使用，对于数据量大的表的更新优化还是很明显的。  </p>
<h3 id="4-change-buffer-和-redo-log"><a href="#4-change-buffer-和-redo-log" class="headerlink" title="4.change buffer 和 redo log"></a>4.change buffer 和 redo log</h3><p>简单地对比这两个机制在提升更新性能上的收益的话，redo log 主要节省的是随机写磁盘的 IO 消耗（转成顺序写），而 change buffer 主要节省的则是随机读磁盘<br>的 IO 消耗。</p>
<pre><code>1. Page 1 在内存中，直接更新内存；
2. Page 2 没有在内存中，就在内存的 change buffer 区域，记录下“我要往 Page 2 插入一行”这个信息。
3. 将上述两个动作记入 redo log 中。</code></pre><h1 id="八、MySQL选择索引"><a href="#八、MySQL选择索引" class="headerlink" title="八、MySQL选择索引"></a>八、MySQL选择索引</h1><p>优化器存在选错索引的可能性   </p>
<p>而优化器选择索引的目的，是找到一个最优的执行方案，并用最小的代价去执行语句。在数据库里面，扫描行数是影响执行代价的因素之一。扫描的行数越少，意味着访问磁盘数据的次数越少，消耗的 CPU 资源越少。当然，扫描行数并不是唯一的判断标准，优化器还会结合是否使用临时表、是否排序等因素进行综合判断。  </p>
<p>对于由于索引统计信息不准确导致的问题，可以用 analyze table t（重新统计索引信息） 来解决。<br>而对于其他优化器误判的情况，你可以在应用端用 force index 来强行指定索引，也可以通过修改语句来引导优化器，还可以通过增加或者删除索引来绕过这个问题。   </p>
<h2 id="索引选择异常和处理"><a href="#索引选择异常和处理" class="headerlink" title="索引选择异常和处理"></a>索引选择异常和处理</h2><pre><code>1.采用 force index 强行选择一个索引。  
2.可以考虑修改语句，引导 MySQL 使用期望的索引。  
3.在有些场景下，我们可以新建一个更合适的索引，来提供给优化器做选择，或删掉误用的索引。  </code></pre><h1 id="九、字符串字段加索引"><a href="#九、字符串字段加索引" class="headerlink" title="九、字符串字段加索引"></a>九、字符串字段加索引</h1><h2 id="1-前缀索引"><a href="#1-前缀索引" class="headerlink" title="1.前缀索引"></a>1.前缀索引</h2><p>MySQL 是支持前缀索引的，也就是说，你可以定义字符串的一部分作为索引。 使用前缀索引后，可能会导致查询语句读数据的次数变多。<br>alter table SUser add index index2(email(6));   </p>
<p><span style="color:red;">使用前缀索引，定义好长度，就可以做到既节省空间，又不用额外增加太多的查询成本。</span><br>select count(distinct email) as L from SUser;查看此列有多少个不同的值  </p>
<h2 id="2-前缀索引对覆盖索引的影响"><a href="#2-前缀索引对覆盖索引的影响" class="headerlink" title="2.前缀索引对覆盖索引的影响"></a>2.前缀索引对覆盖索引的影响</h2><p>使用前缀索引就用不上覆盖索引对查询性能的优化了  </p>
<h2 id="3-倒序存储和Hash字段索引："><a href="#3-倒序存储和Hash字段索引：" class="headerlink" title="3.倒序存储和Hash字段索引："></a>3.倒序存储和Hash字段索引：</h2><p>使用倒序存储：身份证索引<br>使用 hash 字段   </p>
<h3 id="相同点："><a href="#相同点：" class="headerlink" title="相同点："></a>相同点：</h3><pre><code>都不支持范围查询，只支持等值查询；   </code></pre><h3 id="区别：-1"><a href="#区别：-1" class="headerlink" title="区别："></a>区别：</h3><pre><code>1. 从占用的额外空间来看，倒序存储方式在主键索引上，不会消耗额外的存储空间，而hash 字段方法需要增加一个字段。当然，倒序存储方式使用 4 个字节的前缀长度应该是不够的，如果再长一点，这个消耗跟额外这个 hash 字段也差不多抵消了。   

2. 在 CPU 消耗方面，倒序方式每次写和读的时候，都需要额外调用一次 reverse 函数，而 hash 字段的方式需要额外调用一次 crc32() 函数。如果只从这两个函数的计算复杂度来看的话，reverse 函数额外消耗的 CPU 资源会更小些。   

3. 从查询效率上看，使用 hash 字段方式的查询性能相对更稳定一些。因为 crc32 算出来的值虽然有冲突的概率，但是概率非常小，可以认为每次查询的平均扫描行数接近 1。而倒序存储方式毕竟还是用的前缀索引的方式，也就是说还是会增加扫描行数。</code></pre><p>总结：<br>    1. 直接创建完整索引，这样可能比较占用空间；<br>    2. 创建前缀索引，节省空间，但会增加查询扫描次数，并且不能使用覆盖索引；<br>    3. 倒序存储，再创建前缀索引，用于绕过字符串本身前缀的区分度不够的问题；<br>    4. 创建 hash 字段索引，查询性能稳定，有额外的存储和计算消耗，跟第三种方式一样，都不支持范围扫描。   </p>
<h1 id="十、SQL语句偶尔变慢的原因"><a href="#十、SQL语句偶尔变慢的原因" class="headerlink" title="十、SQL语句偶尔变慢的原因"></a>十、SQL语句偶尔变慢的原因</h1><p>当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为“脏页”。内存数据<br>写入到磁盘后，内存和磁盘上的数据页的内容就一致了，称为“干净页”。   </p>
<p>MySQL 偶尔“抖”一下的那个瞬间，可能就是在刷脏页（flush）。  </p>
<p>flush场景：  </p>
<pre><code>- InnoDB 的 redo log 写满了。这时候系统会停止所有更新操作，把 checkpoint 往前推进，redo log 留出空间可以继续写。（nnoDB 要尽量避免）   
- 系统内存不足。当需要新的内存页，而内存不够用的时候，就要淘汰一些数据页，空出内存给别的数据页使用。如果淘汰的是“脏页”，就要先将脏页写到磁盘。
- MySQL 认为系统“空闲”的时候。
- MySQL 正常关闭的情况。   </code></pre><p>刷脏页虽然是常态，但是出现以下这两种情况，都是会明显影响性能的：  </p>
<pre><code>1. 一个查询要淘汰的脏页个数太多，会导致查询的响应时间明显变长；
2. 日志写满，更新全部堵住，写性能跌为 0，这种情况对敏感业务来说，是不能接受的。</code></pre><p>所以，InnoDB 需要有控制脏页比例的机制，来尽量避免上面的这两种情况。  </p>
<h2 id="InnoDB-刷脏页的控制策略"><a href="#InnoDB-刷脏页的控制策略" class="headerlink" title="InnoDB 刷脏页的控制策略"></a>InnoDB 刷脏页的控制策略</h2><p>正确地告诉 InnoDB 所在主机的 IO 能力，这样 InnoDB 才能知道需要全力刷脏页的时候，可以刷多快。innodb_io_capacity 这个参数，它会告诉 InnoDB 你的磁盘能力。这个值建议设置成磁盘的 IOPS。  </p>
<h2 id="设计策略控制刷脏页的速度，会参考因素："><a href="#设计策略控制刷脏页的速度，会参考因素：" class="headerlink" title="设计策略控制刷脏页的速度，会参考因素："></a>设计策略控制刷脏页的速度，会参考因素：</h2><p>一个是脏页比例，一个是 redo log 写盘速度。<br>参数 innodb_max_dirty_pages_pct 是脏页比例上限，默认值是 75%。<br>合理地设置 innodb_io_capacity 的值，并且平时要多关注脏页比例，不要让它经常接近 75%。    </p>
<h3 id="找“邻居”"><a href="#找“邻居”" class="headerlink" title="找“邻居”"></a>找“邻居”</h3><p>而 MySQL 中的一个机制，可能让你的查询会更慢：在准备刷一个脏页的时候，如果<br>这个数据页旁边的数据页刚好是脏页，就会把这个“邻居”也带着一起刷掉；而且这个<br>把“邻居”拖下水的逻辑还可以继续蔓延，也就是对于每个邻居数据页，如果跟它相邻的数据页也还是脏页的话，也会被放到一起刷。<br>在 InnoDB 中，innodb_flush_neighbors 参数就是用来控制这个行为的，值为 1 的时候会有上述的“连坐”机制，值为 0 时表示不找邻居，自己刷自己的。  </p>
<h1 id="十一、数据库表的空间回收"><a href="#十一、数据库表的空间回收" class="headerlink" title="十一、数据库表的空间回收"></a>十一、数据库表的空间回收</h1><p>表删掉一半，但表文件大小还是没变<br>InnoDB表包含：表结构定义和数据<br>表数据既可以存在共享表空间里，也可以是单独的文件。由参数innodb_file_per_table 控制，建议设置为单独的文件，便于管理和删除。   </p>
<h2 id="数据删除流程"><a href="#数据删除流程" class="headerlink" title="数据删除流程"></a>数据删除流程</h2><p>数据删除只是删除记录，重新插入的时候可以直接复用这个空间；<br>删除数据页的所有记录，则整个数据页就可以被复用了。当整个页从 B+ 树里面摘掉以后，可以复用到任何位置。 如果相邻的两个数据页利用率都很小，系统就会把这两个页上的数据合到其中一个页上，另外一个数据页就被标记为可复用。    </p>
<p><span style="color:red;">delete 命令其实只是把记录的位置，或者数据页标记为了“可复用”，但磁盘文件的大小是不会变的。也就是说，通过 delete 命令是不能回收表空间的。</span>  </p>
<h3 id="不止是删除数据会造成空洞，插入数据也会。"><a href="#不止是删除数据会造成空洞，插入数据也会。" class="headerlink" title="不止是删除数据会造成空洞，插入数据也会。"></a><span style="color:red;">不止是删除数据会造成空洞，插入数据也会。</span></h3><p>如果数据是按照索引递增顺序插入的，那么索引是紧凑的。但如果数据是随机插入的，就可能造成索引的数据页分裂。  </p>
<h2 id="解决：重建表"><a href="#解决：重建表" class="headerlink" title="解决：重建表"></a>解决：重建表</h2><h3 id="alter-table-A-engine-InnoDB"><a href="#alter-table-A-engine-InnoDB" class="headerlink" title="alter table A engine=InnoDB"></a>alter table A engine=InnoDB</h3><p>MySQL 5.6 版本开始引入的 Online DDL，对这个操作流程做了优化。   </p>
<h3 id="重建表的流程：（重建表过程中允许对表做增删改操作）（Online-DDL）"><a href="#重建表的流程：（重建表过程中允许对表做增删改操作）（Online-DDL）" class="headerlink" title="重建表的流程：（重建表过程中允许对表做增删改操作）（Online DDL）"></a>重建表的流程：（重建表过程中允许对表做增删改操作）（Online DDL）</h3><pre><code>1. 建立一个临时文件，扫描表 A 主键的所有数据页；
2. 用数据页中表 A 的记录生成 B+ 树，存储到临时文件（InnoDB内部创建，需要占用临时空间）中；
3. 生成临时文件的过程中，将所有对 A 的操作记录在一个日志文件（row log）中，对应的是图中 state2 的状态；
4. 临时文件生成后，将日志文件中的操作应用到临时文件，得到一个逻辑数据上与表 A 相同的数据文件，对应的就是图中 state3 的状态；
5. 用临时文件替换表 A 的数据文件。   </code></pre><p>alter 语句在启动的时候需要获取 MDL 写锁，但是这个写锁在真正拷贝数据之前就退化成读锁了。  </p>
<h2 id="Online-和-inplace"><a href="#Online-和-inplace" class="headerlink" title="Online 和 inplace"></a>Online 和 inplace</h2><p>alter table t engine=innodb,ALGORITHM=inplace;   </p>
<pre><code>1. DDL 过程如果是 Online 的，就一定是 inplace 的；
2. 反过来未必，也就是说 inplace 的 DDL，有可能不是 Online 的。截止到 MySQL8.0，添加全文索引（FULLTEXT index）和空间索引 (SPATIAL index) 就属于这种情况。  </code></pre><h3 id="optimize-table、analyze-table-和-alter-table-这三种方式的区别"><a href="#optimize-table、analyze-table-和-alter-table-这三种方式的区别" class="headerlink" title="optimize table、analyze table 和 alter table 这三种方式的区别"></a>optimize table、analyze table 和 alter table 这三种方式的区别</h3><ul>
<li>从 MySQL 5.6 版本开始，alter table t engine = InnoDB（也就是 recreate）默认的就是上面图 4 的流程了；</li>
<li>analyze table t 其实不是重建表，只是对表的索引信息做重新统计，没有修改数据，这个过程中加了 MDL 读锁；</li>
<li>optimize table t 等于 recreate+analyze。    </li>
</ul>
<h1 id="十二、count-命令速度"><a href="#十二、count-命令速度" class="headerlink" title="十二、count(*)命令速度"></a>十二、count(*)命令速度</h1><p>count(*) 的实现方式  </p>
<ul>
<li>MyISAM 引擎把一个表的总行数存在了磁盘上，因此执行 count(*) 的时候会直接返回这个数，效率很高；   </li>
<li>而 InnoDB 引擎就麻烦了，它执行 count(*) 的时候，需要把数据一行一行地从引擎里面读出来，然后累积计数。  </li>
</ul>
<p>InnoDB 是索引组织表，主键索引树的叶子节点是数据，而普通索引树的叶子节点是主键值。所以，普通索引树比主键索引树小很多。   </p>
<p>在保证逻辑正确的前提下，尽量减少扫描的数据量，是数据库系统设计的通用法则之一。  </p>
<ul>
<li>MyISAM 表虽然 count(*) 很快，但是不支持事务；</li>
<li>show table status 命令虽然返回很快，但是不准确；</li>
<li>InnoDB 表直接 count(*) 会遍历全表，虽然结果准确，但会导致性能问题。  </li>
</ul>
<h2 id="解决："><a href="#解决：" class="headerlink" title="解决："></a>解决：</h2><h3 id="1）用缓存系统保存计数"><a href="#1）用缓存系统保存计数" class="headerlink" title="1）用缓存系统保存计数"></a>1）用缓存系统保存计数</h3><p>将计数保存在缓存系统中的方式，还不只是丢失更新的问题。即使 Redis 正常工作，这个值还是逻辑上不精确的。（一致性问题）  </p>
<h3 id="2）在数据库保存计数"><a href="#2）在数据库保存计数" class="headerlink" title="2）在数据库保存计数"></a>2）在数据库保存计数</h3><p>把这个计数直接放到数据库里单独的一张计数表<br>解决了崩溃丢失的问题，InnoDB 是支持崩溃恢复不丢数据的。   </p>
<p>把计数放在 Redis 里面，不能够保证计数和 MySQL 表里的数据精确一致的原因，是这两个不同的存储构成的系统，不支持分布式事务，无法拿到精确一致的视图。而把计数值也放在 MySQL 中，就解决了一致性视图的问题。</p>
<p>按照效率排序的话，count(字段)&lt;count(主键 id)&lt;count(1)≈count(*)  </p>
<h1 id="十三、order-by工作机制"><a href="#十三、order-by工作机制" class="headerlink" title="十三、order by工作机制"></a>十三、order by工作机制</h1><h2 id="全字段排序"><a href="#全字段排序" class="headerlink" title="全字段排序"></a>全字段排序</h2><p>直接把需要展示的字段放到内存中排序后得到结果<br>“按 name 排序”这个动作，可能在内存中完成，也可能需要使用外部排序，这取决于排序所需的内存和参数 sort_buffer_size。<br>sort_buffer_size，就是 MySQL 为排序开辟的内存（sort_buffer）的大小。如果要排序的数据量小于 sort_buffer_size，排序就在内存中完成。但如果排序数据量太大，内存放不下，则不得不利用磁盘临时文件辅助排序。    </p>
<h2 id="rowid排序"><a href="#rowid排序" class="headerlink" title="rowid排序"></a>rowid排序</h2><p>MySQL 认为排序的单行长度太大，会把部分字段放在内存中排序，然后通过主键返回磁盘查询整个字段得到结果。   </p>
<h2 id="全字段排序-VS-rowid-排序"><a href="#全字段排序-VS-rowid-排序" class="headerlink" title="全字段排序 VS rowid 排序"></a>全字段排序 VS rowid 排序</h2><p>如果 MySQL 实在是担心排序内存太小，会影响排序效率，才会采用 rowid 排序算法，这样排序过程中一次可以排序更多行，但是需要再回到原表去取数据。  </p>
<p>如果 MySQL 认为内存足够大，会优先选择全字段排序，把需要的字段都放到sort_buffer中，这样排序后就会直接从内存里面返回查询结果了，不用再回到原表去取数据。<br>这也就体现了 MySQL 的一个设计思想：如果内存够，就要多利用内存，尽量减少磁盘访问。   </p>
<p>对于 InnoDB 表来说，rowid 排序会要求回表多造成磁盘读，因此不会被优先选择。  </p>
<p>覆盖索引是指，索引上的信息足够满足查询请求，不需要再回到主键索引上去取数据。    </p>
<h1 id="十四、正确显示随机消息"><a href="#十四、正确显示随机消息" class="headerlink" title="十四、正确显示随机消息"></a>十四、正确显示随机消息</h1><h2 id="内存临时表"><a href="#内存临时表" class="headerlink" title="内存临时表"></a>内存临时表</h2><p>order by rand() 使用了内存临时表，内存临时表排序的时候使用了 rowid 排序方法。   </p>
<h2 id="磁盘临时表"><a href="#磁盘临时表" class="headerlink" title="磁盘临时表"></a>磁盘临时表</h2><p>tmp_table_size 这个配置限制了内存临时表的大小，默认值是 16M。如果临时表大小超过了 tmp_table_size，那么内存临时表就会转成磁盘临时表。磁盘临时表使用的引擎默认是 InnoDB，是由参数 internal_tmp_disk_storage_engine控制的。<br>当使用磁盘临时表的时候，对应的就是一个没有显式索引的 InnoDB 表的排序过程。   </p>
<h2 id="优先队列排序算法"><a href="#优先队列排序算法" class="headerlink" title="优先队列排序算法"></a>优先队列排序算法</h2><p>不使用临时文件的算法—归并排序算法的原因：归并排序会把所有数据排序（不需要）<br>优先队列算法，就可以精确地只得到三个最小值，执行流程如下：  </p>
<pre><code>1. 对于这 10000 个准备排序的 (R,rowid)，先取前三行，构造成一个堆；
2. 取下一个行 (R’,rowid’)，跟当前堆里面最大的 R 比较，如果 R’小于 R，把这个(R,rowid) 从堆中去掉，换成 (R’,rowid’)；
3. 重复第 2 步，直到第 10000 个 (R’,rowid’) 完成比较。    </code></pre><p>总之，不论是使用哪种类型的临时表，order by rand() 这种写法都会让计算过程非常复杂，需要大量的扫描行数，因此排序过程的资源消耗也会很大。  </p>
<h2 id="随机排序算法"><a href="#随机排序算法" class="headerlink" title="随机排序算法"></a>随机排序算法</h2><p>取 max(id) 和 min(id) 都是不需要扫描索引的，而第三步的select 也可以用索引快速定位  </p>
<p>MySQL 处理 limit Y,1 的做法就是按顺序一个一个地读出来，丢掉前 Y 个，然后把下一个记录作为返回结果，因此这一步需要扫描 Y+1 行。  </p>
<h1 id="十五、相同逻辑的不同SQL语句性能差异"><a href="#十五、相同逻辑的不同SQL语句性能差异" class="headerlink" title="十五、相同逻辑的不同SQL语句性能差异"></a>十五、相同逻辑的不同SQL语句性能差异</h1><h2 id="1-条件字段函数操作"><a href="#1-条件字段函数操作" class="headerlink" title="1.条件字段函数操作"></a>1.条件字段函数操作</h2><p>如果对字段做了函数计算，就用不上索引了，这是 MySQL 的规定。   </p>
<p>对索引字段做函数操作，可能会破坏索引值的有序性，因此优化器就决定放弃走树搜索功能。  </p>
<h2 id="2-隐式类型转换"><a href="#2-隐式类型转换" class="headerlink" title="2.隐式类型转换"></a>2.隐式类型转换</h2><ol>
<li>数据类型转换的规则是什么？<br>在 MySQL 中，字符串和数字做比较的话，是将字符串转换成数字。  </li>
<li>为什么有数据类型转换，就需要走全索引扫描？<br>对索引字段做函数操作，优化器会放弃<br>走树搜索功能。  </li>
</ol>
<h2 id="3-隐式字符编码转换"><a href="#3-隐式字符编码转换" class="headerlink" title="3.隐式字符编码转换"></a>3.隐式字符编码转换</h2><p>两表匹配时要注意字符编码问题，字符集不同则不能用关联字段的索引。<br>连接过程中要求在被驱动表的索引字段上加函数操作，是直接导致对被驱动表做全表扫描的原因。  </p>
<h1 id="十六、“查一行”执行速度慢的原因"><a href="#十六、“查一行”执行速度慢的原因" class="headerlink" title="十六、“查一行”执行速度慢的原因"></a>十六、“查一行”执行速度慢的原因</h1><p>了在一个简单的表上，执行“查一行”，可能会出现的被锁住和执行慢的例子。这其中涉及到了表锁、行锁和一致性读的概念。  </p>
<h2 id="查询长时间不返回"><a href="#查询长时间不返回" class="headerlink" title="查询长时间不返回"></a>查询长时间不返回</h2><p>等MDL锁<br>等flush  </p>
<h2 id="查询慢"><a href="#查询慢" class="headerlink" title="查询慢"></a>查询慢</h2><p>当前读和一致性读区别  </p>
<h1 id="十七、幻读问题"><a href="#十七、幻读问题" class="headerlink" title="十七、幻读问题"></a>十七、幻读问题</h1>]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>study</tag>
      </tags>
  </entry>
  <entry>
    <title>mysql-1</title>
    <url>/2019/12/19/mysql-1/</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title></title>
    <url>/2019/12/19/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/</url>
    <content><![CDATA[<p>##<a href="https://naotu.baidu.com/file/b832f043e2ead159d584cca4efb19703?token=7a6a56eb2630548c" target="_blank" rel="noopener">数据结构脑图</a></p>
<h2 id="算法脑图"><a href="#算法脑图" class="headerlink" title="算法脑图"></a><a href="https://naotu.baidu.com/file/0a53d3a5343bd86375f348b2831d3610?token=5ab1de1c90d5f3ec" target="_blank" rel="noopener">算法脑图</a></h2><pre><code>if后面加空格；  
{前加空格，不要重启一行；  
for while循环后加空格；  
运算符加空格。</code></pre><p>国际站 most votes最高票的三个答案  </p>
<h2 id="数据结构："><a href="#数据结构：" class="headerlink" title="数据结构："></a>数据结构：</h2><h3 id="一维："><a href="#一维：" class="headerlink" title="一维："></a>一维：</h3><p>数组  链表<br>栈  队列  双端队列  集合  映射</p>
<h3 id="二维："><a href="#二维：" class="headerlink" title="二维："></a>二维：</h3><p>树  图<br>二叉搜索树  堆  并查集  字典树</p>
<h3 id="特殊："><a href="#特殊：" class="headerlink" title="特殊："></a>特殊：</h3><p>位运算  布隆过滤器<br>LRU缓存  </p>
<h2 id="算法："><a href="#算法：" class="headerlink" title="算法："></a>算法：</h2><ul>
<li>if-else，switch—-branch    </li>
<li>for，while loop  —–Iteration  </li>
<li>递归Recursion </li>
<li>搜索：深度优先，广度优先，启发式搜索  </li>
<li>动态规划  </li>
<li>二分查找  </li>
<li>贪心算法  </li>
<li>数学、几何    </li>
</ul>
<p>主定理：<br>二分查找  O(log(n))<br>二叉树遍历     O(n)<br>二维数组查找  O(n)<br>归并排序    O(nlogn)<br>深度优先和广度优先都是O(n)<br>二叉树遍历前序中序后序时间复杂度<br>图的搜索复杂度</p>
<p>数组</p>
<p>升维<br>空间换时间<br>跳表  logn时间复杂度</p>
]]></content>
  </entry>
  <entry>
    <title>leetcode题解</title>
    <url>/2019/12/13/leetcode%E9%A2%98%E8%A7%A3/</url>
    <content><![CDATA[<h1 id="leetcode题解"><a href="#leetcode题解" class="headerlink" title="leetcode题解"></a>leetcode题解</h1><h2 id="P1：罗马数字转换（罗马数字转换成数字）"><a href="#P1：罗马数字转换（罗马数字转换成数字）" class="headerlink" title="P1：罗马数字转换（罗马数字转换成数字）"></a>P1：罗马数字转换（罗马数字转换成数字）</h2><p><a href="https://leetcode.com/problems/roman-to-integer/" target="_blank" rel="noopener">https://leetcode.com/problems/roman-to-integer/</a></p>
<p>Roman numerals are represented by seven different symbols: I, V, X, L, C, D and M.</p>
<pre><code>Symbol       Value
I             1
V             5
X             10
L             50
C             100
D             500
M             1000

I can be placed before V (5) and X (10) to make 4 and 9. 
X can be placed before L (50) and C (100) to make 40 and 90. 
C can be placed before D (500) and M (1000) to make 400 and 900.  </code></pre><p>Example 5:      </p>
<pre><code>Input: &quot;MCMXCIV&quot;
Output: 1994
Explanation: M = 1000, CM = 900, XC = 90 and IV = 4.</code></pre><h3 id="题解1：（switch）"><a href="#题解1：（switch）" class="headerlink" title="题解1：（switch）"></a>题解1：（switch）</h3><pre><code>class Solution {
    public int romanToInt(String s) {
        char[] roman = s.toCharArray();
        int number = 0, len = roman.length;

        for(int i = 0; i &lt; len; i++){
            switch(roman[i]){ // Check which roman numeral appears
                case &apos;M&apos;: // if M add 1000
                    number += 1000;
                    break;

                case &apos;D&apos;: // if D add 500
                    number += 500;
                    break;

                case &apos;C&apos;: //If C check if there is an M or D after it
                    if(i != len - 1){ // if no more characters then its 100
                        switch(roman[i + 1]){ //check next character
                            case &apos;M&apos;: // if M then it&apos;s CM so you add 900
                                number += 900;
                                i++; // move your pointer because CM counts as 1
                                break;

                            case &apos;D&apos;: // if D then it&apos;s CD so you add 400
                                number += 400;
                                i++; // move your pointer because CD counts as 1
                                break;

                            default: // if next character is not a D or M then add 100
                                number += 100; 
                                break;
                        }
                    } else{
                        number += 100;
                    }
                    break;

                case &apos;L&apos;: // if L add 50
                    number += 50;
                    break;

                case &apos;X&apos;: //If X check if there is an C or L after it
                    if(i != len - 1){ // if no more characters then its 10
                        switch(roman[i + 1]){ //check next character
                            case &apos;C&apos;:// if C then its XC so you add 90
                                number += 90;
                                i++; // move your pointer because XC counts as 1
                                break;

                            case &apos;L&apos;: // if L then it&apos;s XL so you add 40
                                number += 40;
                                i++; // move your pointer because XL=L counts as 1
                                break;

                            default: //if next character is not a L or C then add 10
                                number += 10;
                                break;
                        }
                    } else{
                        number += 10;
                    }
                    break;

                case &apos;V&apos;: // If V add 5
                    number += 5;
                    break;

                case &apos;I&apos;: //if I check if there is a V or X after it
                    if(i != len - 1){ //If no more characters then its 1
                        switch(roman[i + 1]){ // check next character
                            case &apos;X&apos;: // if X then its IX so you add 9
                                number += 9;
                                i++; // move your pointer because IX counts as 1
                                break;

                            case &apos;V&apos;: // if V then its IV so you add 4
                                number += 4;
                                i++; // move your pointer because IV counts as 1
                                break;

                            default: // if next character is not V or X then add 1
                                number += 1;
                                break;
                        }
                    } else{
                        number += 1;
                    }
                    break;
            }
        }
        return number;
    }
}</code></pre><h3 id="题解2：（Map）"><a href="#题解2：（Map）" class="headerlink" title="题解2：（Map）"></a>题解2：（Map）</h3><pre><code>public int romanToInt(String s) {
        Map&lt;Character,Integer&gt; map = new HashMap();
        map.put(&apos;I&apos;,1);
        map.put(&apos;V&apos;,5);
        map.put(&apos;X&apos;,10);
        map.put(&apos;L&apos;,50);
        map.put(&apos;C&apos;,100);
        map.put(&apos;D&apos;,500);
        map.put(&apos;M&apos;,1000);
        int res = 0;
        for (int i = 0; i &lt; s.length(); i++) {
            if (i == s.length() - 1) {
                res += map.get(s.charAt(i));
                break;
            }
            res += map.get(s.charAt(i)) &lt; map.get(s.charAt(i + 1)) ? -1 * map.get(s.charAt(i)) : map.get(s.charAt(i));
        }
        return res;
    }</code></pre><h2 id="P1：数字转换为罗马"><a href="#P1：数字转换为罗马" class="headerlink" title="P1：数字转换为罗马"></a>P1：数字转换为罗马</h2><p><a href="https://leetcode.com/problems/integer-to-roman/" target="_blank" rel="noopener">https://leetcode.com/problems/integer-to-roman/</a></p>
<h3 id="题解1："><a href="#题解1：" class="headerlink" title="题解1："></a>题解1：</h3><pre><code>class Solution {
    public String intToRoman(int num) {
        StringBuilder result = new StringBuilder();
        int[] div = {1000, 900, 500, 400, 100, 90, 
                     50, 40, 10, 9, 5, 4, 1};
        String[] roman = {&quot;M&quot;, &quot;CM&quot;, &quot;D&quot;, &quot;CD&quot;, &quot;C&quot;, &quot;XC&quot;, 
                          &quot;L&quot;, &quot;XL&quot;, &quot;X&quot;, &quot;IX&quot;, &quot;V&quot;, &quot;IV&quot;, &quot;I&quot;};
        for (int i = 0; i &lt; div.length;) {
            if (num &gt;= div[i]) {
                result.append(roman[i]);
                num -= div[i];
            } else {
                i++;
            }
        }

        return result.toString();
    }
}  </code></pre><h2 id="P2：Count-and-Say"><a href="#P2：Count-and-Say" class="headerlink" title="P2：Count and Say"></a>P2：Count and Say</h2><p><a href="https://leetcode.com/problems/count-and-say/" target="_blank" rel="noopener">https://leetcode.com/problems/count-and-say/</a><br>The count-and-say sequence is the sequence of integers with the first five terms as following:</p>
<pre><code>1.     1
2.     11
3.     21
4.     1211
5.     111221
1 is read off as &quot;one 1&quot; or 11.
11 is read off as &quot;two 1s&quot; or 21.
21 is read off as &quot;one 2, then one 1&quot; or 1211.</code></pre><p>Given an integer n where 1 ≤ n ≤ 30, generate the nth term of the count-and-say sequence. You can do so recursively, in other words from the previous member read off the digits, counting the number of digits in groups of the same digit.   </p>
<p>Example 1:</p>
<pre><code>Input: 1
Output: &quot;1&quot;
Explanation: This is the base case.</code></pre><h3 id="解决1："><a href="#解决1：" class="headerlink" title="解决1："></a>解决1：</h3><pre><code>public class Solution {
    public String countAndSay(int n) {
        String ans = &quot;1&quot;;
        while (--n &gt; 0) {
            StringBuilder sb = new StringBuilder();
            char[] ansChars = ans.toCharArray();
            for (int i = 0; i &lt; ansChars.length; i++) {
                int count = 1;
                while (i + 1 &lt; ansChars.length &amp;&amp; ansChars[i] == ansChars[i + 1]) {
                    i++;count++;
                }
                sb.append(String.valueOf(count) + String.valueOf(ansChars[i]));
            }
            ans = sb.toString();
        }
        return ans;
    }
}</code></pre><h3 id="解决2："><a href="#解决2：" class="headerlink" title="解决2："></a>解决2：</h3><pre><code> public String countAndSay(int n) {
    String result = &quot;1&quot;;

    while (n &gt; 1) {
        result = nextSay(result);
        n--;
    }

    return result;
}

private String nextSay(String input) {
    int windowStart = 0, windowEnd = 0;
    StringBuilder sb = new StringBuilder();

    for(; windowEnd &lt; input.length(); windowEnd++) {

        if (input.charAt(windowStart) != input.charAt(windowEnd)) {

            sb.append(windowEnd - windowStart);
            sb.append(input.charAt(windowStart));

            windowStart = windowEnd;
        }
    }

    sb.append(windowEnd - windowStart);
    sb.append(input.charAt(windowStart));

    return sb.toString();
}  </code></pre><h2 id="P3："><a href="#P3：" class="headerlink" title="P3："></a>P3：</h2><h3 id="二分法查找中位数："><a href="#二分法查找中位数：" class="headerlink" title="二分法查找中位数："></a>二分法查找中位数：</h3><pre><code>public class TestBinarySearch {
    public static void main(String[] args) {
        int[] arr= {30,20,50,10,80,9,7,12,100,40,8};
        Arrays.sort(arr);
        System.out.println(Arrays.toString(arr));
        System.out.println(myBinarySearch(arr,40));
        }

    public static int myBinarySearch(int[] arr,int value) {
        int low=0;
        int high=arr.length-1;
        while(low&lt;=high) {
            int mid=(low+high)/2;
            if(value==arr[mid]) {
                return mid;
                }
            if(value&gt;arr[mid]) {
                low=mid+1;    
            }
            if(value&lt;arr[mid]) {
                high=mid-1;
            }

        }
        return -1;//没有找到返回-1
    }</code></pre><h2 id="P4："><a href="#P4：" class="headerlink" title="P4："></a>P4：</h2><h3 id="题解1：-1"><a href="#题解1：-1" class="headerlink" title="题解1："></a>题解1：</h3><pre><code>class Solution {
    public int[] twoSum(int[] nums, int target) {

        Map&lt;Integer,Integer&gt; map = new HashMap&lt;&gt;();
        for (int i = 0;i&lt;nums.length;i++)
        {
            if(!map.containsKey(nums[i])) map.put(nums[i],i);
            int  b= target - nums[i];
            if(map.containsKey(b)&amp;&amp;map.get(b)!=i){
                return new int[]{map.get(b),i};
            }
        }
        throw new IllegalArgumentException(&quot;a&quot;);
    }
}</code></pre><h3 id="题解2："><a href="#题解2：" class="headerlink" title="题解2："></a>题解2：</h3><pre><code>class Solution {
    public int[] twoSum(int[] nums, int target) {
        HashMap&lt;Integer, Integer&gt; numsMap = new HashMap&lt;&gt;();
        int[] result = new int[2];

        for (int i = 0; i &lt; nums.length; i++) {
            numsMap.put(nums[i], i);    
        }

        int diff;
        for (int i = 0; i &lt; nums.length; i++) {
            diff = target-nums[i];
            if (numsMap.containsKey(diff) &amp;&amp; numsMap.get(diff) != i) {
                result[0] = numsMap.get(diff);
                result[1] = i;
                break;
            }
        }

        return result; 
    }
}</code></pre><h2 id="P5：字符串数组最长子序列"><a href="#P5：字符串数组最长子序列" class="headerlink" title="P5：字符串数组最长子序列"></a>P5：字符串数组最长子序列</h2><h3 id="题解1：-2"><a href="#题解1：-2" class="headerlink" title="题解1："></a>题解1：</h3><pre><code>class Solution {
    public String longestCommonPrefix(String[] strs) {
        int len = strs.length;//数组长度
        if (len == 0) {
            return &quot;&quot;;
        }
        if (len == 1) {
            return strs[0];
        }
        char[] prefix = strs[0].toCharArray(); //数组1转换为字符数组
        int ei = prefix.length - 1;
        for (int i = 1; i &lt; len; i++) {  
            if (ei &lt; 0) {
                return &quot;&quot;;
            }
            char[] next = strs[i].toCharArray();//数组i转换为字符数组
            for (int j = 0; j &lt;= ei; j++) {
                if (j &gt;= next.length) {
                    ei = j - 1;
                    break;
                }
                if (prefix[j] != next[j]) {
                    ei = j - 1;
                    break;
                }
            }
        }
        if (ei &lt; 0) {
            return &quot;&quot;;
        }
        return new String(prefix, 0, ei + 1);
    }
 }</code></pre><h2 id="P6：查找数组最大连续子序列"><a href="#P6：查找数组最大连续子序列" class="headerlink" title="P6：查找数组最大连续子序列"></a>P6：查找数组最大连续子序列</h2><p><a href="https://leetcode.com/problems/maximum-subarray/" target="_blank" rel="noopener">https://leetcode.com/problems/maximum-subarray/</a>  </p>
<h3 id="题解1：-3"><a href="#题解1：-3" class="headerlink" title="题解1："></a>题解1：</h3><p>1)If currentNumber is greater than the current running sum(sumSoFar) then we can drop all the values we have seen before and reset the sumSoFar to currentNumber.<br>2）Check max at each step.  </p>
<pre><code>public int maxSubArray(int[] nums) {
        if(nums==null || nums.length==0) return 0;
        int sumSoFar = 0;
        int max = Integer.MIN_VALUE;
        for(int num:nums){
            sumSoFar+=num;
            if(num&gt;sumSoFar){
                sumSoFar = num;
            }
            max = Math.max(max,sumSoFar);
        }
        return max;
    }</code></pre><h2 id="P7：加一"><a href="#P7：加一" class="headerlink" title="P7：加一"></a>P7：加一</h2><p><a href="https://leetcode.com/problems/plus-one/" target="_blank" rel="noopener">https://leetcode.com/problems/plus-one/</a></p>
<h3 id="题解1：-4"><a href="#题解1：-4" class="headerlink" title="题解1："></a>题解1：</h3><pre><code>public int[] plusOne(int[] digits) {
        if(digits == null || digits.length==0) return digits;
        int carryOver = 0;
        for(int i=digits.length-1; i&gt;=0; i--) {
            int currentNum = digits[i];

            if(currentNum &lt; 9) {
                digits[i] = ++currentNum;
                break;
            } else {
                carryOver = 1;
                digits[i]=0;
                continue;
            }
        }
        if(digits[0]==0 &amp;&amp; carryOver == 1) {
            int[] result = new int[digits.length+1];
            result[0] = 1;
            for(int i=0; i&lt;digits.length; i++) {
                result[i+1] = digits[i];
            }
            digits=result;
        }
        return digits;
    }</code></pre><h2 id="P8-查找短字符串在长字符串中的位置"><a href="#P8-查找短字符串在长字符串中的位置" class="headerlink" title="P8:查找短字符串在长字符串中的位置"></a>P8:查找短字符串在长字符串中的位置</h2><h3 id="解法1："><a href="#解法1：" class="headerlink" title="解法1："></a>解法1：</h3><pre><code>class Solution {
    public int strStr(String haystack, String needle) {
        if(needle.length()&gt;haystack.length())
            return -1;
        if(needle.length()==0)
            return 0;
        try {
            return haystack.indexOf(needle);
        }
        catch (Exception e)
        {
            return -1;
        }
    }
}</code></pre><h3 id="解法2："><a href="#解法2：" class="headerlink" title="解法2："></a>解法2：</h3><pre><code>class Solution {
    public int strStr(String haystack, String needle) {
        if(needle.isEmpty() || haystack.equals(needle)){
            return 0;
        }
        int n = needle.length();
        String str;
        for(int i=0;i&lt;(haystack.length()-n+1);i++){
            str = haystack.substring(i,i+n);
            if(str.equals(needle)){
                return i;
            }
        }
        return -1;
    }
}</code></pre><h2 id="P9：寻找两个有序数组的中位数（二分查找）"><a href="#P9：寻找两个有序数组的中位数（二分查找）" class="headerlink" title="P9：寻找两个有序数组的中位数（二分查找）"></a>P9：寻找两个有序数组的中位数（二分查找）</h2><p><a href="https://leetcode-cn.com/problems/median-of-two-sorted-arrays/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/median-of-two-sorted-arrays/</a></p>
<h3 id="解法1：（二分法）"><a href="#解法1：（二分法）" class="headerlink" title="解法1：（二分法）"></a>解法1：（二分法）</h3><p> /*<br>    * 1.首先，让我们在任一位置 i 将 A(长度为m) 划分成两个部分：<br>    *            leftA            |                rightA<br>    *   A[0],A[1],…      A[i-1] |  A[i],A[i+1],…A[m - 1]<br>    *<br>    * 由于A有m个元素，所以有m + 1中划分方式(i = 0 ~ m)<br>    *<br>    * 我们知道len(leftA) = i, len(rightA) = m - i;<br>    * 注意：当i = 0时，leftA是空集，而当i = m时，rightA为空集。<br>    *<br>    * 2.采用同样的方式，将B也划分为两部分：<br>    *            leftB            |                rightB<br>    *   B[0],B[1],…      B[j-1] |   B[j],B[j+1],…B[n - 1]<br>    *  我们知道len(leftA) = j, len(rightA) = n - j;<br>    *<br>    *  将leftA和leftB放入一个集合，将rightA和rightB放入一个集合。再把这两个集合分别命名为leftPart和rightPart。<br>    *<br>    *            leftPart         |                rightPart<br>    *   A[0],A[1],…      A[i-1] |  A[i],A[i+1],…A[m - 1]<br>    *   B[0],B[1],…      B[j-1] |  B[j],B[j+1],…B[n - 1]<br>    *<br>    *   如果我们可以确认：<br>    *   1.len(leftPart) = len(rightPart); =====&gt; 该条件在m+n为奇数时，该推理不成立<br>    *   2.max(leftPart) &lt;= min(rightPart);<br>    *<br>    *   median = (max(leftPart) + min(rightPart)) / 2;  目标结果<br>    *<br>    *   要确保这两个条件满足：<br>    *   1.i + j = m - i + n - j(或m - i + n - j + 1)  如果n &gt;= m。只需要使i = 0 ~ m，j = (m+n+1)/2-i =====&gt; 该条件在m+n为奇数/偶数时，该推理都成立<br>    *   2.B[j] &gt;= A[i-1] 并且 A[i] &gt;= B[j-1]<br>    *<br>    *   注意:<br>    *   1.临界条件：i=0,j=0,i=m,j=n。需要考虑<br>    *   2.为什么n &gt;= m ? 由于0 &lt;= i &lt;= m且j = (m+n+1)/2-i,必须确保j不能为负数。<br>    *<br>    *   按照以下步骤进行二叉树搜索<br>    *   1.设imin = 0,imax = m，然后开始在[imin,imax]中进行搜索<br>    *   2.令i = (imin+imax) / 2, j = (m+n+1)/2-i<br>    *   3.现在我们有len(leftPart) = len(rightPart)。而我们只会遇到三种情况：<br>    *<br>    *      ①.B[j] &gt;= A[i-1] 并且 A[i] &gt;= B[j-1]  满足条件<br>    *      ②.B[j-1] &gt; A[i]。此时应该把i增大。 即imin = i + 1;<br>    *      ③.A[i-1] &gt; B[j]。此时应该把i减小。 即imax = i - 1;<br>    *<br>    * */  </p>
<pre><code>public double findMedianSortedArrays(int[] A, int[] B) {
    int m = A.length;
    int n = B.length;
    if (m &gt; n) { // to ensure m&lt;=n
        int[] temp = A; A = B; B = temp;
        int tmp = m; m = n; n = tmp;
    }
    int iMin = 0, iMax = m, halfLen = (m + n + 1) / 2;
    while (iMin &lt;= iMax) {
        int i = (iMin + iMax) / 2;
        int j = halfLen - i;
        if (i &lt; iMax &amp;&amp; B[j - 1] &gt; A[i]) {
            iMin = i + 1; // i is too small
        } else if (i &gt; iMin &amp;&amp; A[i - 1] &gt; B[j]) {
            iMax = i - 1; // i is too big
        } else { // i is perfect
            int maxLeft;
            if (i == 0) {//A分成的leftA(空集) 和 rightA(A的全部)  所以leftPart = leftA(空集) + leftB,故maxLeft = B[j-1]。
                maxLeft = B[j - 1];
            } else if (j == 0) { //B分成的leftB(空集) 和 rightB(B的全部)  所以leftPart = leftA + leftB(空集),故maxLeft = A[i-1]。
                maxLeft = A[i - 1];
            } else { //排除上述两种特殊情况，正常比较
                maxLeft = Math.max(A[i - 1], B[j - 1]);
            }
            if ((m + n) % 2 == 1) { //奇数，中位数正好是maxLeft
                return maxLeft;
            }
            //偶数
            int minRight;
            if (i == m) {//A分成的leftA(A的全部) 和 rightA(空集)  所以rightPart = rightA(空集) + rightB,故minRight = B[j]。
                minRight = B[j];
            } else if (j == n) {//B分成的leftB(B的全部) 和 rightB(空集)  所以rightPart = rightA + rightB(空集),故minRight = A[i]。
                minRight = A[i];
            } else {//排除上述两种特殊情况，正常比较
                minRight = Math.min(B[j], A[i]);
            }

            return (maxLeft + minRight) / 2.0;
        }
    }
    return 0.0;
}</code></pre><p>这道题二分查找不难想，但边界条件处理很难搞，我觉得要把众多条件分清三个层次，第一个层次，首先因为是二分查找，所以循环本身必须符合二分查找的条件，下界小于等于上界，因为中位数必然存在，所以循环必然能够返回，循环外无需任何处理，在这个层次上我们不需要分析i与j如何如何，然后第二个层次，循环内第一步要分析的是分割出来的子数组是否完美，所以这个层次也无需细致考虑i和j的边界。最后第三个层次，就是子数组已经完美，我们只要考虑i和j的边界条件，因为i和j不可能同时为0，两者等级并列，因为n和m有可能为0，所以接下来才考虑n和m，同理，i和j也不可能同时为m和n，所以两者也并列，大致如此，感觉还是要在纸上分析过。</p>
<h3 id="解法2：（归并排序）（时间复杂度不符合）"><a href="#解法2：（归并排序）（时间复杂度不符合）" class="headerlink" title="解法2：（归并排序）（时间复杂度不符合）"></a>解法2：（归并排序）（时间复杂度不符合）</h3><pre><code>class Solution {  
        public double findMedianSortedArrays(int[] nums1, int[] nums2) {
        int l1 = nums1.length;
        int l2 = nums2.length;
        int l = l1+l2;
        if((l&amp;0x01)==0){//中位数为两数之平均数的情况
            int index1 = l/2;
            int index2 = l/2-1;
            int sum1=0;
            int sum2=0;
            int i=0;
            int j=0;
            int x=0;
            while(i&lt;l1||j&lt;l2){
                if(i&gt;=l1){
                    if(x==index1)sum1=nums2[j];
                    if(x==index2)sum2=nums2[j];
                    j++;
                }else if(j&gt;=l2){
                    if(x==index1)sum1=nums1[i];
                    if(x==index2)sum2=nums1[i];
                    i++;
                }
                else if(nums1[i]&lt;nums2[j]){
                    if(x==index1)sum1=nums1[i];
                    if(x==index2)sum2=nums1[i];
                    i++;
                }
                else {
                    if(x==index1)sum1=nums2[j];
                    if(x==index2)sum2=nums2[j];
                    j++;
                }
                x++;
            }
            return (sum1+sum2)/2.0;
        }else{中位数为一个数的情况
            int index = l/2;
            int sum=0;
            int i=0;
            int j=0;
            int x=0;
            while(i&lt;l1||j&lt;l2){
                if(i&gt;=l1){

                    if(x==index){
                        sum=nums2[j];
                        break;
                    }
                    j++;

                }else if(j&gt;=l2){
                    if(x==index){
                        sum = nums1[i];
                        break;
                    }
                    i++;
                }
                else if(nums1[i]&lt;nums2[j]){

                    if(x==index){
                        sum = nums1[i];
                        break;
                    }
                    i++;

                }
                else {

                    if(x==index){
                        sum=nums2[j];
                        break;
                    }
                    j++;

                }
                x++;
            }
            return sum;

        }
    }
}</code></pre>]]></content>
      <categories>
        <category>Algorithms</category>
      </categories>
      <tags>
        <tag>study</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>/2019/12/04/java/</url>
    <content><![CDATA[<p>java<br>int<br>Integer.MAX_VALUE=2的31次方-1<br>Integer.MAX_VALUE + 1 = Integer.MIN_VALUE = -2147483648<br>java的取余运算区别于python    </p>
<pre><code>C++（G++ 编译）： cout &lt;&lt; (-7) % 3; // 输出 -1    
Java（1.6）： System.out.println((-7) % 3); // 输出 -1    
Python 2.6：&gt;&gt;&gt;  (-7) % 3 // 输出 2




public int reverse(int x) {
        boolean neg = false;
        if(x&lt;0){
            neg = true;
            x = -x;
        }
        long ans = 0;
        int maxPow = (int)Math.log10(x);
        while(x&gt;0){
            ans+= (x%10 * Math.pow(10,maxPow--));
            x=x/10;
        }
        if(ans &gt; Integer.MAX_VALUE){
            return 0;
        }
        if(neg){
            return (int)(-ans);
        }else{
           return (int) ans;
        }
    }</code></pre><p>1</p>
<pre><code>class Solution {
    public int reverse(int x) {
        int rev = 0;
        while (x != 0) {
            int pop = x % 10;
            x /= 10;
            if (rev &gt; Integer.MAX_VALUE/10 || (rev == Integer.MAX_VALUE / 10 &amp;&amp; pop &gt; 7)) return 0;
            if (rev &lt; Integer.MIN_VALUE/10 || (rev == Integer.MIN_VALUE / 10 &amp;&amp; pop &lt; -8)) return 0;
            rev = rev * 10 + pop;
        }
        return rev;
    }
}</code></pre>]]></content>
  </entry>
  <entry>
    <title>mysql学习</title>
    <url>/2019/11/20/mysql%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>study</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis面试题</title>
    <url>/2019/11/03/Redis%E9%9D%A2%E8%AF%95%E9%A2%98/</url>
    <content><![CDATA[<p><a href="https://blog.csdn.net/qq_34337272/article/details/80012284" title="参考链接" target="_blank" rel="noopener">https://blog.csdn.net/qq_34337272/article/details/80012284</a></p>
<h2 id="【基础】1-Redis的全称是什么？"><a href="#【基础】1-Redis的全称是什么？" class="headerlink" title="【基础】1.Redis的全称是什么？"></a>【基础】1.Redis的全称是什么？</h2><p>Remote Dictionary Server</p>
<h2 id="【基础】2-什么是Redis？简述它的优缺点？"><a href="#【基础】2-什么是Redis？简述它的优缺点？" class="headerlink" title="【基础】2.什么是Redis？简述它的优缺点？"></a>【基础】2.什么是Redis？简述它的优缺点？</h2><p>简单来说 redis 就是一个数据库，不过与传统数据库不同的是 redis 的数据是存在内存中的，所以读写速度非常快，因此 redis 被广泛应用于缓存方向。另外，redis 也经常用来做分布式锁。redis 提供了多种数据类型来支持不同的业务场景。除此之外，redis 支持事务 、持久化、LUA脚本、LRU驱动事件、多种集群方案。  </p>
<ul>
<li><p>Key-Value 性质的内存数据库</p>
</li>
<li><p>所有的数据保存在内存中，且定期同步到磁盘中，实现主从同步<br>  定期保存有手动保存和自动保存：手动：通过save-同步,bgsave-异步, 自动：设置n秒内m个key被改动，就触发保存<br>  保存分为快照保存：保存二进制.rdb到磁盘中。 还有一种是AOF写日志的形式。<br>  主从同步，是指通过 xxx从 savleof xxx主 同步两个机器之间的数据    </p>
</li>
<li><p>优点<br>  纯内存操作，性能非常出色<br>  支持保存多种数据结构（string，list，set，sorted set，hash），且均支持原子性的push/pop, add/remove<br>  所谓的原子性就是对数据的更改要么全部执行，要么全部不执行  </p>
</li>
<li><p>缺点<br>  数据库容量受到物理内存的限制，无法存放大量数据  </p>
</li>
</ul>
<h2 id="【基础】3-为什么要用-redis-为什么要用缓存"><a href="#【基础】3-为什么要用-redis-为什么要用缓存" class="headerlink" title="【基础】3.为什么要用 redis/为什么要用缓存"></a>【基础】3.为什么要用 redis/为什么要用缓存</h2><p>主要从“高性能”和“高并发”这两点来看待这个问题。</p>
<h3 id="高性能："><a href="#高性能：" class="headerlink" title="高性能："></a>高性能：</h3><p>假如用户第一次访问数据库中的某些数据。这个过程会比较慢，因为是从硬盘上读取的。将该用户访问的数据存在缓存中，这样下一次再访问这些数据的时候就可以直接从缓存中获取了。操作缓存就是直接操作内存，所以速度相当快。如果数据库中的对应数据改变的之后，同步改变缓存中相应的数据即可！</p>
<h3 id="高并发："><a href="#高并发：" class="headerlink" title="高并发："></a>高并发：</h3><p>直接操作缓存能够承受的请求是远远大于直接访问数据库的，所以我们可以考虑把数据库中的部分数据转移到缓存中去，这样用户的一部分请求会直接到缓存这里而不用经过数据库。</p>
<h2 id="4-为什么要用-redis-而不用-map-guava-做缓存"><a href="#4-为什么要用-redis-而不用-map-guava-做缓存" class="headerlink" title="4.为什么要用 redis 而不用 map/guava 做缓存?"></a>4.为什么要用 redis 而不用 map/guava 做缓存?</h2><p>下面的内容来自 segmentfault 一位网友的提问，地址：<a href="https://segmentfault.com/q/1010000009106416" target="_blank" rel="noopener">https://segmentfault.com/q/1010000009106416</a></p>
<p>缓存分为本地缓存和分布式缓存。以 Java 为例，使用自带的 map 或者 guava 实现的是本地缓存，最主要的特点是轻量以及快速，生命周期随着 jvm 的销毁而结束，并且在多实例的情况下，每个实例都需要各自保存一份缓存，缓存不具有一致性。</p>
<p>使用 redis 或 memcached 之类的称为分布式缓存，在多实例的情况下，各实例共用一份缓存数据，缓存具有一致性。缺点是需要保持 redis 或 memcached服务的高可用，整个程序架构上较为复杂。  </p>
<h2 id="【基础】3-Redis有哪些适合的场景？"><a href="#【基础】3-Redis有哪些适合的场景？" class="headerlink" title="【基础】3.Redis有哪些适合的场景？"></a>【基础】3.Redis有哪些适合的场景？</h2><h3 id="1）全页面缓存"><a href="#1）全页面缓存" class="headerlink" title="1）全页面缓存"></a>1）全页面缓存</h3><p>如果你使用的是服务器端内容渲染，你又不想为每个请求重新渲染每个页面，就可以使用 Redis 把常被请求的内容缓存起来，能够大大的降低页面请求的延迟，已经有很多框架用Redis来缓存页面，这就是页面静态化的一种方式。     </p>
<pre><code>//将整个页面放在缓存中
set key &quot;&lt;html&gt;...&lt;/html&gt;&quot; Ex 60

//在需要的地方
get key   </code></pre><h3 id="2）排行"><a href="#2）排行" class="headerlink" title="2）排行"></a>2）排行</h3><p>Redis 基于内存，可以非常快速高效的处理增加和减少的操作，相比于使用 SQL 请求的处理方式，性能的提升是非常巨大的。<br>Redis 的有序集合可以轻松实现“从一个大型列表中取得排名最高的N个元素”，毫秒级，而且非常简单。</p>
<pre><code>//添加一个值，在一个已经排序的集合中
ZADD sortedSet 1 &apos;one&apos;

//获取所有的值，从一个已经排序的集合中
ZRANGE sortedSet 0 -1

//从一个已经排序的集合中，获取所有的值，以及他们的分数
ZRANGE sortedSet 0 -1 WITHSCORES</code></pre><h3 id="3）Session存储"><a href="#3）Session存储" class="headerlink" title="3）Session存储"></a>3）Session存储</h3><p>这可能是应用最广的点了，相比较于类似 memcache 的 session 存储，Redis 具有缓存数据持久化的能力，当缓存因出现问题而重启后，之前的缓存数据还在那儿，这个就比较实用，避免了因为session突然消失带来的用户体验问题。</p>
<pre><code>//将session保存一分钟
SET randomHash &quot;{userId}&quot; EX 60

//获取userid
GET randomHash  </code></pre><h3 id="4）队列"><a href="#4）队列" class="headerlink" title="4）队列"></a>4）队列</h3><p>例如 email 的发送队列、等待被其他应用消费的数据队列，Redis 可以轻松而自然的创建出一个高效的队列。</p>
<pre><code>//添加一个消息
HSET messages &lt;id&gt; &lt;message&gt;
ZADD due &lt;due_timestamp&gt; &lt;id&gt;

//收到一个消息
ZRANGEBYSCORE due -inf &lt;current_timestamp&gt; LIMIT 0 1
HGET messages &lt;message_id&gt;

//删除消息
ZREM due &lt;message_id&gt;
HDEL messages &lt;message_id&gt;  </code></pre><h3 id="5）发布-订阅"><a href="#5）发布-订阅" class="headerlink" title="5）发布/订阅"></a>5）发布/订阅</h3><p>pub/sub 是 Redis 内置的一个非常强大的特性，例如可以创建一个实时的聊天系统、社交网络中的通知触发器等等。</p>
<pre><code>//在一个频道中发布一条消息
PUBLISH channel message

//从一个频道中收到一条消息
SUBSCRIBE channel</code></pre><h2 id="【基础】4-Redis官方为什么不提供Windows版本？"><a href="#【基础】4-Redis官方为什么不提供Windows版本？" class="headerlink" title="【基础】4.Redis官方为什么不提供Windows版本？"></a>【基础】4.Redis官方为什么不提供Windows版本？</h2><p>因为目前Linux版本已经相当稳定，而且用户量很大，无需开发windows版本，反而会带来兼容性等问题。</p>
<h2 id="【基础】5-Redis如何设置密码及验证密码？"><a href="#【基础】5-Redis如何设置密码及验证密码？" class="headerlink" title="【基础】5.Redis如何设置密码及验证密码？"></a>【基础】5.Redis如何设置密码及验证密码？</h2><p>在配置文件中设置 requirepass， 重启后不失效<br>config set requirepass xxx 重启后失效</p>
<h2 id="【基础】6-怎么测试Redis的连通性？"><a href="#【基础】6-怎么测试Redis的连通性？" class="headerlink" title="【基础】6.怎么测试Redis的连通性？"></a>【基础】6.怎么测试Redis的连通性？</h2><p>ping telnet</p>
<h2 id="【基础】7-Redis如何做大量数据插入？"><a href="#【基础】7-Redis如何做大量数据插入？" class="headerlink" title="【基础】7.Redis如何做大量数据插入？"></a>【基础】7.Redis如何做大量数据插入？</h2><p>这里是官方文档的解释：<br><a href="http://www.redis.cn/topics/mass-insert.html" title="大量数据插入" target="_blank" rel="noopener">http://www.redis.cn/topics/mass-insert.html</a><br>简洁一点就是：使用Redis提供的管道模式 ,可以一次性执行大量数据<br>cat data.txt | redis-cli –pipe</p>
<h2 id="【基础】8-查看Redis使用情况及状态信息用什么命令？"><a href="#【基础】8-查看Redis使用情况及状态信息用什么命令？" class="headerlink" title="【基础】8.查看Redis使用情况及状态信息用什么命令？"></a>【基础】8.查看Redis使用情况及状态信息用什么命令？</h2><p>info  </p>
<h2 id="【基础】9-Redis中的管道有什么用？"><a href="#【基础】9-Redis中的管道有什么用？" class="headerlink" title="【基础】9.Redis中的管道有什么用？"></a>【基础】9.Redis中的管道有什么用？</h2><p>一次请求/响应服务器能实现处理新的请求即使旧的请求还未被响应。这样就可以将多个命令发送到服务器，而不用等待回复，最后在一个步骤中读取该答复。   </p>
<p>这就是管道（pipelining），是一种几十年来广泛使用的技术。例如许多POP3协议已经实现支持这个功能，大大加快了从服务器下载新邮件的过程。</p>
<p>Redis中的管道</p>
<h2 id="【基础】10-Redis-key的过期时间和永久有效分别怎么设置？"><a href="#【基础】10-Redis-key的过期时间和永久有效分别怎么设置？" class="headerlink" title="【基础】10.Redis key的过期时间和永久有效分别怎么设置？"></a>【基础】10.Redis key的过期时间和永久有效分别怎么设置？</h2><p>EXPIRE和PERSIST命令。</p>
<h2 id="【基础】11-修改配置不重启Redis会实时生效吗？"><a href="#【基础】11-修改配置不重启Redis会实时生效吗？" class="headerlink" title="【基础】11.修改配置不重启Redis会实时生效吗？"></a>【基础】11.修改配置不重启Redis会实时生效吗？</h2><p>针对运行实例，有许多配置选项可以通过 CONFIG SET 命令进行修改，而无需执行任何形式的重启。 从 Redis 2.2 开始，可以从 AOF 切换到 RDB 的快照持久性或其他方式而不需要重启 Redis。检索 ‘CONFIG GET *’ 命令获取更多信息。</p>
<h2 id="【基础】12-Redis与其他key-value存储有什么不同？"><a href="#【基础】12-Redis与其他key-value存储有什么不同？" class="headerlink" title="【基础】12.Redis与其他key-value存储有什么不同？"></a>【基础】12.Redis与其他key-value存储有什么不同？</h2><p>提供了更多的数据类型<br>提供了原子性操作<br>可以持久化到磁盘  </p>
<h1 id="二、数据"><a href="#二、数据" class="headerlink" title="二、数据"></a>二、数据</h1><h2 id="【数据】1-Redis支持哪几种数据类型？"><a href="#【数据】1-Redis支持哪几种数据类型？" class="headerlink" title="【数据】1.Redis支持哪几种数据类型？"></a>【数据】1.Redis支持哪几种数据类型？</h2><p>string ，list ， set ，sorted set，hash</p>
<h2 id="【数据】2-一个字符串类型的值能存储最大容量是多少？"><a href="#【数据】2-一个字符串类型的值能存储最大容量是多少？" class="headerlink" title="【数据】2.一个字符串类型的值能存储最大容量是多少？"></a>【数据】2.一个字符串类型的值能存储最大容量是多少？</h2><p>512M</p>
<h2 id="【数据】3-Redis持久化数据和缓存怎么做扩容？"><a href="#【数据】3-Redis持久化数据和缓存怎么做扩容？" class="headerlink" title="【数据】3.Redis持久化数据和缓存怎么做扩容？"></a>【数据】3.Redis持久化数据和缓存怎么做扩容？</h2><h3 id="Redis持久化数据有两种方法："><a href="#Redis持久化数据有两种方法：" class="headerlink" title="Redis持久化数据有两种方法："></a>Redis持久化数据有两种方法：</h3><h4 id="Snapshoting"><a href="#Snapshoting" class="headerlink" title="Snapshoting"></a>Snapshoting</h4><p>快照：默认的持久化方式，以配置 redis在 n 秒内如果超过 m 个 key 被修改就自动做快照。 保存为.rdb的文件。缺点是redis服务down掉了。最后一次快照就会丢失。</p>
<h3 id="AOF："><a href="#AOF：" class="headerlink" title="AOF："></a>AOF：</h3><p>就是每调用一次，就保存一次。类似于写日志。然后下次重启，再从这个.aof文件中，恢复redis的数据。缺点是，会造成aof文件越来越大。而且还有很多垃圾数据。<br>例如我们调用 incr test命令 100 次，文件中必须保存全部的 100 条命令，其实有 99 条都是多余的。因为要恢复数据库的状态其实文件中保存一条 set test 100 就够了<br>为了压缩 aof 的持久化文件。 redis 提供了 bgrewriteaof 命令。收到此命令 redis 将使用与快照类似的方式将内存中的数据以命令的方式保存到临时文件中，最后替换原来的文件。<br><a href="https://blog.csdn.net/tr1912/article/details/70197085?foxhandler=RssReadRenderProcessHandler" target="_blank" rel="noopener">https://blog.csdn.net/tr1912/article/details/70197085?foxhandler=RssReadRenderProcessHandler</a></p>
<p>做扩容，就是用集群就好啦！</p>
<h2 id="【数据】4-一个Redis实例最多能存放多少的keys？List、Set、Sorted-Set他们最多能存放多少元素？"><a href="#【数据】4-一个Redis实例最多能存放多少的keys？List、Set、Sorted-Set他们最多能存放多少元素？" class="headerlink" title="【数据】4.一个Redis实例最多能存放多少的keys？List、Set、Sorted Set他们最多能存放多少元素？"></a>【数据】4.一个Redis实例最多能存放多少的keys？List、Set、Sorted Set他们最多能存放多少元素？</h2><p>理论上Redis可以处理多达2^32的keys，并且在实际中进行了测试，每个实例至少存放了2亿5千万的keys。我们正在测试一些较大的值。</p>
<p>任何list、set、和sorted set都可以放2^32个元素。  </p>
<p>换句话说，Redis的存储极限是系统中的可用内存值。  </p>
<h1 id="三、内存"><a href="#三、内存" class="headerlink" title="三、内存"></a>三、内存</h1><h2 id="【内存】1-Redis主要消耗什么物理资源？"><a href="#【内存】1-Redis主要消耗什么物理资源？" class="headerlink" title="【内存】1.Redis主要消耗什么物理资源？"></a>【内存】1.Redis主要消耗什么物理资源？</h2><p>内存</p>
<h2 id="【内存】2-为什么Redis需要把所有数据放到内存中？"><a href="#【内存】2-为什么Redis需要把所有数据放到内存中？" class="headerlink" title="【内存】2.为什么Redis需要把所有数据放到内存中？"></a>【内存】2.为什么Redis需要把所有数据放到内存中？</h2><p>Redis为了达到最快的读写速度将数据都读到内存中，并通过异步的方式将数据写入磁盘。</p>
<p>所以redis具有快速和数据持久化的特征。如果不将数据放在内存中，磁盘I/O速度为严重影响redis的性能。</p>
<p>在内存越来越便宜的今天，redis将会越来越受欢迎。 如果设置了最大使用的内存，则数据已有记录数达到内存限值后不能继续插入新值。</p>
<h2 id="【内存】3-Redis如何做内存优化？"><a href="#【内存】3-Redis如何做内存优化？" class="headerlink" title="【内存】3.Redis如何做内存优化？"></a>【内存】3.Redis如何做内存优化？</h2><p>尽可能使用散列表（hashes），散列表（是说散列表里面存储的数少）使用的内存非常小，所以你应该尽可能的将你的数据模型抽象到一个散列表里面。</p>
<p>比如你的web系统中有一个用户对象，不要为这个用户的名称，姓氏，邮箱，密码设置单独的key,而是应该把这个用户的所有信息存储到一张散列表里面。</p>
<h2 id="【内存】4-Redis的内存占用情况怎么样？"><a href="#【内存】4-Redis的内存占用情况怎么样？" class="headerlink" title="【内存】4.Redis的内存占用情况怎么样？"></a>【内存】4.Redis的内存占用情况怎么样？</h2><p>给你举个例子： 100万个键值对（键是0到999999值是字符串“hello world”）在我的32位的Mac笔记本上 用了100MB。同样的数据放到一个key里只需要16MB， 这是因为键值有一个很大的开销。 在Memcached上执行也是类似的结果，但是相对Redis的开销要小一点点，因为Redis会记录类型信息引用计数等等。</p>
<p>当然，大键值对时两者的比例要好很多。</p>
<p>64位的系统比32位的需要更多的内存开销，尤其是键值对都较小时，这是因为64位的系统里指针占用了8个字节。 但是，当然，64位系统支持更大的内存，所以为了运行大型的Redis服务器或多或少的需要使用64位的系统。</p>
<h2 id="【内存】5-都有哪些办法可以降低Redis的内存使用情况呢？"><a href="#【内存】5-都有哪些办法可以降低Redis的内存使用情况呢？" class="headerlink" title="【内存】5.都有哪些办法可以降低Redis的内存使用情况呢？"></a>【内存】5.都有哪些办法可以降低Redis的内存使用情况呢？</h2><p>如果你使用的是32位的Redis实例，可以好好利用Hash,list,sorted set,set等集合类型数据，因为通常情况下很多小的Key-Value可以用更紧凑的方式存放到一起。</p>
<p>尽量使用集合。而避免使用单个的key-value。 比如一个学生，包含姓名，性别，年龄等。</p>
<p>我们尽量搞一个hash散列表保存他。而不是创建三个k-y保存他。</p>
<p>能节省多少？</p>
<p>100万个键值对，在32位机器上，占用100M内存。如果这一百万个数据，保存在一个key-value中，占用16M。</p>
<h2 id="【内存】6-Redis的内存用完了会发生什么？"><a href="#【内存】6-Redis的内存用完了会发生什么？" class="headerlink" title="【内存】6.Redis的内存用完了会发生什么？"></a>【内存】6.Redis的内存用完了会发生什么？</h2><p>触发数据淘汰。</p>
<h1 id="四、数据淘汰"><a href="#四、数据淘汰" class="headerlink" title="四、数据淘汰"></a>四、数据淘汰</h1><h2 id="【数据淘汰】1-Redis有哪几种数据淘汰策略？"><a href="#【数据淘汰】1-Redis有哪几种数据淘汰策略？" class="headerlink" title="【数据淘汰】1.Redis有哪几种数据淘汰策略？"></a>【数据淘汰】1.Redis有哪几种数据淘汰策略？</h2><p>volatile-lru:从设置了过期时间的 数据集 中，选择最近最久未使用的数据释放；<br>allkeys-lru:从 数据集 中(包括设置过期时间以及未设置过期时间的数据集中)，选择最近最久未使用的数据释放；<br>volatile-random:从设置了过期时间的 数据集 中，随机选择一个数据进行释放；<br>allkeys-random:从 数据集 中(包括了设置过期时间以及未设置过期时间)随机选择一个数据进行入释放；<br>volatile-ttl：从设置了过期时间的 数据集 中，选择马上就要过期的数据进行释放操作；<br>[默认]noeviction：不删除任意数据(但redis还会根据引用计数器进行释放),这时如果内存不够时，会直接返回错误。  </p>
<h2 id="【数据淘汰】2-Redis回收使用的是什么算法？Redis中的LRU算法是什么？"><a href="#【数据淘汰】2-Redis回收使用的是什么算法？Redis中的LRU算法是什么？" class="headerlink" title="【数据淘汰】2.Redis回收使用的是什么算法？Redis中的LRU算法是什么？"></a>【数据淘汰】2.Redis回收使用的是什么算法？Redis中的LRU算法是什么？</h2><p>LRU算法是一个近似算法（LRU是Least Recently Used 的缩写，即最近最少使用，常用于页面置换算法），主要是用于，当redis中的数据，超过内存限制时，所执行的删除key-value的一种策略。这个策略是随机选取n个键值对，（n取决于redis配置文件中所设置的maxmemory-samples的值），然后从n个键值对中，选取最近的最久未使用的键值对，进行淘汰。n越大，越精确，但是耗时也越多。</p>
<h2 id="具体是怎么实现的？"><a href="#具体是怎么实现的？" class="headerlink" title="具体是怎么实现的？"></a>具体是怎么实现的？</h2><p>是在redisObject的结构体中（Redis是C语言写的），在这个结构体中，存放了一个值：server.lruclock，每次使用key-value的时候，都会更新这个值。如果很久没使用，那么这个值，就比较老了。<br><a href="https://www.cnblogs.com/WJ5888/p/4371647.html" target="_blank" rel="noopener">https://www.cnblogs.com/WJ5888/p/4371647.html</a></p>
<h2 id="【数据淘汰】3-MySQL里有2000w数据，redis中只存20w的数据，如何保证redis中的数据都是热点数据？"><a href="#【数据淘汰】3-MySQL里有2000w数据，redis中只存20w的数据，如何保证redis中的数据都是热点数据？" class="headerlink" title="【数据淘汰】3.MySQL里有2000w数据，redis中只存20w的数据，如何保证redis中的数据都是热点数据？"></a>【数据淘汰】3.MySQL里有2000w数据，redis中只存20w的数据，如何保证redis中的数据都是热点数据？</h2><p>redis内存数据集大小上升到一定大小的时候，就会施行数据淘汰策略。</p>
<h2 id="【数据淘汰】4-Redis回收进程如何工作的？"><a href="#【数据淘汰】4-Redis回收进程如何工作的？" class="headerlink" title="【数据淘汰】4.Redis回收进程如何工作的？"></a>【数据淘汰】4.Redis回收进程如何工作的？</h2><p>一个客户端运行了新的命令，添加了新的数据。<br>Redi检查内存使用情况，如果大于maxmemory的限制, 则根据设定好的策略进行回收。   </p>
<h1 id="五、Redis客户端"><a href="#五、Redis客户端" class="headerlink" title="五、Redis客户端"></a>五、Redis客户端</h1><h2 id="【Redis客户端】1-Redis支持的Java客户端都有哪些？官方推荐用哪个？"><a href="#【Redis客户端】1-Redis支持的Java客户端都有哪些？官方推荐用哪个？" class="headerlink" title="【Redis客户端】1.Redis支持的Java客户端都有哪些？官方推荐用哪个？"></a>【Redis客户端】1.Redis支持的Java客户端都有哪些？官方推荐用哪个？</h2><p>Redisson、Jedis、lettuce等等，官方推荐使用Redisson。   </p>
<p>我们公司用的是spring提供的RedisTemplate. Jedis是Redis官方推荐的面向Java的操作Redis的客户端，而RedisTemplate是SpringDataRedis中对JedisApi的高度封装。<br>SpringDataRedis相对于Jedis来说可以方便地更换Redis的Java客户端，比Jedis多了自动管理连接池的特性，方便与其他Spring框架进行搭配使用如：SpringCache  </p>
<h2 id="【Redis客户端】2-Redis和Redisson有什么关系？"><a href="#【Redis客户端】2-Redis和Redisson有什么关系？" class="headerlink" title="【Redis客户端】2.Redis和Redisson有什么关系？"></a>【Redis客户端】2.Redis和Redisson有什么关系？</h2><p>Redisson是一个高级的分布式协调Redis客户端，能帮助用户在分布式环境中轻松实现一些Java的对象 (Bloom filter, BitSet, Set, SetMultimap, ScoredSortedSet, SortedSet, Map, ConcurrentMap, List, ListMultimap, Queue, BlockingQueue, Deque, BlockingDeque, Semaphore, Lock, ReadWriteLock, AtomicLong, CountDownLatch, Publish / Subscribe, HyperLogLog)。</p>
<h2 id="【Redis客户端】3-Jedis与Redisson对比有什么优缺点？"><a href="#【Redis客户端】3-Jedis与Redisson对比有什么优缺点？" class="headerlink" title="【Redis客户端】3.Jedis与Redisson对比有什么优缺点？"></a>【Redis客户端】3.Jedis与Redisson对比有什么优缺点？</h2><p>Jedis是Redis的Java实现的客户端，其API提供了比较全面的Redis命令的支持；</p>
<p>Redisson实现了分布式和可扩展的Java数据结构，和Jedis相比，功能较为简单，不支持字符串操作，不支持排序、事务、管道、分区等Redis特性。Redisson的宗旨是促进使用者对Redis的关注分离，从而让使用者能够将精力更集中地放在处理业务逻辑上。</p>
<h2 id="【Redis客户端】4-支持一致性哈希的客户端有哪些？"><a href="#【Redis客户端】4-支持一致性哈希的客户端有哪些？" class="headerlink" title="【Redis客户端】4.支持一致性哈希的客户端有哪些？"></a>【Redis客户端】4.支持一致性哈希的客户端有哪些？</h2><p>Redis-rb、Predis等。</p>
<h1 id="六、事务"><a href="#六、事务" class="headerlink" title="六、事务"></a>六、事务</h1><h2 id="【事务】1-怎么理解Redis事务？"><a href="#【事务】1-怎么理解Redis事务？" class="headerlink" title="【事务】1.怎么理解Redis事务？"></a>【事务】1.怎么理解Redis事务？</h2><p>事务是一个单独的隔离操作：事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。</p>
<p>事务是一个原子操作：事务中的命令要么全部被执行，要么全部都不执行。</p>
<h2 id="【事务】2-Redis事务相关的命令有哪几个？"><a href="#【事务】2-Redis事务相关的命令有哪几个？" class="headerlink" title="【事务】2.Redis事务相关的命令有哪几个？"></a>【事务】2.Redis事务相关的命令有哪几个？</h2><p>MULTI、EXEC、DISCARD、WATCH。</p>
<p>MULTI: [创建事务] 用于标记一个事务块的开始。<br>EXEC: [执行事务] 在一个事务中执行所有先前放入队列的命令，然后恢复正常的连接状态。<br>DISCARD: [取消事务] 清除所有先前在一个事务中放入队列的命令，然后恢复正常的连接状态。<br>WATCH: watch命令可以监控一个或多个键，一旦其中有一个键被修改（或删除），之后的事务就不会执行。<br>UNWATCH: 清除所有先前为一个事务监控的键。</p>
<h1 id="七、集群"><a href="#七、集群" class="headerlink" title="七、集群"></a>七、集群</h1><h2 id="【集群】1-Redis集群方案应该怎么做？都有哪些方案？"><a href="#【集群】1-Redis集群方案应该怎么做？都有哪些方案？" class="headerlink" title="【集群】1.Redis集群方案应该怎么做？都有哪些方案？"></a>【集群】1.Redis集群方案应该怎么做？都有哪些方案？</h2><p>redis的集群方案大致分为四种：</p>
<h3 id="使用twitter开源的Twemproxy代理"><a href="#使用twitter开源的Twemproxy代理" class="headerlink" title="使用twitter开源的Twemproxy代理"></a>使用twitter开源的Twemproxy代理</h3><p>Twemproxy作为代理，可接受来自多个程序的访问，按照路由规则，转发给后台的各个Redis服务器，再原路返回。缺点就是：无法平滑地扩容/缩容。对运维考验力度比较大。</p>
<h3 id="使用豌豆荚开源的Codis"><a href="#使用豌豆荚开源的Codis" class="headerlink" title="使用豌豆荚开源的Codis"></a>使用豌豆荚开源的Codis</h3><p>Codis 是一个分布式 Redis 解决方案, 对于上层的应用来说, 连接到 Codis Proxy 和连接原生的 Redis Server 没有明显的区别 (有一些命令不支持), 上层应用可以像使用单机的 Redis 一样使用, Codis 底层会处理请求的转发, 不停机的数据迁移等工作, 所有后边的一切事情, 对于前面的客户端来说是透明的, 可以简单的认为后边连接的是一个内存无限大的 Redis 服务。支持在 节点数量改变情况下，旧节点数据可恢复到新hash节点。</p>
<h3 id="redis-3-0-自带的集群功能"><a href="#redis-3-0-自带的集群功能" class="headerlink" title="redis 3.0 自带的集群功能"></a>redis 3.0 自带的集群功能</h3><p>和 Codis差不多。特点在于他的分布式算法不是一致性hash，而是hash槽的概念，以及自身支持节点设置从节点。</p>
<h3 id="客户端处理"><a href="#客户端处理" class="headerlink" title="客户端处理"></a>客户端处理</h3><p>起几个毫无关联的redis实例，在代码层，对key 进行hash计算，然后去对应的redis实例操作数据。对代码层要求很高，需要处理很多异常情况：节点失效后的替代算法方案，数据震荡后的自动脚本恢复，实例的监控，等等。</p>
<h2 id="【集群】2-redis集群的哈希槽概念是什么？"><a href="#【集群】2-redis集群的哈希槽概念是什么？" class="headerlink" title="【集群】2.redis集群的哈希槽概念是什么？"></a>【集群】2.redis集群的哈希槽概念是什么？</h2><p>Redis 集群中内置了 16384 个哈希槽，当需要在 Redis 集群中放置一个 key-value时，redis 先对 key 使用 crc16 算法算出一个结果，然后把结果对 16384 求余数，这样每个 key 都会对应一个编号在 0-16383 之间的哈希槽，redis 会根据节点数量大致均等的将哈希槽映射到不同的节点。<br><img src="/.com//%E5%93%88%E5%B8%8C%E6%A7%BD.jpg" alt="哈希槽"></p>
<h2 id="【集群】3-普通哈希，一致性哈希和哈希槽分别是什么？"><a href="#【集群】3-普通哈希，一致性哈希和哈希槽分别是什么？" class="headerlink" title="【集群】3.普通哈希，一致性哈希和哈希槽分别是什么？"></a>【集群】3.普通哈希，一致性哈希和哈希槽分别是什么？</h2><p>参考我的另一篇博客：普通hash和一致性hash和哈希槽的概念和区别</p>
<h2 id="【集群】4-Redis集群方案什么情况下会导致整个集群不可用？"><a href="#【集群】4-Redis集群方案什么情况下会导致整个集群不可用？" class="headerlink" title="【集群】4.Redis集群方案什么情况下会导致整个集群不可用？"></a>【集群】4.Redis集群方案什么情况下会导致整个集群不可用？</h2><p>某一个节点失效时，会导致确实部分hash槽，导致集群不可用。</p>
<h2 id="【集群】5-Redis集群的主从复制模型是怎样的？"><a href="#【集群】5-Redis集群的主从复制模型是怎样的？" class="headerlink" title="【集群】5.Redis集群的主从复制模型是怎样的？"></a>【集群】5.Redis集群的主从复制模型是怎样的？</h2><p>为了使在部分节点失败或者大部分节点无法通信的情况下集群仍然可用，所以集群使用了主从复制模型,每个节点都会有N-1个复制品。</p>
<p>工作原理：从slave服务启动连接master节点，从slave节点发送一个sync命令到master，master节点收到命令后启动后台存盘进程，收集所有的操作命令，收集完之后将整个数据库文件发送给slave节点。来完成一次同步。slave节点收到数据库文件之后存盘加载到内存。此后，master节点继续收集命令依次发送给slave节点，slave节点再依次执行这些命令，从而达到数据同步。</p>
<h3 id="Redis集群-主从复制模式"><a href="#Redis集群-主从复制模式" class="headerlink" title="Redis集群 -主从复制模式"></a>Redis集群 -主从复制模式</h3><p>配置主节点的配置文件不需要任何改动<br>配置从节点只需要在配置文件中slaveof<br>如果设置了密码，就要设置：masterauth 即可  </p>
<h2 id="【集群】6-Redis集群会有写操作丢失吗？为什么？"><a href="#【集群】6-Redis集群会有写操作丢失吗？为什么？" class="headerlink" title="【集群】6. Redis集群会有写操作丢失吗？为什么？"></a>【集群】6. Redis集群会有写操作丢失吗？为什么？</h2><p>Redis并不能保证数据的强一致性（使用同步复制），这意味这在实际中集群在特定的条件下可能会丢失写操作。</p>
<p>Redis集群可能丢失写的第一个原因是因为它用异步复制。<br>写可能是这样发生的：1.客户端写到master B。2.master B回复客户端OK。3.master B将这个写操作广播给它的slaves B1、B2、B3。正如你看到的那样，B没有等到B1、B2、B3确认就回复客户端了，也就是说，B在回复客户端之前没有等待B1、B2、B3的确认，这对应Redis来说是一个潜在的风险。</p>
<p>也可以设置使用同步复制。 但是会大大降低性能。</p>
<h2 id="【集群】7-Redis集群之间是如何复制的？"><a href="#【集群】7-Redis集群之间是如何复制的？" class="headerlink" title="【集群】7.Redis集群之间是如何复制的？"></a>【集群】7.Redis集群之间是如何复制的？</h2><p>异步复制的。如果绝对需要的话，Redis集群也是支持同步写的，这是通过WAIT命令实现的。</p>
<h2 id="【集群】8-Redis集群最大节点个数是多少？"><a href="#【集群】8-Redis集群最大节点个数是多少？" class="headerlink" title="【集群】8.Redis集群最大节点个数是多少？"></a>【集群】8.Redis集群最大节点个数是多少？</h2><p>2的14次方。 16348 个， 因为Hash槽最多只有16348个。</p>
<h2 id="【集群】9-Redis集群如何选择数据库？"><a href="#【集群】9-Redis集群如何选择数据库？" class="headerlink" title="【集群】9.Redis集群如何选择数据库？"></a>【集群】9.Redis集群如何选择数据库？</h2><p>Redis集群目前无法做数据库选择，默认在0数据库。</p>
<h2 id="【集群】10-为什么要做Redis分区？"><a href="#【集群】10-为什么要做Redis分区？" class="headerlink" title="【集群】10.为什么要做Redis分区？"></a>【集群】10.为什么要做Redis分区？</h2><p>单台计算机的内存，带宽，CPU是有限的，分区的实现，就允许我们：</p>
<p>通过利用多台计算机内存的和值，允许我们构造更大的数据库。<br>通过多核和多台计算机，允许我们扩展计算能力；通过多台计算机和网络适配器，允许我们扩展网络带宽。  </p>
<h2 id="【集群】11-你知道有哪些Redis分区实现方案？"><a href="#【集群】11-你知道有哪些Redis分区实现方案？" class="headerlink" title="【集群】11.你知道有哪些Redis分区实现方案？"></a>【集群】11.你知道有哪些Redis分区实现方案？</h2><p>范围分区：比如，ID从0到10000的用户会保存到实例R0，ID从10001到 20000的用户会保存到R1，以此类推。<br>哈希分区：加入有四个实例，比如，对ID进行hash，然后对4取模，得到0-3的数字，分别保存到对应的实例上。  </p>
<h2 id="【集群】12-Redis分区有什么缺点？"><a href="#【集群】12-Redis分区有什么缺点？" class="headerlink" title="【集群】12.Redis分区有什么缺点？"></a>【集群】12.Redis分区有什么缺点？</h2><p>涉及多个key的操作通常是不被支持的。举例来说，当两个set映射到不同的redis实例上时，你就不能对这两个set执行交集操作。<br>涉及多个key的redis事务不能使用。<br>当使用分区时，数据处理较为复杂，比如你需要处理多个rdb/aof文件，并且从多个实例和主机备份持久化文件。<br>增加或删除容量也比较复杂。redis集群大多数支持在运行时增加、删除节点的透明数据平衡的能力，但是类似于客户端分区、代理等其他系统则不支持这项特性。然而，一种叫做presharding的技术对此是有帮助的。  </p>
<h2 id="【集群】13-Redis分区和集群是一样的吗？有什么区别？"><a href="#【集群】13-Redis分区和集群是一样的吗？有什么区别？" class="headerlink" title="【集群】13.Redis分区和集群是一样的吗？有什么区别？"></a>【集群】13.Redis分区和集群是一样的吗？有什么区别？</h2><p>Redis分区，就是集群。 一个东西。</p>
<p>但是Redis分区，仅仅只是指使用Redis Cluster内置的集群。</p>
<p>Redis内置集群 == Redis分区。</p>
<h2 id="【集群】14-分布式Redis是前期做还是后期规模上来了再做好？为什么？"><a href="#【集群】14-分布式Redis是前期做还是后期规模上来了再做好？为什么？" class="headerlink" title="【集群】14.分布式Redis是前期做还是后期规模上来了再做好？为什么？"></a>【集群】14.分布式Redis是前期做还是后期规模上来了再做好？为什么？</h2><p>既然Redis是如此的轻量（单实例只使用1M内存）,为防止以后的扩容，最好的办法就是一开始就启动较多实例。即便你只有一台服务器，你也可以一开始就让Redis以分布式的方式运行，使用分区，在同一台服务器上启动多个实例。</p>
<p>一开始就多设置几个Redis实例，例如32或者64个实例，对大多数用户来说这操作起来可能比较麻烦，但是从长久来看做这点牺牲是值得的。</p>
<p>这样的话，当你的数据不断增长，需要更多的Redis服务器时，你需要做的就是仅仅将Redis实例从一台服务迁移到另外一台服务器而已（而不用考虑重新分区的问题）。一旦你添加了另一台服务器，你需要将你一半的Redis实例从第一台机器迁移到第二台机器。</p>
<h2 id="【集群】15-Twemproxy是什么？"><a href="#【集群】15-Twemproxy是什么？" class="headerlink" title="【集群】15.Twemproxy是什么？"></a>【集群】15.Twemproxy是什么？</h2><p>也是一个集群工具，twitter开源的。</p>
<p>Twemproxy是Twitter维护的（缓存）代理系统，代理Memcached的ASCII协议和Redis协议。它是单线程程序，使用c语言编写，运行起来非常快。它是采用Apache 2.0 license的开源软件。 Twemproxy支持自动分区，如果其代理的其中一个Redis节点不可用时，会自动将该节点排除（这将改变原来的keys-instances的映射关系，所以你应该仅在把Redis当缓存时使用Twemproxy)。 Twemproxy本身不存在单点问题，因为你可以启动多个Twemproxy实例，然后让你的客户端去连接任意一个Twemproxy实例。 Twemproxy是Redis客户端和服务器端的一个中间层，由它来处理分区功能应该不算复杂，并且应该算比较可靠的。</p>
<h2 id="【集群】16-Redis是单线程的，如何提高多核CPU的利用率？"><a href="#【集群】16-Redis是单线程的，如何提高多核CPU的利用率？" class="headerlink" title="【集群】16.Redis是单线程的，如何提高多核CPU的利用率？"></a>【集群】16.Redis是单线程的，如何提高多核CPU的利用率？</h2><p>可以在同一个服务器部署多个Redis的实例，并把他们当作不同的服务器来使用，在某些时候，无论如何一个服务器是不够的， 所以，如果你想使用多个CPU，你可以考虑一下分片（shard）。</p>
]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis学习-2（哨兵+集群）</title>
    <url>/2019/11/01/Redis%E5%AD%A6%E4%B9%A0-2%EF%BC%88%E5%93%A8%E5%85%B5-%E9%9B%86%E7%BE%A4%EF%BC%89/</url>
    <content><![CDATA[<p><a href="https://www.cnblogs.com/Zzbj/p/10280363.html" title="哨兵+集群" target="_blank" rel="noopener">https://www.cnblogs.com/Zzbj/p/10280363.html</a></p>
<h1 id="六、哨兵"><a href="#六、哨兵" class="headerlink" title="六、哨兵"></a>六、哨兵</h1><h2 id="1-Redis的高可用实现方案"><a href="#1-Redis的高可用实现方案" class="headerlink" title="1. Redis的高可用实现方案"></a>1. Redis的高可用实现方案</h2><p>Redis主从复制模式： 将主节点的数据改变同步给从节点<br>作为主节点的一个备份，一旦主节点出现故障，从节点晋升为主节点，保证数据尽量不丢失；<br>从节点可以扩展主节点的读能力。   </p>
<h3 id="1）主从复制存在问题："><a href="#1）主从复制存在问题：" class="headerlink" title="1）主从复制存在问题："></a>1）主从复制存在问题：</h3><p>1.<span style="color:red;"> 一旦主节点出现故障，需要手动将一个从节点晋升为主节点，同时需要修改应用方的主节点地址，还需要命令其他从节点去复制新的主节点，整个过程都需要人工干预。——高可用问题—通过哨兵来解决。</span><br>2. 主节点的写能力受到单机的限制。——分布式问题<br>3. 主节点的存储能力受到单机的限制。——-分布式问题   </p>
<p><img src="/.com//redis%E5%93%A8%E5%85%B5.PNG" alt="sentinel"></p>
<h3 id="2）Redis-Sentinel："><a href="#2）Redis-Sentinel：" class="headerlink" title="2）Redis Sentinel："></a>2）Redis Sentinel：</h3><p>分布式架构—Redis数据节点、Sentinel节点、客户端分布在多个物理节点的架构。<br>包含多个Sentinel节点和Redis数据节点，每个Sentinel节点会对数据节点和其余Sebtinel几点进行监控，当发现节点不可达时，会对节点做下线标识。<br>如果标识的是主节点，还会和其他Sentinel节点进行协商，当大多数Sentinel节点都认为主节点不可达时，会选举出一个Sentinel节点来完成故障转移的工作，同时会将这个变化实时通知给Redis应用方，整个过程自动。  </p>
<h3 id="3）处理过程："><a href="#3）处理过程：" class="headerlink" title="3）处理过程："></a>3）处理过程：</h3><ul>
<li>主节点出现故障，从节点与主节点失去连接，主从复制失败；  </li>
<li>每个Sentinel节点通过定期监控发现主节点出现了故障；  </li>
<li>多个Sentinel节点最主节点的故障达成一致，选举Sentinel-3节点作为领导者负责故障转移；   </li>
<li>Sentinel-3节点领导者执行了故障转移。（实现从节点晋升为主节点并维护后续正确的主从关系。  </li>
</ul>
<h3 id="4）配置："><a href="#4）配置：" class="headerlink" title="4）配置："></a>4）配置：</h3><p>sentinel monitor mymaster 127.0.0.1 6379 2<br>此sentinel节点需要监控6379这个主节点，2代表判断主节点失败至少需要2个sentinel节点同意。<br>sentinel会找到主节点并发现从节点；<br>sentinel节点能够彼此感知对方，同时能够感知到Redis数据节点。    </p>
<p>每个sentinel节点需要通过定期发送ping命令来判断Redis数据节点和其余sentinel节点是否可达，如果超过down-after-milliseconds 配置的时间则不可达。<br>parallel-syncs用来限制在一次故障转移之后，每次向新的主节点发起复制操作的从节点的个数。<br>failover-timeout故障转移超时时间，作用于故障转移的各个阶段。</p>
<h3 id="5）部署技巧："><a href="#5）部署技巧：" class="headerlink" title="5）部署技巧："></a>5）部署技巧：</h3><p>sentinel节点不应该部署在一台物理机器上；<br>部署至少三个且奇数个sentinel节点；<br>sentinel节点集合可以只监控一个主节点，也可以监控多个主节点（维护成本低，但sentinel集合出现异常。可能会对多个数据节点造成影响）。  </p>
<p>API：Sentinel节点数一个特殊的Redis节点，有自己专属的API。可以显示监控信息等。   </p>
<h2 id="2-客户端连接"><a href="#2-客户端连接" class="headerlink" title="2. 客户端连接"></a>2. 客户端连接</h2><p>客户端初始化时连接的是sentinel节点集合，不再是具体的Redis节点，但Sentinel只是配置中心不是代理。  </p>
<h2 id="3-实现原理"><a href="#3-实现原理" class="headerlink" title="3. 实现原理"></a>3. 实现原理</h2><h3 id="1）三个定时监控任务"><a href="#1）三个定时监控任务" class="headerlink" title="1）三个定时监控任务"></a>1）三个定时监控任务</h3><ul>
<li>每隔10秒，每个sentinel节点会向主节点和从节点发送info命令获取最新的拓扑结构；  </li>
<li>每隔2秒，sentinel节点回想Redis数据节点的<strong>sentinel</strong>:hello频道发送该sentinel节点对主节点的判断以及当前sentinel节点的信息，同时每个sentinel节点会订阅该频道，了解其他sentinel节点；  </li>
<li>每隔1秒，每个sentinel节点会向主节点、从节点、其他sentinel节点发送ping命令做心跳检测，确认这些节点是否可达。  </li>
</ul>
<h3 id="2）主观下线与客观下线"><a href="#2）主观下线与客观下线" class="headerlink" title="2）主观下线与客观下线"></a>2）主观下线与客观下线</h3><ul>
<li>主观下线：当前Sentinel节点对节点判定失败，一家之言；  </li>
<li>客观下线：主观下线的节点是主节点时，该sentinel节点会通过命令向其他sentinel节点询问对主节点的判断，当大部分节点对主节点的下线做了同意的判定，为客观下线。  <h3 id="3）领导者Sentinel节点选举"><a href="#3）领导者Sentinel节点选举" class="headerlink" title="3）领导者Sentinel节点选举"></a>3）领导者Sentinel节点选举</h3><h4 id="Rsft算法："><a href="#Rsft算法：" class="headerlink" title="Rsft算法："></a>Rsft算法：</h4>每个在线的Sentinel节点都有资格称为领导者，当它确认主节点主观下线时，会向其他节点发送命令，要求自己成为领导者；<br>收到命令的Sentinel节点，如果没有同意过其它节点的请求，将同意该请求，否则拒绝。<br>如果该Sentinel节点发现自己的票数已经大于max，将称为领导者。<br>如果此过程没有选举出领导者，将进入下一次选举。   </li>
</ul>
<h2 id="4-开发与运维中的问题"><a href="#4-开发与运维中的问题" class="headerlink" title="4. 开发与运维中的问题"></a>4. 开发与运维中的问题</h2><h1 id="七、集群"><a href="#七、集群" class="headerlink" title="七、集群"></a>七、集群</h1><p>Redis分布式解决方案，解决单机内存、并发、流量等问题。  </p>
<h2 id="1-数据分布"><a href="#1-数据分布" class="headerlink" title="1.数据分布"></a>1.数据分布</h2><h3 id="1）数据分布理论"><a href="#1）数据分布理论" class="headerlink" title="1）数据分布理论"></a>1）数据分布理论</h3><p>解决把整个数据集按照分区规则映射到多个节点的问题，把数据集划分到多个节点上，每个节点负责整体数据的一个子集。<br>数据分区规则：哈希分区和顺序分区。<br>Redis Cluster采用哈希分区规则。  </p>
<h4 id="节点取余分区"><a href="#节点取余分区" class="headerlink" title="节点取余分区"></a>节点取余分区</h4><p>使用特定的数据，如redis的键或用户ID，再根据节点数量N使用公式：hash(key)%N计算出hash值，用来决定数据映射到哪一个节点上。扩容时通常采用翻倍扩容。  </p>
<h4 id="一致性哈希分区"><a href="#一致性哈希分区" class="headerlink" title="一致性哈希分区"></a>一致性哈希分区</h4><p>为系统每个节点分配一个token，范围一般在0-2的32次方，构成一个哈希环。数据读写执行节点查找操作时，先根据key计算hash值，然后顺时针找到第一个大于等于该hash值的token节点。<br>存在问题：加减节点会造成哈希环中部分数据无法命中；使用少量节点时，节点变化将大范围影响哈希环中数据映射；普通的一致性哈希分区在增减节点时需要增加一倍或减去一半节点才能保证数据和负载均衡。  </p>
<h4 id="虚拟槽分区"><a href="#虚拟槽分区" class="headerlink" title=" 虚拟槽分区"></a><span style="color:red;"> 虚拟槽分区</span></h4><p>使用分散度良好的hash函数把所有数据映射到一个固定范围的整数集合中，整数定义为槽。槽是集群内数据管理和迁移的基本单位。每个节点负责一定数量的槽。  </p>
<h3 id="2）Redis数据分区"><a href="#2）Redis数据分区" class="headerlink" title="2）Redis数据分区"></a>2）Redis数据分区</h3><p>虚拟槽分区，每一个节点负责维护一部分槽以及槽所映射的键值数据。<br><img src="/.com//%E8%99%9A%E6%8B%9F%E6%A7%BD%E5%88%86%E9%85%8D.PNG" alt="虚拟槽分配"></p>
<h4 id="特点："><a href="#特点：" class="headerlink" title="特点："></a>特点：</h4><p>解耦数据和节点的关系，简化了节点扩容和收缩难度。<br>节点自身维护槽的映射关系，不需要客户端或者代理服务维护槽分区元数据。<br>支持节点、槽、键之间的映射查询。  </p>
<h2 id="2-搭建集群"><a href="#2-搭建集群" class="headerlink" title="2.搭建集群"></a>2.搭建集群</h2><h3 id="1）准备节点"><a href="#1）准备节点" class="headerlink" title="1）准备节点"></a>1）准备节点</h3><p>集群节点数量至少为6个。<br>节点配置，集群配置。  </p>
<h3 id="2）节点握手"><a href="#2）节点握手" class="headerlink" title="2）节点握手"></a>2）节点握手</h3><p>一批运行在集群模式下的节点通过Gossip协议彼此进行通信。感知对方。<br>cluster meet 127.0.0.1 6378<br>握手状态会通过消息在集群内传播；<br>节点建立握手之后还不能正常工作，这时集群处于下线状态，所有数据读写都被禁止；<br>由于目前所有的槽没有分配节点，因此集群无法完成槽到节点的映射。  </p>
<h3 id="3）分配槽"><a href="#3）分配槽" class="headerlink" title="3）分配槽"></a>3）分配槽</h3><p>Redis集群把所有数据映射到n个槽中，每个key会映射为一个固定的槽，只有当节点分配了槽，才能相应和这些槽关联的键命令。<br>cluster nodes查看节点和槽的分配关系；<br>每个处理槽的节点应该具有从节点，保证当它出现故障时可以自动进行故障转移；<br>首次启动的节点和被分配的槽的节点都是主节点，cluster replicate{nodeID} 命令让一个节点成为从节点（在从节点执行命令）。  </p>
<h3 id="4）使用redis-trib-rb搭建集群"><a href="#4）使用redis-trib-rb搭建集群" class="headerlink" title="4）使用redis-trib.rb搭建集群"></a>4）使用redis-trib.rb搭建集群</h3><h2 id="3-节点通信"><a href="#3-节点通信" class="headerlink" title="3.节点通信"></a>3.节点通信</h2><h3 id="1）Gossip协议信息交换"><a href="#1）Gossip协议信息交换" class="headerlink" title="1）Gossip协议信息交换"></a>1）Gossip协议信息交换</h3><h4 id="通信过程说明："><a href="#通信过程说明：" class="headerlink" title="通信过程说明："></a>通信过程说明：</h4><p>1&gt;集群中的每个节点都会单独开辟一个TCP通道，用于节点之间彼此通信，通信端口号在基础端口上加10000，不如6379这个节点的通信端口看起来是这样的：16379<br>2&gt;每个节点在固定周期内通过特定规则选择几个节点发送ping消息。<br>3&gt;接收到ping消息的节点用pong消息作为响应。<br>集群中每个节点通过一定规则挑选要通信的节点，每个节点可能知道全部节点，也可能仅知道部分节点，只要这些节点彼此可以正常通信，最终它们会达到一致的状态。当节点出故障，新节点加入，主从角色变化，槽信息变更等事件发生时，通过不断ping/pong消息通信，经过一段时间后所有的节点都会知道整个集群全部节点的最新状态，从而达到集群状态同步的目的。</p>
<ul>
<li>meet:用于通知新节点加入；  </li>
<li>ping：检测节点是否在线并交换彼此状态信息；  </li>
<li>pong：作为响应消息回复确认消息正常通信；  </li>
<li>fail：判断集群节点下线广播fail消息。  </li>
</ul>
<h3 id="2）节点选择"><a href="#2）节点选择" class="headerlink" title="2）节点选择"></a>2）节点选择</h3><p>Redis集群内节点通信采用固定频率（定时任务每秒执行10次） </p>
<p><img src="/.com//%E9%9B%86%E7%BE%A4%E8%8A%82%E7%82%B9%E9%80%9A%E4%BF%A1%E9%80%89%E6%8B%A9.jpg" alt="集群节点通信选择">   </p>
<h2 id="4-集群伸缩扩容"><a href="#4-集群伸缩扩容" class="headerlink" title="4.集群伸缩扩容"></a>4.集群伸缩扩容</h2><h2 id="5-请求路由"><a href="#5-请求路由" class="headerlink" title="5.请求路由"></a>5.请求路由</h2><h2 id="6-故障转移"><a href="#6-故障转移" class="headerlink" title="6.故障转移"></a>6.故障转移</h2><p>主观下线和客观下线  </p>
<h3 id="故障检测"><a href="#故障检测" class="headerlink" title="故障检测"></a>故障检测</h3><p>集群中的每个节点都会定期的向集群中的其他节点发送PING消息，以此来检测对方是否在线，如果接收PING消息的节点没有在规定的时间内，向发送PING消息的节点返回PONG消息，那么发送PING消息的节点就会将接收PING消息的节点标记为疑似下线（probable fail，PFAIL）。<br>集群中的各个节点会通过互相发送消息的方式来交换集群中各个节点的状态信息，例如某个节点是处于在线状态、疑似下线状态（PFAIL），还是已下线状态（FAIL）。<br>如果在一个集群里面，半数以上负责处理槽的主节点都将某个主节点X报告为疑似下线，那么这个主节点X将被标记为已下线（FAIL），将主节点X标记为已下线的节点会向集群广播一条关于主节点X的FAIL消息，所有收到这条FAIL消息的节点都会立即将主节点X标记为已下线。</p>
<h3 id="故障转移"><a href="#故障转移" class="headerlink" title="故障转移"></a>故障转移</h3><p>当一个从节点发现自己正在复制的主节点进入了已下线状态时，从节点将开始对下线主节点进行故障转移，以下是故障转移执行的步骤：<br>1.复制下线主节点的所有从节点里面，会有一个从节点被选中；<br>2.被选中的从节点会执行SLAVEOF no one命令，成为新的主节点；<br>3.新的主节点会撤销所有对已下线主节点的槽指派，并将这些槽全部指派给自己；<br>4.新的主节点向集群广播一条PONG消息，这条PONG消息可以让集群中的其他节点立即知道这个节点已经由从节点变成了主节点，并且这个主节点已经接管了原本由已下线节点负责处理的槽。<br>5.新的主节点开始接收和自己负责处理的槽有关的命令请求，故障转移完成。</p>
<h3 id="选举新的主节点"><a href="#选举新的主节点" class="headerlink" title="选举新的主节点"></a>选举新的主节点</h3><p><img src="/.com//%E9%80%89%E4%B8%BE%E6%96%B0%E7%9A%84%E4%B8%BB%E8%8A%82%E7%82%B9.jpg" alt="选举新的主节点">    </p>
<h2 id="7-集群运维"><a href="#7-集群运维" class="headerlink" title="7.集群运维"></a>7.集群运维</h2><h1 id="八、缓存设计"><a href="#八、缓存设计" class="headerlink" title="八、缓存设计"></a>八、缓存设计</h1><h2 id="1-缓存的收益和成本分析"><a href="#1-缓存的收益和成本分析" class="headerlink" title="1.缓存的收益和成本分析"></a>1.缓存的收益和成本分析</h2><p>收益：加速度写；降低后端负载。<br>成本：数据不一致性；代码维护成本；运维成本。  </p>
<h2 id="2-缓存更新策略的选择和使用场景"><a href="#2-缓存更新策略的选择和使用场景" class="headerlink" title="2.缓存更新策略的选择和使用场景"></a>2.缓存更新策略的选择和使用场景</h2><p>缓存更新策略：LRU/LFU/FIFO算法剔除；超时剔除；主动更新。<br>低一致性业务建议配置最大内存和淘汰策略的方式使用；高一致性业务可以结合使用超时剔除和主动更新。    </p>
<h2 id="3-缓存粒度控制方法"><a href="#3-缓存粒度控制方法" class="headerlink" title="3.缓存粒度控制方法"></a>3.缓存粒度控制方法</h2><p>通用性：实际来看很长时间内应用只需要几个重要的属性；<br>空间占用；<br>代码维护。  </p>
<h2 id="4-穿透问题优化"><a href="#4-穿透问题优化" class="headerlink" title="4.穿透问题优化"></a>4.穿透问题优化</h2><p>查询一个根本不存在的数据，缓存层和存储层都不会命中，通常，如果从存储层查不到数据则不写入缓存层，这会导致不存在的数据每次请求都回到存储层查找，后端负载加大。<br>基本原因：自身业务代码或者数据出现问题；恶意攻击、爬虫造成大量空命中。<br>缓存空对象：内存空间占用搭，可设置较短的过期时间；缓存层和存储层会有一段时间窗口不一致。<br>布隆过滤器拦截：在访问缓存层和存储层之前，将存在的key用布隆过滤器提前保存，做第一层拦截。  </p>
<h2 id="5-无底洞问题优化"><a href="#5-无底洞问题优化" class="headerlink" title="5.无底洞问题优化"></a>5.无底洞问题优化</h2><p>更多节点性能反而下降。</p>
<h2 id="6-雪崩问题优化"><a href="#6-雪崩问题优化" class="headerlink" title="6.雪崩问题优化"></a>6.雪崩问题优化</h2><p>缓存层不提供服务，造成存储层宕机</p>
<h2 id="7-热点key问题优化"><a href="#7-热点key问题优化" class="headerlink" title="7.热点key问题优化"></a>7.热点key问题优化</h2>]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>study</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis学习-1（持久化、复制、阻塞、内存）</title>
    <url>/2019/10/24/Redis%E5%AD%A6%E4%B9%A0-1/</url>
    <content><![CDATA[<h2 id="Redis命令参考"><a href="#Redis命令参考" class="headerlink" title="Redis命令参考"></a><a href="http://redisdoc.com/index.html" title="Redis命令参考" target="_blank" rel="noopener">Redis命令参考</a></h2><h1 id="一、redis客户端"><a href="#一、redis客户端" class="headerlink" title="一、redis客户端"></a>一、redis客户端</h1><h2 id="1-客户端通信协议"><a href="#1-客户端通信协议" class="headerlink" title="1. 客户端通信协议"></a>1. 客户端通信协议</h2><p>客户端与服务器的通信在TCP协议上构建；<br>Redis制定了RESP序列化协议实现交互  </p>
<h2 id="2-Java客户端Jedis"><a href="#2-Java客户端Jedis" class="headerlink" title="2. Java客户端Jedis"></a>2. Java客户端Jedis</h2><p>第三方开发包  </p>
<pre><code>Jedis jedis = new Jedis(&quot;127.0.0.1&quot;,6379);
jedis.set(&quot;hello&quot;,&quot;world&quot;);
String value = jedis.get(&quot;hello&quot;)  </code></pre><p>jedis连接池：频繁访问redis时用<br>预先初始化好redis连接<br>JedisPool类  common-pool资源管理工具  </p>
<h2 id="3-Python客户端redis-py"><a href="#3-Python客户端redis-py" class="headerlink" title="3. Python客户端redis-py"></a>3. Python客户端redis-py</h2><pre><code>import redis  
client = redis.StrictRedis(host=&quot;127.0.0.1&quot;,port=6379)  
client.set(key,&quot;python-redis&quot;)  
client.get(key)   


//生成pipeline
pipeline = client.pipeline(transaction= False)  
pipeline.set(&quot;hello&quot;,&quot;world&quot;)  
pipeline.incr(&quot;counter&quot;)  
result = pipeline.execute()  
可用pipeline实现mdel（批量删除功能）</code></pre><h2 id="4-客户端管理"><a href="#4-客户端管理" class="headerlink" title="4. 客户端管理"></a>4. 客户端管理</h2><h3 id="客户端API"><a href="#客户端API" class="headerlink" title="客户端API"></a>客户端API</h3><h4 id="1）-client-list-列出所有与服务端相连的客户端信息"><a href="#1）-client-list-列出所有与服务端相连的客户端信息" class="headerlink" title="1） client list  列出所有与服务端相连的客户端信息"></a>1） client list  列出所有与服务端相连的客户端信息</h4><p>参数包含：   </p>
<h5 id="id-addr-fd-name"><a href="#id-addr-fd-name" class="headerlink" title="id,addr,fd,name"></a>id,addr,fd,name</h5><h5 id="输入缓冲区：qbuf，qbuf-free"><a href="#输入缓冲区：qbuf，qbuf-free" class="headerlink" title="输入缓冲区：qbuf，qbuf-free"></a>输入缓冲区：qbuf，qbuf-free</h5><p>一旦某个客户端的输入缓冲区超过1G，客户端将被关闭（redis的处理速度跟不上输入缓冲区的输入速度）<br>解决： 通过client list命令； 或通过info命令的info clients模块，找到最大的输入缓冲区，设置超过IOM报警    </p>
<h5 id="输出缓冲区：-obl（固定缓冲区数组长度）-oll（动态缓冲区列表长度）-omem（使用的字节数）"><a href="#输出缓冲区：-obl（固定缓冲区数组长度）-oll（动态缓冲区列表长度）-omem（使用的字节数）" class="headerlink" title="输出缓冲区： obl（固定缓冲区数组长度）,oll（动态缓冲区列表长度）,omem（使用的字节数）"></a>输出缓冲区： obl（固定缓冲区数组长度）,oll（动态缓冲区列表长度）,omem（使用的字节数）</h5><p>保存命令执行的结果返回给客户端<br>可通过client-outlut-buffer-limit来设置<br>客户端：普通客户端、发布订阅客户端、slave客户端（用于复制）<br>缓冲区分为固定缓冲区和动态缓冲区<br>监控方法：  </p>
<ul>
<li>定期执行client list命令；  </li>
<li>通过info命令的info clients模块，找到输出缓冲区的列表最大对象数client_longest_output_list  </li>
</ul>
<p>预防方法：  </p>
<ul>
<li>监控设置阈值；  </li>
<li>限制普通客户端的输入缓冲区的hard limit,soft limit,soft seconds；  </li>
<li>适当增大slave客户端的hard limit,soft limit,soft seconds；   </li>
<li>限制容易让输出缓冲区增大的命令；  </li>
<li>及时监控内存。</li>
</ul>
<h5 id="客户端的存活状态：-age-idle"><a href="#客户端的存活状态：-age-idle" class="headerlink" title="客户端的存活状态： age idle"></a>客户端的存活状态： age idle</h5><h5 id="客户端的限制：-maxclients（限制最大客户端连接数），timeout（限制连接的最大空闲时间）-（通过info-clients查询）"><a href="#客户端的限制：-maxclients（限制最大客户端连接数），timeout（限制连接的最大空闲时间）-（通过info-clients查询）" class="headerlink" title="客户端的限制： maxclients（限制最大客户端连接数），timeout（限制连接的最大空闲时间） （通过info clients查询）"></a>客户端的限制： maxclients（限制最大客户端连接数），timeout（限制连接的最大空闲时间） （通过info clients查询）</h5><h4 id="2）-client-setName和client-getName"><a href="#2）-client-setName和client-getName" class="headerlink" title="2） client setName和client getName"></a>2） client setName和client getName</h4><p>设置名字  </p>
<h4 id="3）-client-kill"><a href="#3）-client-kill" class="headerlink" title="3） client kill"></a>3） client kill</h4><p>杀掉指定ip和端口的客户端  </p>
<h4 id="4）-client-pause"><a href="#4）-client-pause" class="headerlink" title="4） client pause"></a>4） client pause</h4><p>阻塞客户端timeout毫秒数  </p>
<h4 id="5）-monitor"><a href="#5）-monitor" class="headerlink" title="5） monitor"></a>5） monitor</h4><p>监控Redis正在执行的命令  </p>
<h3 id="客户端相关配置"><a href="#客户端相关配置" class="headerlink" title="客户端相关配置"></a>客户端相关配置</h3><p>timeout maxclients tcp-keepalive  tcp-backlog  </p>
<h3 id="客户端统计片段"><a href="#客户端统计片段" class="headerlink" title="客户端统计片段"></a>客户端统计片段</h3><p>info clients命令    </p>
<h3 id="客户端常见异常"><a href="#客户端常见异常" class="headerlink" title="客户端常见异常"></a>客户端常见异常</h3><ul>
<li>无法从连接池获取连接；  </li>
<li>客户端读写超时；  </li>
<li>客户端连接超时；  </li>
<li>客户端缓冲区异常；  </li>
<li>Lua脚本正在执行；  </li>
<li>Redis正在加持持久化文件；  </li>
<li>Redis使用的内存超过maxmemory配置；  </li>
<li>客户端连接数过大。  </li>
</ul>
<hr>
<h1 id="二、持久化"><a href="#二、持久化" class="headerlink" title="二、持久化"></a>二、持久化</h1><p>避免因进程退出造成的数据丢失，当下次重启时利用之前持久化的文件可实现数据恢复。<br>RDB和AOF  </p>
<h2 id="1-RDB"><a href="#1-RDB" class="headerlink" title="1. RDB"></a>1. RDB</h2><p>RDB持久化是把当前进程数据生成快照保存到硬盘的过程。分为手动触发和自动触发。  </p>
<p>触发机制  </p>
<h3 id="1）手动触发：save和bgsave"><a href="#1）手动触发：save和bgsave" class="headerlink" title="1）手动触发：save和bgsave"></a>1）手动触发：save和bgsave</h3><p>save: 阻塞当前redis服务器，知道RDB过程完成；<br>bgsave：redis进程执行fork操作创建子进程，RDB持久化过程由子进程负责，完成后自动结束。阻塞只发生在fork阶段。  </p>
<h3 id="2）自动触发："><a href="#2）自动触发：" class="headerlink" title="2）自动触发："></a>2）自动触发：</h3><ul>
<li>使用save相关配置，save m n：m秒内数据集存在n次修改时自动触发bgsave；  </li>
<li>如果从节点执行全量复制操作，主节点自动执行bgsave生成RDB文件并发送给从节点；  </li>
<li>执行debug-reload命令重新加载Redis时，也会自动触发；  </li>
<li>默认情况下执行shutdown命令时，如果没有开启AOF持久化功能则自动执行bgsave。  </li>
</ul>
<h4 id="bgsave流程："><a href="#bgsave流程：" class="headerlink" title="bgsave流程："></a>bgsave流程：</h4><ul>
<li>执行bgsave命令，父进程判断当前是否有正在执行的子进程，如果有，直接返回；  </li>
<li>父进程执行fork操作创建子进程，fork过程父进程会阻塞；  </li>
<li>父进程fork完成后，bgsave命令返回信息并不再阻塞；  </li>
<li>子进程创建RDB文件，根据父进程内存生成临时快照文件，完成后对原有文件进行原子替换；  </li>
<li>进程发送信号给父进程表示完成。  </li>
</ul>
<h4 id="RDB文件的处理："><a href="#RDB文件的处理：" class="headerlink" title="RDB文件的处理："></a>RDB文件的处理：</h4><ul>
<li>保存：dir配置指定的目录下；  </li>
<li>压缩：默认采用LZF算法压缩处理，压缩以后的文件远远小于内存大小，默认开启。  </li>
</ul>
<h4 id="RBS的优缺点："><a href="#RBS的优缺点：" class="headerlink" title="RBS的优缺点："></a>RBS的优缺点：</h4><p>优点：  </p>
<pre><code>RDB时一个紧凑压缩的二进制文件，代表Redis在某个时间点上的数据快照。非常适合用于备份，全量复制等场景。  
Redis加载RDB恢复数据远远快于AOF方式。  </code></pre><p>缺点：  </p>
<pre><code>RDB方式数据没办法做到实施持久化/秒级持久化。因为bgsave每次运行时都要执行fork操作创建子进程，属于重量级操作，频繁操作成本过高。  
RDB文件使用特定二进制格式保存，Redis版本演进过程中有多个格式的RDB版本，存在无法兼容问题。  </code></pre><h2 id="2-AOF"><a href="#2-AOF" class="headerlink" title="2. AOF"></a>2. AOF</h2><p>以独立日志的方式记录每次写命令，重启时重新执行AOF文件中的命令达到数据恢复的目的。<br><span style="color:red;">解决了数据持久化的实时性，目前是Redis持久化的主流方式。 </span>  </p>
<p>使用AOF<br>设置配置：appendonly yes  </p>
<ul>
<li>保存：dir配置指定的目录下；  </li>
<li>压缩：默认采用LZF算法压缩处理，压缩以后的文件远远小于内存大小，默认开启。  </li>
</ul>
<h4 id="RBS的优缺点：-1"><a href="#RBS的优缺点：-1" class="headerlink" title="RBS的优缺点："></a>RBS的优缺点：</h4><p>优点：  </p>
<pre><code>RDB时一个紧凑压缩的二进制文件，代表Redis在某个时间点上的数据快照。非常适合用于备份，全量复制等场景。  
Redis加载RDB恢复数据远远快于AOF方式。  </code></pre><p>缺点：  </p>
<pre><code>RDB方式数据没办法做到实施持久化/秒级持久化。因为bgsave每次运行时都要执行fork操作创建子进程，属于重量级操作，频繁操作成本过高。  
RDB文件使用特定二进制格式保存，Redis版本演进过程中有多个格式的RDB版本，存在无法兼容问题。  </code></pre><h2 id="2-AOF-1"><a href="#2-AOF-1" class="headerlink" title="2. AOF"></a>2. AOF</h2><p>以独立日志的方式记录每次写命令，重启时重新执行AOF文件中的命令达到数据恢复的目的。<br><span style="color:red;">工作流程：  命令写入（append）、文件同步（sync）、文件重写（rewrite）、重新加载（load）。</span>  </p>
<h3 id="流程："><a href="#流程：" class="headerlink" title="流程："></a>流程：</h3><ul>
<li>所有的写入命令会追加到aof_buf（缓冲区）中；  </li>
<li>AOF缓冲区根据对应的策略想硬盘做数据同步；  </li>
<li>随着AOF文件越来越大，需要定期对AOF文件进行重写，达到压缩的目的；  </li>
<li>当Redis服务器重启的时候，可以加载AOF文件进行数据恢复。   </li>
</ul>
<h3 id="1-命令写入"><a href="#1-命令写入" class="headerlink" title="1)命令写入"></a>1)命令写入</h3><p>文本协议格式：具有很好的兼容性；追加操作避免二次开销；具有可读性，方便修改处理。<br>把命令追加到缓冲区中：Redis只用单线程响应命令，如果每次写AOF命令都直接追加到硬盘，那么性能完全取决于硬盘负载。写到缓冲区中还可以有多种缓冲区同步硬盘的策略。  </p>
<h3 id="2-文件同步"><a href="#2-文件同步" class="headerlink" title="2)文件同步"></a>2)文件同步</h3><p>appendfsync控制同步文件策略<br>系统调用write和fsync<br>默认配置everysec，命令写入aof_buf后调用系统write操作，write完成后线程返回。fsync同步文件操作由专门线程每秒调用一次。理论上只有在突然宕机的情况下丢失一秒数据。  </p>
<h3 id="3-重写机制"><a href="#3-重写机制" class="headerlink" title="3)重写机制"></a>3)重写机制</h3><p>随着命令不断写入AOF，文件会越来越大，Redis引入重写机制压缩文件体积。<br>把Redis进程内的数据转化为写命令同步到新的AOF文件。<br>多条写命令可以合并为一个；<br>进程内已经超时的数据不再写入文件；<br>旧的AOF文件含有无效命令，新的AOF文件只保留最终数据的写入命令。  </p>
<p>手动触发和自动触发。  </p>
<h4 id="AOF重写流程："><a href="#AOF重写流程：" class="headerlink" title="AOF重写流程："></a>AOF重写流程：</h4><ul>
<li>执行AOF重写请求。  </li>
<li>如果当前进程正在进行AOF重写，请求不执行；如果当前进程正在执行bgsave操作，重写命令延迟到bgsave完成后再执行。  </li>
<li>父进程执行fork创建子进程，开销等于bgsave过程。  </li>
<li>主进程fork完成后，继续响应其他命令。所有修改命令依然写入AOF缓冲区名根据appendsync策略同步到硬盘；  </li>
<li>由于fork操作运用写时复制技术，子进程只能共享fork操作时的内存数据。由于父进程依然响应命令，Redis使用AOF重写缓冲区来保存这部分新数据，防止AOF文件生成期间丢失这部分数据。  </li>
<li>子进程根据进程快照，按照命令合并规则写入到新的文件。  </li>
<li>新的AOF文件写入完成后，子进程发送信号给父进程。  </li>
<li>父进程把AOF重写缓冲区的数据写入到新的AOF文件。  </li>
<li>使用新的AOF文件替换老文件，完成AOF重写。  </li>
</ul>
<h3 id="4-重启加载"><a href="#4-重启加载" class="headerlink" title="4)重启加载"></a>4)重启加载</h3><p>服务器重启时数据恢复。<br>AOF持久化开启且存在AOF文件时，优先加载AOF文件。<br>AOF关闭时加载RDB文件。<br>加载AOF/RDB文件成功后，Redis启动成功。  </p>
<h4 id="文件校验"><a href="#文件校验" class="headerlink" title="文件校验"></a>文件校验</h4><p>加载损坏的AOF文件时会拒绝启动。   </p>
<h2 id="3-问题定位与优化"><a href="#3-问题定位与优化" class="headerlink" title="3. 问题定位与优化"></a>3. 问题定位与优化</h2><h3 id="1-fork操作"><a href="#1-fork操作" class="headerlink" title="1) fork操作"></a>1) fork操作</h3><p>Redis做RDB和AOF重写要执行fork操作创建子进程，fork操作是个重量级操作。<br>fork创建的子进程不需要拷贝父进程的物理内粗空间，但会复制父进程的空间内存页表。<br>fork操作耗时跟进程总内存量息息相关。  </p>
<h4 id="fork耗时问题定位："><a href="#fork耗时问题定位：" class="headerlink" title="fork耗时问题定位："></a>fork耗时问题定位：</h4><p>fork操作耗时再秒级会拖慢Redis几万条命令执行，对线上应用延迟影响非常明显。<br>正常情况下fork操作应该是每GB消耗20毫秒左右。  </p>
<h4 id="改善fork操作耗时："><a href="#改善fork操作耗时：" class="headerlink" title="改善fork操作耗时："></a>改善fork操作耗时：</h4><p>优先使用物理机或者高效支持fork操作的虚拟化技术，避免使用Xen虚拟机。<br>控制Redis实例最大可用内存，fork耗时跟内存量成正比，线上建议每个Redis实例内存控制在10GB以内。<br>合理配置Linux内存分配策略，避免物理内存不足导致fork失败。<br>降低fork操作的频率。    </p>
<h3 id="2-子进程开销监控和优化"><a href="#2-子进程开销监控和优化" class="headerlink" title="2) 子进程开销监控和优化"></a>2) 子进程开销监控和优化</h3><p>子进程负责AOF或者RDB的重写，运行过程主要涉及CPU、内存、硬盘三部分的消耗。  </p>
<h4 id="CPU"><a href="#CPU" class="headerlink" title="CPU"></a>CPU</h4><p>CPU开销：子进程负责把进程内的数据分批写入文件，这个过程属于CPU密集操作，通常子进程对单核CPU利用率接近90%。<br>CPU消耗优化：不要和其他CPU密集型服务部署在一起，造成CPU过度竞争；如果部署多个Redis实例，尽量保证同一时刻也只有一个子进程执行重写操作。  </p>
<h4 id="内存"><a href="#内存" class="headerlink" title="内存"></a>内存</h4><p>内存消耗：子进程通过fork操作产生，占用内存大小等于父进程，理论山需要两倍的内存来完成持久化操作。<br>消耗优化：如果部署多个Redis实例，尽量保证同一时刻也只有一个子进程执行重写操作；避免在大量写入时做子进程重写操作，这样将导致父进程维护大量页副本，造成内存消耗，  </p>
<h4 id="硬盘"><a href="#硬盘" class="headerlink" title="硬盘"></a>硬盘</h4><p>硬盘开销：子进程主要职责把AOF或RDB文件写入硬盘持久化。<br>开销优化：不要和其他高硬盘负载的服务器部署在一起；AOF重写期间不做fsync操作；对于单机配置多个Redis实例情况，可配置不同实例分盘存储AOF文件。  </p>
<h3 id="3-AOF追加阻塞"><a href="#3-AOF追加阻塞" class="headerlink" title="3) AOF追加阻塞"></a>3) AOF追加阻塞</h3><p>当开启AOF持久化时，常用同步硬盘策略everysec，Redis使用另一条线程每秒执行fsync同步硬盘。当系统硬盘资源繁忙时，会造成Redis主线程阻塞。<br>阻塞流程：  </p>
<ul>
<li>主线程负责写入AOF缓冲区；  </li>
<li>AOF线程负责每秒执行一次同步硬盘操作，并记录最近一次同步时间。  </li>
<li>主线程负责对比上次AOF同步时间：<br> 如果据上次同步成功时间在2秒以内，主线程直接返回；<br> 如果据上次同步成功时间超过2秒，主线程将会阻塞，直到同步操作完成。   </li>
</ul>
<p>everysec配置最多可能丢失2秒数据，不是1秒。<br>如果fsync缓慢，将会导致Redis主线程阻塞影响效率。  </p>
<h3 id="4-多实例部署"><a href="#4-多实例部署" class="headerlink" title="4) 多实例部署"></a>4) 多实例部署</h3><p>Redis单线程架构导致无法充分利用CPU多核特性。</p>
<hr>
<h1 id="三、复制"><a href="#三、复制" class="headerlink" title="三、复制"></a>三、复制</h1><p>相同数据的多个Redis副本。<br>复制功能是高可用Redis的基础。  </p>
<h2 id="1-配置"><a href="#1-配置" class="headerlink" title="1. 配置"></a>1. 配置</h2><h3 id="1）建立复制："><a href="#1）建立复制：" class="headerlink" title="1）建立复制："></a>1）建立复制：</h3><p>复制的数据流是单项的，只能从主节点复制到从节点。<br>一个从节点只能有一个主节点，一个主节点可以有多个从节点。<br>slaveof命令复制<br>slaveof配置是在从节点发起。<br>6380：slaveof 127.0.0.1 6379<br>针对主节点6379的任何修改都会同步到从节点6380.<br>slaveof本身是异步命令   </p>
<h3 id="2）断开复制"><a href="#2）断开复制" class="headerlink" title="2）断开复制"></a>2）断开复制</h3><p>在从节点执行slaveof no one<br>断开与主节点复制关系；从节点晋升为主节点。（不会抛弃原有数据）  </p>
<h4 id="切主操作：把当前从节点对主节点的复制切换到另一个主节点。"><a href="#切主操作：把当前从节点对主节点的复制切换到另一个主节点。" class="headerlink" title="切主操作：把当前从节点对主节点的复制切换到另一个主节点。"></a>切主操作：把当前从节点对主节点的复制切换到另一个主节点。</h4><p>切主操作流程：  </p>
<ul>
<li>断开与旧主节点复制关系；<br>与新主节点建立复制关系；<br>删除从节点当前所有数据；<br>对新主节点进行复制。  </li>
</ul>
<h3 id="3）安全性：设置参数进行密码验证。"><a href="#3）安全性：设置参数进行密码验证。" class="headerlink" title="3）安全性：设置参数进行密码验证。"></a>3）安全性：设置参数进行密码验证。</h3><h3 id="4）只读：默认从节点只读。对从节点的修改不会同步到主节点。"><a href="#4）只读：默认从节点只读。对从节点的修改不会同步到主节点。" class="headerlink" title="4）只读：默认从节点只读。对从节点的修改不会同步到主节点。"></a>4）只读：默认从节点只读。对从节点的修改不会同步到主节点。</h3><h3 id="5）传输延迟：repl-disable-tcp-nodelay控制是否关闭延迟。"><a href="#5）传输延迟：repl-disable-tcp-nodelay控制是否关闭延迟。" class="headerlink" title="5）传输延迟：repl-disable-tcp-nodelay控制是否关闭延迟。"></a>5）传输延迟：repl-disable-tcp-nodelay控制是否关闭延迟。</h3><h2 id="2-拓扑"><a href="#2-拓扑" class="headerlink" title="2. 拓扑"></a>2. 拓扑</h2><p>一主一从、一主多从、树状主从结构。  </p>
<h3 id="1）一主一从结构"><a href="#1）一主一从结构" class="headerlink" title="1）一主一从结构"></a>1）一主一从结构</h3><p>主节点出现宕机时从节点提供故障转移支持。当应用写命令并发量较高且需要持久化时，可以只在从节点上开启AOF，保证数据安全性也避免了持久化对主节点的性能干扰。<br>当主节点关闭持久化时，如果主节点脱机套避免自动重启操作。（因为主节点没有开启持久化重启后数据集为空，从节点继续复制主节点会导致从节点数据清空。）应在从节点上执行slaveof no one断开与主节点的复制关系，再重启主节点。  </p>
<h3 id="2）一主多从结构"><a href="#2）一主多从结构" class="headerlink" title="2）一主多从结构"></a>2）一主多从结构</h3><p>应用端可以利用多个从节点实现读写分离。<br>对于读占比较大的场景，可以把都命令发送到从节点来分担主节点压力。如果要执行比较耗时的都命令，可以在一台从节点上进行，防止阻塞。<br>对于写并发量较高的场景，多个从节点会导致主节点写命令的多次发送而过渡消耗网络带宽，同时也加重了主节点的负载。  </p>
<h3 id="3）树状主从结构"><a href="#3）树状主从结构" class="headerlink" title="3）树状主从结构"></a>3）树状主从结构</h3><p>从节点不断可以复制主节点的数据，同时可以作为其他从节点的主节点继续向下复制。<br>通过引用复制中间层，可以有效地降低主节点负载和需要传送给从节点的数据量。   </p>
<h2 id="2-原理"><a href="#2-原理" class="headerlink" title="2. 原理"></a>2. 原理</h2><h3 id="1）复制过程"><a href="#1）复制过程" class="headerlink" title="1）复制过程"></a>1）复制过程</h3><p><img src="/.com//%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E8%BF%87%E7%A8%8B.PNG" alt="主从复制过程"></p>
<p>保存主节点信息；（地址信息）    </p>
<ul>
<li>主从建立socket连接；  </li>
<li>发送ping命令；  </li>
<li>权限验证；  </li>
<li>同步数据集；  </li>
<li>命令持续复制。  </li>
</ul>
<h3 id="2）数据同步"><a href="#2）数据同步" class="headerlink" title="2）数据同步"></a>2）数据同步</h3><p>psync命令完成数据同步，全量复制（初次复制）和部分复制（补发丢失数据）<br>psync命令运行需要组件：  </p>
<ul>
<li>主从节点各自复制偏移量：主节点在处理完写入命令后，会把命令的字节长度做累加记录，从节点每秒钟会上报自身的复制偏移量给主节点，在收到主节点发送的命令后，也会累加记录自身的偏移量。通过对比主从节点的复制偏移量判断数据是否一致。  </li>
<li>复制积压缓冲区：是保存在主节点上的一个固定长度的队列，当主节点有连接的从节点时被创建，主节点响应写命令时，会把命令发送给从节点和复制积压缓冲区，实现保存最近已复制数据的功能，用于部分复制和复制命令丢失的数据补救。  </li>
<li>主节点运行ID：唯一识别Redis节点，Redis关闭再启动，运行ID会改变。  可以通过配置不改变ID重启。  </li>
</ul>
<p>psync命令<br><span style="color:red;">psync runID offset</span></p>
<h4 id="全量复制"><a href="#全量复制" class="headerlink" title="全量复制"></a>全量复制</h4><p>主从第一次建立复制必须全量  </p>
<ul>
<li>从节点发送psync ? -1；  </li>
<li>主节点解析出全量复制，回复；  </li>
<li>从节点接收主节点响应数据保存runID和偏移量offset；  </li>
<li>主节点执行bgsave保存RDB文件到本地；  </li>
<li>主节点发送RDB文件给从节点，从节点接收所谓数据文件。<br>（针对数据量较大的节点，建议调大repl-timeout参数防止出现全量同步数据超时。）  </li>
<li>对于从节点开始接收RDB文件快照到接收完成期间，主节点仍然响应读写命令，保存在复制客户端缓冲区内。（为防止主节点复制客户端缓冲区溢出，要调整client-outbut-buffer-limit slave配置  </li>
<li>从节点接收完主节点传送来的全部数据会清空自身旧数据；  </li>
<li>清空后加载RDB文件；  </li>
<li>加载完，如果当前节点开启了AOF持久化，会立即做bgrewriteaof操作，为了保证全量复制后AOF持久化文件立刻使用。  </li>
</ul>
<p>复制过程时间开销：  </p>
<ul>
<li>主节点bgsave时间；  </li>
<li>RDB文件网络传输时间；  </li>
<li>从节点清空数据时间；  </li>
<li>从节点加载RDB时间；  </li>
<li>可能的AOF重写时间。   </li>
</ul>
<h4 id="部分复制"><a href="#部分复制" class="headerlink" title="部分复制"></a>部分复制</h4><p>psync runID offset<br>当从节点正在复制主节点时，如果出现网络闪断或者命令丢失等异常情况，从节点会问主节点要求补发丢失的命令数据，如果主节点的复制积压缓冲区存在则直接发送。<br>流程：  </p>
<ul>
<li>网络中断打印日志；  </li>
<li>中断期间主节点依然响应命令，写入复制积压缓冲区；  </li>
<li>网络恢复连接；  </li>
<li>从节点发送自身runID和偏移量offset；  </li>
<li>主节点核对查找缓冲区；  </li>
<li>主节点发送数据。  </li>
</ul>
<h3 id="3）心跳：主从节点在建立复制后，他们维护着长连接并彼此发送心跳命令。"><a href="#3）心跳：主从节点在建立复制后，他们维护着长连接并彼此发送心跳命令。" class="headerlink" title="3）心跳：主从节点在建立复制后，他们维护着长连接并彼此发送心跳命令。"></a>3）心跳：主从节点在建立复制后，他们维护着长连接并彼此发送心跳命令。</h3><h3 id="4）异步复制"><a href="#4）异步复制" class="headerlink" title="4）异步复制"></a>4）异步复制</h3><p>主节点数据读写并把写命令同步给从节点，写命令的发送是异步完成。  </p>
<h2 id="3-开发与运维中的问题"><a href="#3-开发与运维中的问题" class="headerlink" title="3. 开发与运维中的问题"></a>3. 开发与运维中的问题</h2><h3 id="1）读写分离"><a href="#1）读写分离" class="headerlink" title="1）读写分离"></a>1）读写分离</h3><p>对于读占比较高的场景，可以通过把一部分读流量分摊到从节点来减轻主节点压力，但需永远只对主节点执行写操作。<br>从节点响应读请求可能会遇到：<br>复制数据延迟；  </p>
<ul>
<li><p>读到过期数据；  </p>
</li>
<li><p>主节点惰性删除和定时删除。</p>
</li>
<li><p>从节点故障。  </p>
<h3 id="2）主从配置不一致"><a href="#2）主从配置不一致" class="headerlink" title="2）主从配置不一致"></a>2）主从配置不一致</h3><h3 id="3）规避全量复制"><a href="#3）规避全量复制" class="headerlink" title="3）规避全量复制"></a>3）规避全量复制</h3></li>
<li><p>第一次建立复制（低峰操作）；  </p>
</li>
<li><p>节点运行ID不匹配（主节点重启，ID改变，从节点会全量复制。  应手动提升从节点为主节点，或采用支持故障自动转移的哨兵或集群）  </p>
</li>
<li><p>复制积压缓冲区不足：增大。  </p>
</li>
</ul>
<h3 id="4）规避复制风暴"><a href="#4）规避复制风暴" class="headerlink" title="4）规避复制风暴"></a>4）规避复制风暴</h3><h4 id="单主节点复制风暴"><a href="#单主节点复制风暴" class="headerlink" title="单主节点复制风暴"></a>单主节点复制风暴</h4><p>主节点恢复重启，多个从节点全量同步。<br>解决：减少主节点挂载从节点，或者采用树状复制结构。  </p>
<h4 id="单机器复制风暴"><a href="#单机器复制风暴" class="headerlink" title="单机器复制风暴"></a>单机器复制风暴</h4><p>解决：主节点分散到多台机器上，提供故障转移机制</p>
<hr>
<h1 id="四、阻塞"><a href="#四、阻塞" class="headerlink" title="四、阻塞"></a>四、阻塞</h1><ul>
<li>内在原因：API或数据结构使用不合理（慢查询–转为低算法度，发现大对象）；CPU饱和（判断并发量是否达到极限，集群化水平扩展分摊压力）；持久化相关的阻塞（fork阻塞，AOF刷盘阻塞）。  </li>
<li>外在原因：CPU竞争；内存交换；网络问题。<br>  CPU竞争：进程竞争（和其他服务竞争）；绑定CPU（Redis绑定在CPU上，父进程创建子进程进行重写，父子进程共享CPU，子进程重写CPU使用率&gt;90%，父子竞争，所以持久化或复制节点不建议绑定CPU）<br>  内存交换：需保证机器充足的可用内存；确保所有实例设置最大可用内存；降低系统使用Swap优先级。<br>  网络问题：连接拒绝；网络延迟；网卡软中断。  </li>
</ul>
<hr>
<h1 id="五、理解内存"><a href="#五、理解内存" class="headerlink" title="五、理解内存"></a>五、理解内存</h1><h2 id="1-内存消耗"><a href="#1-内存消耗" class="headerlink" title="1. 内存消耗"></a>1. 内存消耗</h2><p>内存使用统计：执行info memory命令<br><strong>内存消耗划分：自身内存（消耗非常少）+对象内存+缓冲内存+内存碎片</strong><br>对象内存：数据存储<br>缓冲内存：客户端缓冲、复制积压缓冲区、AOF缓冲区<br>客户端缓冲区：输入缓冲无法控制，最大1G，输出缓冲可以控制；<br>复制积压缓冲区可设置较大值；<br>AOF缓冲用户无法控制。<br>内存碎片：存储数据长短差异较大会出现高内存碎片  </p>
<h3 id="子进程内存消耗"><a href="#子进程内存消耗" class="headerlink" title="子进程内存消耗"></a>子进程内存消耗</h3><p>执行AOF/RDB重写时Redis创建的子进程内存消耗。Redis执行fork操作产生的子进程内存占用量对外表现为与父进程相同，理论上需要一倍的物理内存来完成重写操作。但Linux具有写时复制技术，父子进程会共享相同的物理内存页，当父进程处理写请求时会对需要修改的页复制出一份副本完成写操作，而子进程依然读取fork时整个父进程的内存快照。<br>需要设置sysctl vm.overcommit_memory=1来允许内核可以分配所有的物理内存，防止Redis进程执行fork时因系统剩余内存不足而失败。  </p>
<h2 id="2-内存管理"><a href="#2-内存管理" class="headerlink" title="2. 内存管理"></a>2. 内存管理</h2><p>设置内存上限<br>Redis使用maxmemory参数限制最大可用内存。（限制的是实际使用的内存量）<br>动态调整内存上限<br>通过config set maxmemory进行动态修改  </p>
<p><strong>Redis默认无限使用服务器内存</strong>    </p>
<h2 id="3-内存回收策略"><a href="#3-内存回收策略" class="headerlink" title="3. 内存回收策略"></a>3. 内存回收策略</h2><h3 id="1）删除达到过期时间的键对象（惰性删除、定时任务删除）"><a href="#1）删除达到过期时间的键对象（惰性删除、定时任务删除）" class="headerlink" title="1）删除达到过期时间的键对象（惰性删除、定时任务删除）"></a>1）删除达到过期时间的键对象（惰性删除、定时任务删除）</h3><p>过期删除策略：<br>1、定时删除<br>对于每一个设置了过期时间的key都会创建一个定时器，一旦到达过期时间就立即删除。该策略可以立即清除过期的数据，对内存较友好，但是缺点是占用了大量的CPU资源去处理过期的数据，会影响Redis的吞吐量和响应时间。<br>2、惰性删除<br>当访问一个key时，才判断该key是否过期，过期则删除。该策略能最大限度地节省CPU资源，但是对内存却十分不友好。有一种极端的情况是可能出现大量的过期key没有被再次访问，因此不会被清除，导致占用了大量的内存。<br>在计算机科学中，懒惰删除（英文：lazy deletion）指的是从一个散列表（也称哈希表）中删除元素的一种方法。在这个方法中，删除仅仅是指标记一个元素被删除，而不是整个清除它。被删除的位点在插入时被当作空元素，在搜索之时被当作已占据。<br>3、定期删除<br>每隔一段时间，扫描Redis中过期key字典，并清除部分过期的key。该策略是前两者的一个折中方案，还可以通过调整定时扫描的时间间隔和每次扫描的限定耗时，在不同情况下使得CPU和内存资源达到最优的平衡效果。</p>
<p><span style="color:red;">在Redis中，同时使用了定期删除和惰性删除。</span>    </p>
<h3 id="2）内存使用到达maxmemory上限时触发内存溢出控制策略"><a href="#2）内存使用到达maxmemory上限时触发内存溢出控制策略" class="headerlink" title="2）内存使用到达maxmemory上限时触发内存溢出控制策略"></a>2）内存使用到达maxmemory上限时触发内存溢出控制策略</h3><p>内存淘汰策略<br>Redis的内存淘汰策略，是指内存达到maxmemory极限时，使用某种算法来决定清理掉哪些数据，以保证新数据的存入。</p>
<p>Redis的内存淘汰机制：  </p>
<ul>
<li>volatile-lru -&gt; 根据LRU算法生成的过期时间来删除。  </li>
<li>allkeys-lru -&gt; 根据LRU算法删除任何key。  </li>
<li>volatile-random -&gt; 根据过期设置来随机删除key。  </li>
<li>allkeys-random -&gt; 无差别随机删。  </li>
<li>volatile-ttl -&gt; 根据最近过期时间来删除（辅以TTL）  </li>
<li>noeviction -&gt; 谁也不删，直接在写操作时返回错误。  </li>
</ul>
<p>什么时候会进行淘汰？<br>Redis会在每一次处理命令的时候（processCommand函数调用freeMemoryIfNeeded）判断当前redis是否达到了内存的最大限制，如果达到限制，则使用对应的算法去处理需要删除的key。   </p>
<h2 id="4-内存优化"><a href="#4-内存优化" class="headerlink" title="4. 内存优化"></a>4. 内存优化</h2><h3 id="1）RedisObject对象"><a href="#1）RedisObject对象" class="headerlink" title="1）RedisObject对象"></a>1）RedisObject对象</h3><p>结构体：type、encoding、lru、refcount、*ptr字段  </p>
<h3 id="2）缩减键值对象"><a href="#2）缩减键值对象" class="headerlink" title="2）缩减键值对象"></a>2）缩减键值对象</h3><p>降低Redis内存使用最直接的方式就是缩减键（key）和值（value）的长度。<br>key长度：如在设计键时，在完整描述业务情况下，键值越短越好。<br>value长度：值对象缩减比较复杂，常见需求是把业务对象序列化成二进制数组放入Redis。首先应该在业务上精简业务对象，去掉不必要的属性避免存储无效数据。其次在序列化工具选择上，应该选择更高效的序列化工具来降低字节数组大小。以JAVA为例，内置的序列化方式无论从速度还是压缩比都不尽如人意，这时可以选择更高效的序列化工具，如: protostuff，kryo等。  </p>
<h3 id="3）共享对象池"><a href="#3）共享对象池" class="headerlink" title="3）共享对象池"></a>3）共享对象池</h3><p>对象共享池指Redis内部维护[0-9999]的整数对象池。创建大量的整数类型redisObject存在内存开销，每个redisObject内部结构至少占16字节，甚至超过了整数自身空间消耗。所以Redis内存维护一个[0-9999]的整数对象池，用于节约内存。 除了整数值对象，其他类型如list,hash,set,zset内部元素也可以使用整数对象池。因此开发中在满足需求的前提下，尽量使用整数对象以节省内存。<br><strong>为什么开启maxmemory和LRU淘汰策略后对象池无效?</strong><br>LRU算法需要获取对象最后被访问时间，以便淘汰最长未访问数据，每个对象最后访问时间存储在redisObject对象的lru字段。对象共享意味着多个引用共享同一个redisObject，这时lru字段也会被共享，导致无法获取每个对象的最后访问时间。如果没有设置maxmemory，直到内存被用尽Redis也不会触发内存回收，所以共享对象池可以正常工作。<br>综上所述，共享对象池与maxmemory+LRU策略冲突，使用时需要注意。 对于ziplist编码的值对象，即使内部数据为整数也无法使用共享对象池，因为ziplist使用压缩且内存连续的结构，对象共享判断成本过高，ziplist编码细节后面内容详细说明。</p>
<p><strong>为什么只有整数对象池？</strong><br>首先整数对象池复用的几率最大，其次对象共享的一个关键操作就是判断相等性，Redis之所以只有整数对象池，是因为整数比较算法时间复杂度为O(1)，只保留一万个整数为了防止对象池浪费。如果是字符串判断相等性，时间复杂度变为O(n)，特别是长字符串更消耗性能(浮点数在Redis内部使用字符串存储)。对于更复杂的数据结构如hash,list等，相等性判断需要O(n2)。对于单线程的Redis来说，这样的开销显然不合理，因此Redis只保留整数共享对象池。   </p>
<h3 id="4）字符串优化"><a href="#4）字符串优化" class="headerlink" title="4）字符串优化"></a>4）字符串优化</h3><p>1.字符串结构<br>Redis没有采用原生C语言的字符串类型而是自己实现了字符串结构，内部简单动态字符串(simple dynamic string)，简称SDS。<br>2.预分配机制<br>因为字符串(SDS)存在预分配机制，日常开发中要小心预分配带来的内存浪费，例如下表的测试用例。<br>3.字符串重构<br>字符串重构:指不一定把每份数据作为字符串整体存储，像json这样的数据可以使用hash结构，使用二级结构存储也能帮我们节省内存。同时可以使用hmget,hmset命令支持字段的部分读取修改，而不用每次整体存取。    </p>
<h3 id="5）编码优化"><a href="#5）编码优化" class="headerlink" title="5）编码优化"></a>5）编码优化</h3><p><strong>控制编码类型</strong><br>编码类型转换在Redis写入数据时自动完成，这个转换过程是不可逆的，转换规则只能从小内存编码向大内存编码转换。<br><strong>ziplist编码</strong><br>ziplist编码主要目的是为了节约内存，因此所有数据都是采用线性连续的内存结构。ziplist编码是应用范围最广的一种，可以分别作为hash、list、zset类型的底层数据结构实现。首先从ziplist编码结构开始分析，它的内部结构类似这样:&lt;….&gt;。一个ziplist可以包含多个entry(元素)，每个entry保存具体的数据(整数或者字节数组)。<br><strong>intset编码</strong><br>intset编码是集合(set)类型编码的一种，内部表现为存储有序，不重复的整数集。当集合只包含整数且长度不超过set-max-intset-entries配置时被启用。  </p>
<h3 id="6）控制key的数量"><a href="#6）控制key的数量" class="headerlink" title="6）控制key的数量"></a>6）控制key的数量</h3><p>当使用Redis存储大量数据时，通常会存在大量键，过多的键同样会消耗大量内存。Redis本质是一个数据结构服务器，它为我们提供多种数据结构，如hash，list，set，zset 等结构。使用Redis时不要进入一个误区，大量使用get/set这样的API，把Redis当成Memcached使用。对于存储相同的数据内容利用Redis的数据结构降低外层键的数量，也可以节省大量内存。<br>hash结构降低键数量分析：<br>根据键规模在客户端通过分组映射到一组hash对象中，如存在100万个键，可以映射到1000个hash中，每个hash保存1000个元素。<br>hash的field可用于记录原始key字符串，方便哈希查找。<br>hash的value保存原始值对象，确保不要超过hash-max-ziplist-value限制。  </p>
<hr>
<p><strong>内存优化：</strong><br><strong>精简键值对大小，键值字面量精简，使用高效二进制序列化工具。</strong><br><strong>使用对象共享池优化小证书对象。</strong><br><strong>数据优先使用整数，比字符串类型更节省空间。</strong><br><strong>优先字符串使用，避免预分配造成的内存浪费。</strong><br><strong>使用ziplist压缩编码优化hash、list结构，注重效率和空间的平衡。</strong><br><strong>使用intset编码优化整数集合。</strong><br><strong>使用ziplist编码的hash结构降低小对象链规模。</strong></p>
]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>study</tag>
      </tags>
  </entry>
  <entry>
    <title>redis-cli命令</title>
    <url>/2019/10/18/redis-cli%E5%91%BD%E4%BB%A4/</url>
    <content><![CDATA[<pre><code>systemctl start redis.service #启动redis服务器

systemctl stop redis.service #停止redis服务器

systemctl restart redis.service #重新启动redis服务器

systemctl status redis.service #获取redis服务器的运行状态

systemctl enable redis.service #开机启动redis服务器

systemctl disable redis.service #开机禁用redis服务器</code></pre><h2 id="Redis-redis-cli-命令总结"><a href="#Redis-redis-cli-命令总结" class="headerlink" title="[Redis] redis-cli 命令总结"></a>[Redis] redis-cli 命令总结</h2><p><a href="https://maoxian.de/2015/08/1342.html" target="_blank" rel="noopener">原文链接</a></p>
<p>Redis提供了丰富的命令（command）对数据库和各种数据类型进行操作，这些command可以在Linux终端使用。在编程时，比如使用Redis 的Java语言包，这些命令都有对应的方法。下面将Redis提供的命令做一总结。</p>
<hr>
<p>官网命令列表：<a href="http://redis.io/commands" target="_blank" rel="noopener">http://redis.io/commands</a> （英文）</p>
<hr>
<h3 id="1、连接操作相关的命令"><a href="#1、连接操作相关的命令" class="headerlink" title="1、连接操作相关的命令"></a>1、连接操作相关的命令</h3><ul>
<li>quit：关闭连接（connection）  </li>
<li>auth：简单密码认证  </li>
</ul>
<h3 id="2、对value操作的命令"><a href="#2、对value操作的命令" class="headerlink" title="2、对value操作的命令"></a>2、对value操作的命令</h3><ul>
<li>exists(key)：确认一个key是否存在</li>
<li>del(key)：删除一个key</li>
<li>type(key)：返回值的类型</li>
<li>keys(pattern)：返回满足给定pattern的所有key</li>
<li>randomkey：随机返回key空间的一个key</li>
<li>rename(oldname, newname)：将key由oldname重命名为newname，若newname存在则删除newname表示的key</li>
<li>dbsize：返回当前数据库中key的数目</li>
<li>expire：设定一个key的活动时间（s）</li>
<li>ttl：获得一个key的活动时间</li>
<li>select(index)：按索引查询</li>
<li>move(key, dbindex)：将当前数据库中的key转移到有dbindex索引的数据库</li>
<li>flushdb：删除当前选择数据库中的所有key</li>
<li>flushall：删除所有数据库中的所有key </li>
</ul>
<h3 id="3、对String操作的命令"><a href="#3、对String操作的命令" class="headerlink" title="3、对String操作的命令"></a>3、对String操作的命令</h3><ul>
<li>set(key, value)：给数据库中名称为key的string赋予值value</li>
<li>get(key)：返回数据库中名称为key的string的value</li>
<li>getset(key, value)：给名称为key的string赋予上一次的value</li>
<li>mget(key1, key2,…, key N)：返回库中多个string（它们的名称为key1，key2…）的value</li>
<li>setnx(key, value)：如果不存在名称为key的string，则向库中添加string，名称为key，值为value</li>
<li>setex(key, time, value)：向库中添加string（名称为key，值为value）同时，设定过期时间time</li>
<li>mset(key1, value1, key2, value2,…key N, value N)：同时给多个string赋值，名称为key i的string赋值value i</li>
<li>msetnx(key1, value1, key2, value2,…key N, value N)：如果所有名称为key i的string都不存在，则向库中添加string，名称key i赋值为value i</li>
<li>incr(key)：名称为key的string增1操作</li>
<li>incrby(key, integer)：名称为key的string增加integer</li>
<li>decr(key)：名称为key的string减1操作</li>
<li>decrby(key, integer)：名称为key的string减少integer</li>
<li>append(key, value)：名称为key的string的值附加value</li>
<li>substr(key, start, end)：返回名称为key的string的value的子串  </li>
</ul>
<h3 id="4、对List操作的命令"><a href="#4、对List操作的命令" class="headerlink" title="4、对List操作的命令"></a>4、对List操作的命令</h3><ul>
<li>rpush(key, value)：在名称为key的list尾添加一个值为value的元素</li>
<li>lpush(key, value)：在名称为key的list头添加一个值为value的 元素</li>
<li>llen(key)：返回名称为key的list的长度</li>
<li>lrange(key, start, end)：返回名称为key的list中start至end之间的元素（下标从0开始，下同）</li>
<li>ltrim(key, start, end)：截取名称为key的list，保留start至end之间的元素</li>
<li>lindex(key, index)：返回名称为key的list中index位置的元素</li>
<li>lset(key, index, value)：给名称为key的list中index位置的元素赋值为value</li>
<li>lrem(key, count, value)：删除count个名称为key的list中值为value的元素。count为0，删除所有值为value的元素，count&gt;0从头至尾删除count个值为value的元素，count&lt;0从尾到头删除|count|个值为value的元素。 lpop(key)：返回并删除名称为key的list中的首元素 rpop(key)：返回并删除名称为key的list中的尾元素 blpop(key1, key2,… key N, timeout)：lpop命令的block版本。即当timeout为0时，若遇到名称为key i的list不存在或该list为空，则命令结束。如果timeout&gt;0，则遇到上述情况时，等待timeout秒，如果问题没有解决，则对keyi+1开始的list执行pop操作。</li>
<li>brpop(key1, key2,… key N, timeout)：rpop的block版本。参考上一命令。</li>
<li>rpoplpush(srckey, dstkey)：返回并删除名称为srckey的list的尾元素，并将该元素添加到名称为dstkey的list的头部  </li>
</ul>
<h3 id="5、对Set操作的命令"><a href="#5、对Set操作的命令" class="headerlink" title="5、对Set操作的命令"></a>5、对Set操作的命令</h3><ul>
<li>sadd(key, member)：向名称为key的set中添加元素member</li>
<li>srem(key, member) ：删除名称为key的set中的元素member</li>
<li>spop(key) ：随机返回并删除名称为key的set中一个元素</li>
<li>smove(srckey, dstkey, member) ：将member元素从名称为srckey的集合移到名称为dstkey的集合</li>
<li>scard(key) ：返回名称为key的set的基数</li>
<li>sismember(key, member) ：测试member是否是名称为key的set的元素</li>
<li>sinter(key1, key2,…key N) ：求交集</li>
<li>sinterstore(dstkey, key1, key2,…key N) ：求交集并将交集保存到dstkey的集合</li>
<li>sunion(key1, key2,…key N) ：求并集</li>
<li>sunionstore(dstkey, key1, key2,…key N) ：求并集并将并集保存到dstkey的集合</li>
<li>sdiff(key1, key2,…key N) ：求差集</li>
<li>sdiffstore(dstkey, key1, key2,…key N) ：求差集并将差集保存到dstkey的集合</li>
<li>smembers(key) ：返回名称为key的set的所有元素</li>
<li>srandmember(key) ：随机返回名称为key的set的一个元素  </li>
</ul>
<h3 id="6、对zset（sorted-set）操作的命令"><a href="#6、对zset（sorted-set）操作的命令" class="headerlink" title="6、对zset（sorted set）操作的命令"></a>6、对zset（sorted set）操作的命令</h3><ul>
<li>zadd(key, score, member)：向名称为key的zset中添加元素member，score用于排序。如果该元素已经存在，则根据score更新该元素的顺序。</li>
<li>zrem(key, member) ：删除名称为key的zset中的元素member</li>
<li>zincrby(key, increment, member) ：如果在名称为key的zset中已经存在元素member，则该元素的score增加increment；否则向集合中添加该元素，其score的值为increment</li>
<li>zrank(key, member) ：返回名称为key的zset（元素已按score从小到大排序）中member元素的rank（即index，从0开始），若没有member元素，返回“nil”</li>
<li>zrevrank(key, member) ：返回名称为key的zset（元素已按score从大到小排序）中member元素的rank（即index，从0开始），若没有member元素，返回“nil”</li>
<li>zrange(key, start, end)：返回名称为key的zset（元素已按score从小到大排序）中的index从start到end的所有元素</li>
<li>zrevrange(key, start, end)：返回名称为key的zset（元素已按score从大到小排序）中的index从start到end的所有元素</li>
<li>zrangebyscore(key, min, max)：返回名称为key的zset中score &gt;= min且score &lt;= max的所有元素 zcard(key)：返回名称为key的zset的基数 zscore(key, element)：返回名称为key的zset中元素element的score zremrangebyrank(key, min, max)：删除名称为key的zset中rank &gt;= min且rank &lt;= max的所有元素 zremrangebyscore(key, min, max) ：删除名称为key的zset中score &gt;= min且score &lt;= max的所有元素</li>
<li>zunionstore / zinterstore(dstkeyN, key1,…,keyN, WEIGHTS w1,…wN, AGGREGATE SUM|MIN|MAX)：对N个zset求并集和交集，并将最后的集合保存在dstkeyN中。对于集合中每一个元素的score，在进行AGGREGATE运算前，都要乘以对于的WEIGHT参数。如果没有提供WEIGHT，默认为1。默认的AGGREGATE是SUM，即结果集合中元素的score是所有集合对应元素进行SUM运算的值，而MIN和MAX是指，结果集合中元素的score是所有集合对应元素中最小值和最大值。  </li>
</ul>
<h3 id="7、对Hash操作的命令"><a href="#7、对Hash操作的命令" class="headerlink" title="7、对Hash操作的命令"></a>7、对Hash操作的命令</h3><ul>
<li>hset(key, field, value)：向名称为key的hash中添加元素field&lt;—&gt;value</li>
<li>hget(key, field)：返回名称为key的hash中field对应的value</li>
<li>hmget(key, field1, …,field N)：返回名称为key的hash中field i对应的value</li>
<li>hmset(key, field1, value1,…,field N, value N)：向名称为key的hash中添加元素field i&lt;—&gt;value i</li>
<li>hincrby(key, field, integer)：将名称为key的hash中field的value增加integer</li>
<li>hexists(key, field)：名称为key的hash中是否存在键为field的域</li>
<li>hdel(key, field)：删除名称为key的hash中键为field的域</li>
<li>hlen(key)：返回名称为key的hash中元素个数</li>
<li>hkeys(key)：返回名称为key的hash中所有键</li>
<li>hvals(key)：返回名称为key的hash中所有键对应的value</li>
<li>hgetall(key)：返回名称为key的hash中所有的键（field）及其对应的value   </li>
</ul>
<h3 id="8、持久化"><a href="#8、持久化" class="headerlink" title="8、持久化"></a>8、持久化</h3><ul>
<li>save：将数据同步保存到磁盘</li>
<li>bgsave：将数据异步保存到磁盘</li>
<li>lastsave：返回上次成功将数据保存到磁盘的Unix时戳</li>
<li>shundown：将数据同步保存到磁盘，然后关闭服务  </li>
</ul>
<h3 id="9、远程服务控制"><a href="#9、远程服务控制" class="headerlink" title="9、远程服务控制"></a>9、远程服务控制</h3><ul>
<li>info：提供服务器的信息和统计</li>
<li>monitor：实时转储收到的请求</li>
<li>slaveof：改变复制策略设置</li>
<li>config：在运行时配置Redis服务器</li>
</ul>
<h2 id="Redis高级应用"><a href="#Redis高级应用" class="headerlink" title="Redis高级应用"></a>Redis高级应用</h2><h3 id="1、安全性"><a href="#1、安全性" class="headerlink" title="1、安全性"></a>1、安全性</h3><h3 id="2、主从复制"><a href="#2、主从复制" class="headerlink" title="2、主从复制"></a>2、主从复制</h3><h3 id="3、事务处理"><a href="#3、事务处理" class="headerlink" title="3、事务处理"></a>3、事务处理</h3><h3 id="4、持久化机制"><a href="#4、持久化机制" class="headerlink" title="4、持久化机制"></a>4、持久化机制</h3><p>常用命令：<br>1） 查看keys个数  </p>
<ul>
<li>keys * // 查看所有keys  </li>
<li>keys prefix_* // 查看前缀为”prefix_”的所有keys</li>
</ul>
<p>2） 清空数据库  </p>
<ul>
<li>flushdb // 清除当前数据库的所有keys  </li>
<li>flushall // 清除所有数据库的所有keys </li>
</ul>
]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>command</tag>
      </tags>
  </entry>
  <entry>
    <title>linux常用命令</title>
    <url>/2019/10/17/linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</url>
    <content><![CDATA[<h2 id="Linux常用命令"><a href="#Linux常用命令" class="headerlink" title="Linux常用命令"></a>Linux常用命令</h2><p>du -h //查看目录空间<br>df -h(-m -k)  //查看所有文件系统使用空间</p>
<p>free -m   //查看内存使用<br>top      //显示进程信息</p>
<p>rm -rf  file  //删除文件夹  </p>
<p>useradd  testuser<br>passwd testuser</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>command</tag>
      </tags>
  </entry>
  <entry>
    <title>scrapy-es_config</title>
    <url>/2019/10/17/scrapy-es-config/</url>
    <content><![CDATA[<h2 id="Scrapy配置"><a href="#Scrapy配置" class="headerlink" title="Scrapy配置"></a>Scrapy配置</h2>]]></content>
      <categories>
        <category>ES</category>
      </categories>
      <tags>
        <tag>config</tag>
      </tags>
  </entry>
  <entry>
    <title>es 踩坑记录</title>
    <url>/2019/10/16/es-%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95/</url>
    <content><![CDATA[<h2 id="解决es数据表某一字段重复出现的一系列问题（es7-1-1"><a href="#解决es数据表某一字段重复出现的一系列问题（es7-1-1" class="headerlink" title="解决es数据表某一字段重复出现的一系列问题（es7.1.1)"></a>解决es数据表某一字段重复出现的一系列问题（es7.1.1)</h2><h3 id="index-ip-domain-date-flag-domain去重）"><a href="#index-ip-domain-date-flag-domain去重）" class="headerlink" title="index: ip domain date flag (domain去重）"></a>index: ip domain date flag (domain去重）</h3><h3 id="方法：通过es聚合，使用字段聚合-top-hits聚合方式"><a href="#方法：通过es聚合，使用字段聚合-top-hits聚合方式" class="headerlink" title="方法：通过es聚合，使用字段聚合+top_hits聚合方式"></a>方法：通过es聚合，使用字段聚合+top_hits聚合方式</h3><h4 id="es中聚合API调用格式："><a href="#es中聚合API调用格式：" class="headerlink" title="es中聚合API调用格式："></a>es中聚合API调用格式：</h4><pre><code>&quot;aggregations&quot; : {                  // 表示聚合操作，可以使用aggs替代
    &quot;&lt;aggregation_name&gt;&quot; : {        // 聚合名，可以是任意的字符串。用做响应的key，便于快速取得正确的响应数据。
        &quot;&lt;aggregation_type&gt;&quot; : {    // 聚合类别，就是各种类型的聚合，如min等
            &lt;aggregation_body&gt;      // 聚合体，不同的聚合有不同的body
        }
        [,&quot;aggregations&quot; : { [&lt;sub_aggregation&gt;]+ } ]? // 嵌套的子聚合，可以有0或多个
    }
    [,&quot;&lt;aggregation_name_2&gt;&quot; : { ... } ]* // 另外的聚合，可以有0或多个
}</code></pre><h3 id="配置："><a href="#配置：" class="headerlink" title="配置："></a>配置：</h3><h4 id="scroll"><a href="#scroll" class="headerlink" title="scroll"></a>scroll</h4><p>虽然搜索请求返回一个结果“页面”，但是滚动API可以用于从一个搜索请求检索大量结果(甚至所有结果)，这与在传统数据库上使用游标的方法非常相似。</p>
<p>滚动不是为实时用户请求而设计的，而是为处理大量数据而设计的，例如，为了将一个索引的内容重新编入具有不同配置的新索引中。</p>
<p>注意:滚动请求返回的结果反映了发出初始搜索请求时索引的状态，就像时间快照一样。文档的后续更改(索引、更新或删除)只会影响以后的搜索请求。</p>
<p>为了使用滚动，初始搜索请求应该在查询字符串中指定滚动参数，该参数告诉Elasticsearch应该保持“搜索上下文”活动多长时间(参见保持搜索上下文活动)，例如?scroll=1m。</p>
<p>修改最大滚动数： （默认500）</p>
<pre><code>curl -X PUT http://192.168.1.182:9200/_cluster/settings -H &apos;Content-Type: application/json&apos; -d&apos;{
    &quot;persistent&quot; : {
        &quot;search.max_open_scroll_context&quot;: 10000
    },
    &quot;transient&quot;: {
        &quot;search.max_open_scroll_context&quot;: 10000
    }
}
&apos;</code></pre><h4 id="bucketing（桶）聚合：划分不同的“桶”，将数据分配到不同的“桶”里。"><a href="#bucketing（桶）聚合：划分不同的“桶”，将数据分配到不同的“桶”里。" class="headerlink" title="bucketing（桶）聚合：划分不同的“桶”，将数据分配到不同的“桶”里。"></a>bucketing（桶）聚合：划分不同的“桶”，将数据分配到不同的“桶”里。</h4><p>修改桶：(默认值10000）</p>
<pre><code>curl -X PUT http://192.168.1.182:9200/_cluster/settings -H &apos;Content-Type: application/json&apos; -d&apos;{
    &quot;persistent&quot; : {
        &quot;search.max_buckets&quot;: 10000000
    },
    &quot;transient&quot;: {
        &quot;search.max_buckets&quot;: 10000000
    }
}
&apos;</code></pre><h4 id="设置最大返回条数："><a href="#设置最大返回条数：" class="headerlink" title="设置最大返回条数："></a>设置最大返回条数：</h4><pre><code>PUT /ips-domains/_settings
{
  &quot;index&quot;:{
    &quot;max_result_window&quot;:2147483647,
    &quot;max_inner_result_window&quot;:5200000,
  }
}</code></pre><h2 id="聚合："><a href="#聚合：" class="headerlink" title="聚合："></a>聚合：</h2><pre><code>dsl2= {
    &quot;query&quot;: {
        &quot;match_all&quot;: {}
    },
    &quot;aggs&quot;: {
        &quot;distinct_domains&quot;: {
            &quot;terms&quot;: {
                &quot;field&quot;: &quot;domain&quot;,
                &quot;size&quot;: 5210000,
                &quot;order&quot;: {
                  &quot;_count&quot;: &quot;desc&quot;
                },
                &quot;min_doc_count&quot;: 2 //最小重复数
              }
    }
    },
    &quot;size&quot;: 0
}</code></pre><p><a href="https://www.cnblogs.com/primadonna/p/11358440.html#%E8%AE%BE%E7%BD%AEcluster_cluster" target="_blank" rel="noopener">聚合教程</a></p>
<p><a href="https://blog.csdn.net/ZYC88888/article/details/83023143" target="_blank" rel="noopener">es字段折叠详解</a></p>
]]></content>
      <categories>
        <category>ES</category>
      </categories>
      <tags>
        <tag>config</tag>
      </tags>
  </entry>
</search>
